fit y_l_r
C:\Users\dell-pc\Anaconda3.6\python.exe C:/Users/dell-pc/Quant/Quant/ml_model.py
2013-01-01 2018-12-31
Time slice keys in hdf5: 2013/0101-0101,2014/0101-0101,2015/0101-0101,2016/0101-0101,2017/0101-0101,2018/0101-0101

Current key: 2013/0101-0101
Current slice size(length): 278061
Current subsample size(length): 55612

Current key: 2014/0101-0101
Current slice size(length): 291574
Current subsample size(length): 58314

Current key: 2015/0101-0101
Current slice size(length): 304680
Current subsample size(length): 60936

Current key: 2016/0101-0101
Current slice size(length): 313767
Current subsample size(length): 62753

Current key: 2017/0101-0101
Current slice size(length): 333371
Current subsample size(length): 66674

Current key: 2018/0101-0101
Current slice size(length): 347712
Current subsample size(length): 69542

Total concatenating size: 373831
Result dataset size: 373831
<class 'pandas.core.frame.DataFrame'>
Int64Index: 373831 entries, 20130607 to 20180925
Columns: 2037 entries, (10MA/20MA-1) to vol0
dtypes: float16(1987), float64(44), int64(1), uint8(5)
memory usage: 1.5 GB
None
(185, 8)
          y_l_rise  y_l_decline  y_l_avg  y_s_rise  y_s_decline  y_s_avg  y_l  \
date
20161202       0.0          0.0      NaN       0.0          0.0      NaN  0.0
20161216       0.0          0.0      NaN       0.0          0.0      NaN  0.0
20161121       0.0          0.0      NaN       0.0          0.0      NaN  0.0
20161208       0.0          0.0      NaN       0.0          0.0      NaN  0.0
20161205       0.0          0.0      NaN       0.0          0.0      NaN  0.0
20161025       0.0          0.0      NaN       0.0          0.0      NaN  0.0
20161103       0.0          0.0      NaN       0.0          0.0      NaN  0.0
20161111       0.0          0.0      NaN       0.0          0.0      NaN  0.0
20161026       0.0          0.0      NaN       0.0          0.0      NaN  0.0
20161108       0.0          0.0      NaN       0.0          0.0      NaN  0.0
20161125       0.0          0.0      NaN       0.0          0.0      NaN  0.0
20161010       0.0          0.0      NaN       0.0          0.0      NaN  0.0
20161027       0.0          0.0      NaN       0.0          0.0      NaN  0.0
20161128       0.0          0.0      NaN       0.0          0.0      NaN  0.0
20161117       0.0          0.0      NaN       0.0          0.0      NaN  0.0
20161102       0.0          0.0      NaN       0.0          0.0      NaN  0.0
20161102       0.0          0.0      NaN       0.0          0.0      NaN  0.0
20160927       0.0          0.0      NaN       0.0          0.0      NaN  0.0
20161214       0.0          0.0      NaN       0.0          0.0      NaN  0.0
20160926       0.0          0.0      NaN       0.0          0.0      NaN  0.0

          y_l_r
date
20161202    NaN
20161216    NaN
20161121    NaN
20161208    NaN
20161205    NaN
20161025    NaN
20161103    NaN
20161111    NaN
20161026    NaN
20161108    NaN
20161125    NaN
20161010    NaN
20161027    NaN
20161128    NaN
20161117    NaN
20161102    NaN
20161102    NaN
20160927    NaN
20161214    NaN
20160926    NaN

test period:20160701-20170101
(200091, 2036) (32118, 2036)

--------------------Train network--------------------

 (200091, 2036) (200091,) {'fit': {'categorical_feature': ['area', 'market', 'exchange', 'is_hs']}, 'train_indexes': (0, None)}

----------Train layer 0----------
slice(0, None, None)

Train l2_y_l
C:\Users\dell-pc\Anaconda3.6\lib\site-packages\lightgbm\basic.py:1042: UserWarning: categorical_feature in Dataset is overridden. New categorical_feature is ['area', 'exchange', 'is_hs', 'market']
  warnings.warn('categorical_feature in Dataset is overridden. New categorical_feature is {}'.format(sorted(list(categorical_feature))))
[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves
[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves
Time usage: 174.82s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=0.1, max_depth=12, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=50,
       n_jobs=-1, num_leaves=31, objective=None, random_state=0,
       reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,
       subsample_for_bin=200000, subsample_freq=0)
                                    feature  importance_raw  \
2025                                 sz_vol             111
1865                               sz50_vol             101
1705                                 sh_vol              69
567                                     amt              54
1526        p80mv_(20k_low/p20mv_20k_low-1)              33
895                               hs300_vol              32
454                          (high-low)/avg              26
732                                 cyb_vol              24
1268           p360mv_lower_shadow/120k_avg              16
1449  p600mv_(120k_low-120k_close)/120k_avg              16
1120       p20mv_(20k_low-20k_open)/20k_avg              15
1466        p60mv_(20k_low/p20mv_20k_low-1)              15
453                        (high-close)/avg              14
1457        p60mv_(20k_avg/p20mv_20k_avg-1)              13
1321        p40mv_(20k_avg/p20mv_20k_avg-1)              12
1350           p480mv_lower_shadow/120k_avg              12
1241        p30mv_(10k_avg/p10mv_10k_avg-1)              12
1347    p480mv_(120k_low/p120mv_120k_low-1)              12
1235       p300mv_(60k_low/p60mv_60k_low-1)              11
125               (20k_avg/p80mv_20k_avg-1)              11

      importance_percent
2025                7.40
1865                6.73
1705                4.60
567                 3.60
1526                2.20
895                 2.13
454                 1.73
732                 1.60
1268                1.07
1449                1.07
1120                1.00
1466                1.00
453                 0.93
1457                0.87
1321                0.80
1350                0.80
1241                0.80
1347                0.80
1235                0.73
125                 0.73
Among 2036 features, 1624 features are not used in the model

--------------------Predict--------------------

----------Layer 0 predicts----------

y_l_r
               count  eval_mean  eval_median  eval_std  eval_max  eval_min
pred_range
(-1.00,-0.95]      0        NaN          NaN       NaN       NaN       NaN
(-0.95,-0.90]      0        NaN          NaN       NaN       NaN       NaN
(-0.90,-0.85]      0        NaN          NaN       NaN       NaN       NaN
(-0.85,-0.80]      0        NaN          NaN       NaN       NaN       NaN
(-0.80,-0.75]      0        NaN          NaN       NaN       NaN       NaN
(-0.75,-0.70]      0        NaN          NaN       NaN       NaN       NaN
(-0.70,-0.65]      0        NaN          NaN       NaN       NaN       NaN
(-0.65,-0.60]      0        NaN          NaN       NaN       NaN       NaN
(-0.60,-0.55]      0        NaN          NaN       NaN       NaN       NaN
(-0.55,-0.50]      0        NaN          NaN       NaN       NaN       NaN
(-0.50,-0.45]      0        NaN          NaN       NaN       NaN       NaN
(-0.45,-0.40]      0        NaN          NaN       NaN       NaN       NaN
(-0.40,-0.35]      0        NaN          NaN       NaN       NaN       NaN
(-0.35,-0.30]      0        NaN          NaN       NaN       NaN       NaN
(-0.30,-0.25]      0        NaN          NaN       NaN       NaN       NaN
(-0.25,-0.20]      0        NaN          NaN       NaN       NaN       NaN
(-0.20,-0.15]      1     -0.202       -0.202       NaN    -0.202    -0.202
(-0.15,-0.10]     16     -0.023       -0.073     0.167     0.380    -0.212
(-0.10,-0.05]    348     -0.018       -0.053     0.118     0.328    -0.294
(-0.05,0.00]    5452      0.009        0.000     0.103     0.858    -0.284
(0.00,0.05]    18779      0.017        0.023     0.099     1.063    -0.341
(0.05,0.10]     6556      0.009       -0.013     0.117     1.055    -0.331
(0.10,0.15]      837     -0.033       -0.063     0.107     0.607    -0.299
(0.15,0.20]      108     -0.035       -0.066     0.117     0.310    -0.212
(0.20,0.25]       18     -0.071       -0.089     0.087     0.107    -0.185
(0.25,0.30]        3     -0.044       -0.069     0.114     0.081    -0.143
(0.30,0.35]        0        NaN          NaN       NaN       NaN       NaN
(0.35,0.40]        0        NaN          NaN       NaN       NaN       NaN
(0.40,0.45]        0        NaN          NaN       NaN       NaN       NaN
(0.45,0.50]        0        NaN          NaN       NaN       NaN       NaN
(0.50,0.55]        0        NaN          NaN       NaN       NaN       NaN
(0.55,0.60]        0        NaN          NaN       NaN       NaN       NaN
(0.60,0.65]        0        NaN          NaN       NaN       NaN       NaN
(0.65,0.70]        0        NaN          NaN       NaN       NaN       NaN
(0.70,0.75]        0        NaN          NaN       NaN       NaN       NaN
(0.75,0.80]        0        NaN          NaN       NaN       NaN       NaN
(0.80,0.85]        0        NaN          NaN       NaN       NaN       NaN
(0.85,0.90]        0        NaN          NaN       NaN       NaN       NaN
(0.90,0.95]        0        NaN          NaN       NaN       NaN       NaN
(0.95,1.00]        0        NaN          NaN       NaN       NaN       NaN

y_l
               count  eval_mean  eval_median  eval_std  eval_max  eval_min
pred_range
(-1.00,-0.95]      0        NaN          NaN       NaN       NaN       NaN
(-0.95,-0.90]      0        NaN          NaN       NaN       NaN       NaN
(-0.90,-0.85]      0        NaN          NaN       NaN       NaN       NaN
(-0.85,-0.80]      0        NaN          NaN       NaN       NaN       NaN
(-0.80,-0.75]      0        NaN          NaN       NaN       NaN       NaN
(-0.75,-0.70]      0        NaN          NaN       NaN       NaN       NaN
(-0.70,-0.65]      0        NaN          NaN       NaN       NaN       NaN
(-0.65,-0.60]      0        NaN          NaN       NaN       NaN       NaN
(-0.60,-0.55]      0        NaN          NaN       NaN       NaN       NaN
(-0.55,-0.50]      0        NaN          NaN       NaN       NaN       NaN
(-0.50,-0.45]      0        NaN          NaN       NaN       NaN       NaN
(-0.45,-0.40]      0        NaN          NaN       NaN       NaN       NaN
(-0.40,-0.35]      0        NaN          NaN       NaN       NaN       NaN
(-0.35,-0.30]      0        NaN          NaN       NaN       NaN       NaN
(-0.30,-0.25]      0        NaN          NaN       NaN       NaN       NaN
(-0.25,-0.20]      0        NaN          NaN       NaN       NaN       NaN
(-0.20,-0.15]      1     -0.237       -0.237       NaN    -0.237    -0.237
(-0.15,-0.10]     16     -0.030       -0.087     0.196     0.454    -0.242
(-0.10,-0.05]    348     -0.023       -0.070     0.139     0.369    -0.337
(-0.05,0.00]    5452      0.008        0.000     0.122     0.956    -0.321
(0.00,0.05]    18779      0.017        0.000     0.117     1.274    -0.393
(0.05,0.10]     6556      0.009       -0.029     0.138     1.204    -0.364
(0.10,0.15]      837     -0.042       -0.078     0.125     0.692    -0.341
(0.15,0.20]      108     -0.043       -0.081     0.136     0.376    -0.239
(0.20,0.25]       18     -0.083       -0.105     0.102     0.124    -0.209
(0.25,0.30]        3     -0.047       -0.083     0.139     0.106    -0.165
(0.30,0.35]        0        NaN          NaN       NaN       NaN       NaN
(0.35,0.40]        0        NaN          NaN       NaN       NaN       NaN
(0.40,0.45]        0        NaN          NaN       NaN       NaN       NaN
(0.45,0.50]        0        NaN          NaN       NaN       NaN       NaN
(0.50,0.55]        0        NaN          NaN       NaN       NaN       NaN
(0.55,0.60]        0        NaN          NaN       NaN       NaN       NaN
(0.60,0.65]        0        NaN          NaN       NaN       NaN       NaN
(0.65,0.70]        0        NaN          NaN       NaN       NaN       NaN
(0.70,0.75]        0        NaN          NaN       NaN       NaN       NaN
(0.75,0.80]        0        NaN          NaN       NaN       NaN       NaN
(0.80,0.85]        0        NaN          NaN       NaN       NaN       NaN
(0.85,0.90]        0        NaN          NaN       NaN       NaN       NaN
(0.90,0.95]        0        NaN          NaN       NaN       NaN       NaN
(0.95,1.00]        0        NaN          NaN       NaN       NaN       NaN

y_l_avg
               count  eval_mean  eval_median  eval_std  eval_max  eval_min
pred_range
(-1.00,-0.95]      0        NaN          NaN       NaN       NaN       NaN
(-0.95,-0.90]      0        NaN          NaN       NaN       NaN       NaN
(-0.90,-0.85]      0        NaN          NaN       NaN       NaN       NaN
(-0.85,-0.80]      0        NaN          NaN       NaN       NaN       NaN
(-0.80,-0.75]      0        NaN          NaN       NaN       NaN       NaN
(-0.75,-0.70]      0        NaN          NaN       NaN       NaN       NaN
(-0.70,-0.65]      0        NaN          NaN       NaN       NaN       NaN
(-0.65,-0.60]      0        NaN          NaN       NaN       NaN       NaN
(-0.60,-0.55]      0        NaN          NaN       NaN       NaN       NaN
(-0.55,-0.50]      0        NaN          NaN       NaN       NaN       NaN
(-0.50,-0.45]      0        NaN          NaN       NaN       NaN       NaN
(-0.45,-0.40]      0        NaN          NaN       NaN       NaN       NaN
(-0.40,-0.35]      0        NaN          NaN       NaN       NaN       NaN
(-0.35,-0.30]      0        NaN          NaN       NaN       NaN       NaN
(-0.30,-0.25]      0        NaN          NaN       NaN       NaN       NaN
(-0.25,-0.20]      0        NaN          NaN       NaN       NaN       NaN
(-0.20,-0.15]      1     -0.096       -0.096       NaN    -0.096    -0.096
(-0.15,-0.10]     16     -0.019       -0.031     0.081     0.158    -0.123
(-0.10,-0.05]    348     -0.007       -0.010     0.057     0.209    -0.165
(-0.05,0.00]    5452      0.005        0.000     0.051     0.564    -0.193
(0.00,0.05]    18779      0.009        0.001     0.050     0.612    -0.234
(0.05,0.10]     6556      0.006       -0.000     0.060     0.613    -0.230
(0.10,0.15]      837     -0.016       -0.021     0.055     0.352    -0.184
(0.15,0.20]      108     -0.021       -0.026     0.058     0.157    -0.133
(0.20,0.25]       18     -0.035       -0.040     0.043     0.059    -0.113
(0.25,0.30]        3     -0.032       -0.029     0.041     0.007    -0.075
(0.30,0.35]        0        NaN          NaN       NaN       NaN       NaN
(0.35,0.40]        0        NaN          NaN       NaN       NaN       NaN
(0.40,0.45]        0        NaN          NaN       NaN       NaN       NaN
(0.45,0.50]        0        NaN          NaN       NaN       NaN       NaN
(0.50,0.55]        0        NaN          NaN       NaN       NaN       NaN
(0.55,0.60]        0        NaN          NaN       NaN       NaN       NaN
(0.60,0.65]        0        NaN          NaN       NaN       NaN       NaN
(0.65,0.70]        0        NaN          NaN       NaN       NaN       NaN
(0.70,0.75]        0        NaN          NaN       NaN       NaN       NaN
(0.75,0.80]        0        NaN          NaN       NaN       NaN       NaN
(0.80,0.85]        0        NaN          NaN       NaN       NaN       NaN
(0.85,0.90]        0        NaN          NaN       NaN       NaN       NaN
(0.90,0.95]        0        NaN          NaN       NaN       NaN       NaN
(0.95,1.00]        0        NaN          NaN       NaN       NaN       NaN

y_l_rise
               count  eval_mean  eval_median  eval_std  eval_max  eval_min
pred_range
(-1.00,-0.95]      0        NaN          NaN       NaN       NaN       NaN
(-0.95,-0.90]      0        NaN          NaN       NaN       NaN       NaN
(-0.90,-0.85]      0        NaN          NaN       NaN       NaN       NaN
(-0.85,-0.80]      0        NaN          NaN       NaN       NaN       NaN
(-0.80,-0.75]      0        NaN          NaN       NaN       NaN       NaN
(-0.75,-0.70]      0        NaN          NaN       NaN       NaN       NaN
(-0.70,-0.65]      0        NaN          NaN       NaN       NaN       NaN
(-0.65,-0.60]      0        NaN          NaN       NaN       NaN       NaN
(-0.60,-0.55]      0        NaN          NaN       NaN       NaN       NaN
(-0.55,-0.50]      0        NaN          NaN       NaN       NaN       NaN
(-0.50,-0.45]      0        NaN          NaN       NaN       NaN       NaN
(-0.45,-0.40]      0        NaN          NaN       NaN       NaN       NaN
(-0.40,-0.35]      0        NaN          NaN       NaN       NaN       NaN
(-0.35,-0.30]      0        NaN          NaN       NaN       NaN       NaN
(-0.30,-0.25]      0        NaN          NaN       NaN       NaN       NaN
(-0.25,-0.20]      0        NaN          NaN       NaN       NaN       NaN
(-0.20,-0.15]      1      0.060        0.060       NaN     0.060     0.060
(-0.15,-0.10]     16      0.086        0.048     0.114     0.454     0.004
(-0.10,-0.05]    348      0.071        0.051     0.070     0.369     0.000
(-0.05,0.00]    5452      0.067        0.047     0.075     0.956     0.000
(0.00,0.05]    18779      0.068        0.048     0.074     1.274     0.000
(0.05,0.10]     6556      0.075        0.051     0.087     1.204     0.000
(0.10,0.15]      837      0.058        0.038     0.065     0.692     0.000
(0.15,0.20]      108      0.060        0.035     0.074     0.376     0.000
(0.20,0.25]       18      0.050        0.040     0.032     0.124     0.008
(0.25,0.30]        3      0.055        0.033     0.044     0.106     0.027
(0.30,0.35]        0        NaN          NaN       NaN       NaN       NaN
(0.35,0.40]        0        NaN          NaN       NaN       NaN       NaN
(0.40,0.45]        0        NaN          NaN       NaN       NaN       NaN
(0.45,0.50]        0        NaN          NaN       NaN       NaN       NaN
(0.50,0.55]        0        NaN          NaN       NaN       NaN       NaN
(0.55,0.60]        0        NaN          NaN       NaN       NaN       NaN
(0.60,0.65]        0        NaN          NaN       NaN       NaN       NaN
(0.65,0.70]        0        NaN          NaN       NaN       NaN       NaN
(0.70,0.75]        0        NaN          NaN       NaN       NaN       NaN
(0.75,0.80]        0        NaN          NaN       NaN       NaN       NaN
(0.80,0.85]        0        NaN          NaN       NaN       NaN       NaN
(0.85,0.90]        0        NaN          NaN       NaN       NaN       NaN
(0.90,0.95]        0        NaN          NaN       NaN       NaN       NaN
(0.95,1.00]        0        NaN          NaN       NaN       NaN       NaN

test period:20170101-20170701
(232010, 2036) (31925, 2036)

--------------------Train network--------------------

 (232010, 2036) (232010,) {'fit': {'categorical_feature': ['area', 'market', 'exchange', 'is_hs']}, 'train_indexes': (0, None)}

----------Train layer 0----------
slice(0, None, None)

Train l2_y_l
C:\Users\dell-pc\Anaconda3.6\lib\site-packages\lightgbm\basic.py:1042: UserWarning: categorical_feature in Dataset is overridden. New categorical_feature is ['area', 'exchange', 'is_hs', 'market']
  warnings.warn('categorical_feature in Dataset is overridden. New categorical_feature is {}'.format(sorted(list(categorical_feature))))
[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves
[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves
Time usage: 195.21s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=0.1, max_depth=12, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=50,
       n_jobs=-1, num_leaves=31, objective=None, random_state=0,
       reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,
       subsample_for_bin=200000, subsample_freq=0)
                                      feature  importance_raw  \
1865                                 sz50_vol             121
2025                                   sz_vol             117
1705                                   sh_vol              90
567                                       amt              45
895                                 hs300_vol              44
1526          p80mv_(20k_low/p20mv_20k_low-1)              28
732                                   cyb_vol              23
454                            (high-low)/avg              22
1466          p60mv_(20k_low/p20mv_20k_low-1)              20
1449    p600mv_(120k_low-120k_close)/120k_avg              18
1457          p60mv_(20k_avg/p20mv_20k_avg-1)              15
1120         p20mv_(20k_low-20k_open)/20k_avg              13
568                                      area              13
1321          p40mv_(20k_avg/p20mv_20k_avg-1)              13
986       p120mv_(60k_close-60k_open)/60k_avg              12
1241          p30mv_(10k_avg/p10mv_10k_avg-1)              12
453                          (high-close)/avg              12
1235         p300mv_(60k_low/p60mv_60k_low-1)              11
1227      p300mv_(60k_close-60k_open)/60k_avg              11
1005  p1250mv_(250k_high-250k_close)/250k_avg              11

      importance_percent
1865                8.07
2025                7.80
1705                6.00
567                 3.00
895                 2.93
1526                1.87
732                 1.53
454                 1.47
1466                1.33
1449                1.20
1457                1.00
1120                0.87
568                 0.87
1321                0.87
986                 0.80
1241                0.80
453                 0.80
1235                0.73
1227                0.73
1005                0.73
Among 2036 features, 1655 features are not used in the model

--------------------Predict--------------------

----------Layer 0 predicts----------

y_l_r
               count  eval_mean  eval_median  eval_std  eval_max  eval_min
pred_range
(-1.00,-0.95]      0        NaN          NaN       NaN       NaN       NaN
(-0.95,-0.90]      0        NaN          NaN       NaN       NaN       NaN
(-0.90,-0.85]      0        NaN          NaN       NaN       NaN       NaN
(-0.85,-0.80]      0        NaN          NaN       NaN       NaN       NaN
(-0.80,-0.75]      0        NaN          NaN       NaN       NaN       NaN
(-0.75,-0.70]      0        NaN          NaN       NaN       NaN       NaN
(-0.70,-0.65]      0        NaN          NaN       NaN       NaN       NaN
(-0.65,-0.60]      0        NaN          NaN       NaN       NaN       NaN
(-0.60,-0.55]      0        NaN          NaN       NaN       NaN       NaN
(-0.55,-0.50]      0        NaN          NaN       NaN       NaN       NaN
(-0.50,-0.45]      0        NaN          NaN       NaN       NaN       NaN
(-0.45,-0.40]      0        NaN          NaN       NaN       NaN       NaN
(-0.40,-0.35]      0        NaN          NaN       NaN       NaN       NaN
(-0.35,-0.30]      0        NaN          NaN       NaN       NaN       NaN
(-0.30,-0.25]      0        NaN          NaN       NaN       NaN       NaN
(-0.25,-0.20]      0        NaN          NaN       NaN       NaN       NaN
(-0.20,-0.15]      0        NaN          NaN       NaN       NaN       NaN
(-0.15,-0.10]      0        NaN          NaN       NaN       NaN       NaN
(-0.10,-0.05]      6     -0.143       -0.157     0.089     0.000    -0.240
(-0.05,0.00]     790     -0.017        0.000     0.126     0.673    -0.337
(0.00,0.05]    18378      0.004        0.000     0.113     1.219    -0.454
(0.05,0.10]    12460      0.021        0.041     0.116     1.063    -0.444
(0.10,0.15]      254      0.078        0.089     0.151     1.022    -0.408
(0.15,0.20]       26      0.024        0.012     0.166     0.457    -0.187
(0.20,0.25]       11     -0.003       -0.113     0.166     0.292    -0.170
(0.25,0.30]        0        NaN          NaN       NaN       NaN       NaN
(0.30,0.35]        0        NaN          NaN       NaN       NaN       NaN
(0.35,0.40]        0        NaN          NaN       NaN       NaN       NaN
(0.40,0.45]        0        NaN          NaN       NaN       NaN       NaN
(0.45,0.50]        0        NaN          NaN       NaN       NaN       NaN
(0.50,0.55]        0        NaN          NaN       NaN       NaN       NaN
(0.55,0.60]        0        NaN          NaN       NaN       NaN       NaN
(0.60,0.65]        0        NaN          NaN       NaN       NaN       NaN
(0.65,0.70]        0        NaN          NaN       NaN       NaN       NaN
(0.70,0.75]        0        NaN          NaN       NaN       NaN       NaN
(0.75,0.80]        0        NaN          NaN       NaN       NaN       NaN
(0.80,0.85]        0        NaN          NaN       NaN       NaN       NaN
(0.85,0.90]        0        NaN          NaN       NaN       NaN       NaN
(0.90,0.95]        0        NaN          NaN       NaN       NaN       NaN
(0.95,1.00]        0        NaN          NaN       NaN       NaN       NaN

y_l
               count  eval_mean  eval_median  eval_std  eval_max  eval_min
pred_range
(-1.00,-0.95]      0        NaN          NaN       NaN       NaN       NaN
(-0.95,-0.90]      0        NaN          NaN       NaN       NaN       NaN
(-0.90,-0.85]      0        NaN          NaN       NaN       NaN       NaN
(-0.85,-0.80]      0        NaN          NaN       NaN       NaN       NaN
(-0.80,-0.75]      0        NaN          NaN       NaN       NaN       NaN
(-0.75,-0.70]      0        NaN          NaN       NaN       NaN       NaN
(-0.70,-0.65]      0        NaN          NaN       NaN       NaN       NaN
(-0.65,-0.60]      0        NaN          NaN       NaN       NaN       NaN
(-0.60,-0.55]      0        NaN          NaN       NaN       NaN       NaN
(-0.55,-0.50]      0        NaN          NaN       NaN       NaN       NaN
(-0.50,-0.45]      0        NaN          NaN       NaN       NaN       NaN
(-0.45,-0.40]      0        NaN          NaN       NaN       NaN       NaN
(-0.40,-0.35]      0        NaN          NaN       NaN       NaN       NaN
(-0.35,-0.30]      0        NaN          NaN       NaN       NaN       NaN
(-0.30,-0.25]      0        NaN          NaN       NaN       NaN       NaN
(-0.25,-0.20]      0        NaN          NaN       NaN       NaN       NaN
(-0.20,-0.15]      0        NaN          NaN       NaN       NaN       NaN
(-0.15,-0.10]      0        NaN          NaN       NaN       NaN       NaN
(-0.10,-0.05]      6     -0.168       -0.194     0.101     0.000    -0.276
(-0.05,0.00]     790     -0.023        0.000     0.148     0.775    -0.408
(0.00,0.05]    18378      0.001        0.000     0.133     1.303    -0.491
(0.05,0.10]    12460      0.020        0.046     0.136     1.191    -0.466
(0.10,0.15]      254      0.086        0.104     0.175     1.130    -0.458
(0.15,0.20]       26      0.027        0.033     0.195     0.527    -0.229
(0.20,0.25]       11     -0.011       -0.140     0.195     0.325    -0.208
(0.25,0.30]        0        NaN          NaN       NaN       NaN       NaN
(0.30,0.35]        0        NaN          NaN       NaN       NaN       NaN
(0.35,0.40]        0        NaN          NaN       NaN       NaN       NaN
(0.40,0.45]        0        NaN          NaN       NaN       NaN       NaN
(0.45,0.50]        0        NaN          NaN       NaN       NaN       NaN
(0.50,0.55]        0        NaN          NaN       NaN       NaN       NaN
(0.55,0.60]        0        NaN          NaN       NaN       NaN       NaN
(0.60,0.65]        0        NaN          NaN       NaN       NaN       NaN
(0.65,0.70]        0        NaN          NaN       NaN       NaN       NaN
(0.70,0.75]        0        NaN          NaN       NaN       NaN       NaN
(0.75,0.80]        0        NaN          NaN       NaN       NaN       NaN
(0.80,0.85]        0        NaN          NaN       NaN       NaN       NaN
(0.85,0.90]        0        NaN          NaN       NaN       NaN       NaN
(0.90,0.95]        0        NaN          NaN       NaN       NaN       NaN
(0.95,1.00]        0        NaN          NaN       NaN       NaN       NaN

y_l_avg
               count  eval_mean  eval_median  eval_std  eval_max  eval_min
pred_range
(-1.00,-0.95]      0        NaN          NaN       NaN       NaN       NaN
(-0.95,-0.90]      0        NaN          NaN       NaN       NaN       NaN
(-0.90,-0.85]      0        NaN          NaN       NaN       NaN       NaN
(-0.85,-0.80]      0        NaN          NaN       NaN       NaN       NaN
(-0.80,-0.75]      0        NaN          NaN       NaN       NaN       NaN
(-0.75,-0.70]      0        NaN          NaN       NaN       NaN       NaN
(-0.70,-0.65]      0        NaN          NaN       NaN       NaN       NaN
(-0.65,-0.60]      0        NaN          NaN       NaN       NaN       NaN
(-0.60,-0.55]      0        NaN          NaN       NaN       NaN       NaN
(-0.55,-0.50]      0        NaN          NaN       NaN       NaN       NaN
(-0.50,-0.45]      0        NaN          NaN       NaN       NaN       NaN
(-0.45,-0.40]      0        NaN          NaN       NaN       NaN       NaN
(-0.40,-0.35]      0        NaN          NaN       NaN       NaN       NaN
(-0.35,-0.30]      0        NaN          NaN       NaN       NaN       NaN
(-0.30,-0.25]      0        NaN          NaN       NaN       NaN       NaN
(-0.25,-0.20]      0        NaN          NaN       NaN       NaN       NaN
(-0.20,-0.15]      0        NaN          NaN       NaN       NaN       NaN
(-0.15,-0.10]      0        NaN          NaN       NaN       NaN       NaN
(-0.10,-0.05]      6     -0.069       -0.060     0.060     0.000    -0.144
(-0.05,0.00]     790     -0.007        0.000     0.064     0.368    -0.218
(0.00,0.05]    18378      0.004        0.000     0.059     0.968    -0.342
(0.05,0.10]    12460      0.012        0.009     0.061     0.860    -0.381
(0.10,0.15]      254      0.046        0.041     0.088     0.698    -0.259
(0.15,0.20]       26      0.022        0.004     0.083     0.249    -0.089
(0.20,0.25]       11      0.022       -0.002     0.080     0.193    -0.059
(0.25,0.30]        0        NaN          NaN       NaN       NaN       NaN
(0.30,0.35]        0        NaN          NaN       NaN       NaN       NaN
(0.35,0.40]        0        NaN          NaN       NaN       NaN       NaN
(0.40,0.45]        0        NaN          NaN       NaN       NaN       NaN
(0.45,0.50]        0        NaN          NaN       NaN       NaN       NaN
(0.50,0.55]        0        NaN          NaN       NaN       NaN       NaN
(0.55,0.60]        0        NaN          NaN       NaN       NaN       NaN
(0.60,0.65]        0        NaN          NaN       NaN       NaN       NaN
(0.65,0.70]        0        NaN          NaN       NaN       NaN       NaN
(0.70,0.75]        0        NaN          NaN       NaN       NaN       NaN
(0.75,0.80]        0        NaN          NaN       NaN       NaN       NaN
(0.80,0.85]        0        NaN          NaN       NaN       NaN       NaN
(0.85,0.90]        0        NaN          NaN       NaN       NaN       NaN
(0.90,0.95]        0        NaN          NaN       NaN       NaN       NaN
(0.95,1.00]        0        NaN          NaN       NaN       NaN       NaN

y_l_rise
               count  eval_mean  eval_median  eval_std  eval_max  eval_min
pred_range
(-1.00,-0.95]      0        NaN          NaN       NaN       NaN       NaN
(-0.95,-0.90]      0        NaN          NaN       NaN       NaN       NaN
(-0.90,-0.85]      0        NaN          NaN       NaN       NaN       NaN
(-0.85,-0.80]      0        NaN          NaN       NaN       NaN       NaN
(-0.80,-0.75]      0        NaN          NaN       NaN       NaN       NaN
(-0.75,-0.70]      0        NaN          NaN       NaN       NaN       NaN
(-0.70,-0.65]      0        NaN          NaN       NaN       NaN       NaN
(-0.65,-0.60]      0        NaN          NaN       NaN       NaN       NaN
(-0.60,-0.55]      0        NaN          NaN       NaN       NaN       NaN
(-0.55,-0.50]      0        NaN          NaN       NaN       NaN       NaN
(-0.50,-0.45]      0        NaN          NaN       NaN       NaN       NaN
(-0.45,-0.40]      0        NaN          NaN       NaN       NaN       NaN
(-0.40,-0.35]      0        NaN          NaN       NaN       NaN       NaN
(-0.35,-0.30]      0        NaN          NaN       NaN       NaN       NaN
(-0.30,-0.25]      0        NaN          NaN       NaN       NaN       NaN
(-0.25,-0.20]      0        NaN          NaN       NaN       NaN       NaN
(-0.20,-0.15]      0        NaN          NaN       NaN       NaN       NaN
(-0.15,-0.10]      0        NaN          NaN       NaN       NaN       NaN
(-0.10,-0.05]      6      0.015        0.010     0.020     0.054     0.000
(-0.05,0.00]     790      0.057        0.026     0.083     0.775     0.000
(0.00,0.05]    18378      0.066        0.044     0.081     1.303     0.000
(0.05,0.10]    12460      0.081        0.060     0.083     1.191     0.000
(0.10,0.15]      254      0.134        0.105     0.123     1.130     0.000
(0.15,0.20]       26      0.115        0.094     0.116     0.527     0.002
(0.20,0.25]       11      0.111        0.100     0.091     0.325     0.003
(0.25,0.30]        0        NaN          NaN       NaN       NaN       NaN
(0.30,0.35]        0        NaN          NaN       NaN       NaN       NaN
(0.35,0.40]        0        NaN          NaN       NaN       NaN       NaN
(0.40,0.45]        0        NaN          NaN       NaN       NaN       NaN
(0.45,0.50]        0        NaN          NaN       NaN       NaN       NaN
(0.50,0.55]        0        NaN          NaN       NaN       NaN       NaN
(0.55,0.60]        0        NaN          NaN       NaN       NaN       NaN
(0.60,0.65]        0        NaN          NaN       NaN       NaN       NaN
(0.65,0.70]        0        NaN          NaN       NaN       NaN       NaN
(0.70,0.75]        0        NaN          NaN       NaN       NaN       NaN
(0.75,0.80]        0        NaN          NaN       NaN       NaN       NaN
(0.80,0.85]        0        NaN          NaN       NaN       NaN       NaN
(0.85,0.90]        0        NaN          NaN       NaN       NaN       NaN
(0.90,0.95]        0        NaN          NaN       NaN       NaN       NaN
(0.95,1.00]        0        NaN          NaN       NaN       NaN       NaN

test period:20170701-20180101
(263835, 2036) (34678, 2036)

--------------------Train network--------------------

 (263835, 2036) (263835,) {'fit': {'categorical_feature': ['area', 'market', 'exchange', 'is_hs']}, 'train_indexes': (0, None)}

----------Train layer 0----------
slice(0, None, None)

Train l2_y_l
C:\Users\dell-pc\Anaconda3.6\lib\site-packages\lightgbm\basic.py:1042: UserWarning: categorical_feature in Dataset is overridden. New categorical_feature is ['area', 'exchange', 'is_hs', 'market']
  warnings.warn('categorical_feature in Dataset is overridden. New categorical_feature is {}'.format(sorted(list(categorical_feature))))
[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves
[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves
Time usage: 227.74s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=0.1, max_depth=12, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=50,
       n_jobs=-1, num_leaves=31, objective=None, random_state=0,
       reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,
       subsample_for_bin=200000, subsample_freq=0)
                                    feature  importance_raw  \
1865                               sz50_vol             111
1705                                 sh_vol             105
2025                                 sz_vol             101
895                               hs300_vol              52
567                                     amt              44
732                                 cyb_vol              28
454                          (high-low)/avg              26
1526        p80mv_(20k_low/p20mv_20k_low-1)              24
1466        p60mv_(20k_low/p20mv_20k_low-1)              20
1449  p600mv_(120k_low-120k_close)/120k_avg              15
1321        p40mv_(20k_avg/p20mv_20k_avg-1)              14
1457        p60mv_(20k_avg/p20mv_20k_avg-1)              14
1241        p30mv_(10k_avg/p10mv_10k_avg-1)              13
986     p120mv_(60k_close-60k_open)/60k_avg              13
1268           p360mv_lower_shadow/120k_avg              13
453                        (high-close)/avg              12
1120       p20mv_(20k_low-20k_open)/20k_avg              11
568                                    area              11
1260   p360mv_(120k_high-120k_low)/120k_avg              10
141             (20k_high/p80mv_20k_high-1)              10

      importance_percent
1865                7.40
1705                7.00
2025                6.73
895                 3.47
567                 2.93
732                 1.87
454                 1.73
1526                1.60
1466                1.33
1449                1.00
1321                0.93
1457                0.93
1241                0.87
986                 0.87
1268                0.87
453                 0.80
1120                0.73
568                 0.73
1260                0.67
141                 0.67
Among 2036 features, 1634 features are not used in the model

--------------------Predict--------------------

----------Layer 0 predicts----------

y_l_r
               count  eval_mean  eval_median  eval_std  eval_max  eval_min
pred_range
(-1.00,-0.95]      0        NaN          NaN       NaN       NaN       NaN
(-0.95,-0.90]      0        NaN          NaN       NaN       NaN       NaN
(-0.90,-0.85]      0        NaN          NaN       NaN       NaN       NaN
(-0.85,-0.80]      0        NaN          NaN       NaN       NaN       NaN
(-0.80,-0.75]      0        NaN          NaN       NaN       NaN       NaN
(-0.75,-0.70]      0        NaN          NaN       NaN       NaN       NaN
(-0.70,-0.65]      0        NaN          NaN       NaN       NaN       NaN
(-0.65,-0.60]      0        NaN          NaN       NaN       NaN       NaN
(-0.60,-0.55]      0        NaN          NaN       NaN       NaN       NaN
(-0.55,-0.50]      0        NaN          NaN       NaN       NaN       NaN
(-0.50,-0.45]      0        NaN          NaN       NaN       NaN       NaN
(-0.45,-0.40]      0        NaN          NaN       NaN       NaN       NaN
(-0.40,-0.35]      0        NaN          NaN       NaN       NaN       NaN
(-0.35,-0.30]      0        NaN          NaN       NaN       NaN       NaN
(-0.30,-0.25]      0        NaN          NaN       NaN       NaN       NaN
(-0.25,-0.20]      0        NaN          NaN       NaN       NaN       NaN
(-0.20,-0.15]      0        NaN          NaN       NaN       NaN       NaN
(-0.15,-0.10]      4     -0.046       -0.083     0.093     0.092    -0.108
(-0.10,-0.05]    149      0.002       -0.029     0.136     0.807    -0.202
(-0.05,0.00]    9537      0.023        0.013     0.114     0.854    -0.375
(0.00,0.05]    23385      0.018        0.014     0.115     0.814    -0.358
(0.05,0.10]     1500      0.028        0.044     0.147     1.730    -0.286
(0.10,0.15]       94      0.011       -0.019     0.136     0.389    -0.209
(0.15,0.20]        9      0.033       -0.050     0.168     0.366    -0.127
(0.20,0.25]        0        NaN          NaN       NaN       NaN       NaN
(0.25,0.30]        0        NaN          NaN       NaN       NaN       NaN
(0.30,0.35]        0        NaN          NaN       NaN       NaN       NaN
(0.35,0.40]        0        NaN          NaN       NaN       NaN       NaN
(0.40,0.45]        0        NaN          NaN       NaN       NaN       NaN
(0.45,0.50]        0        NaN          NaN       NaN       NaN       NaN
(0.50,0.55]        0        NaN          NaN       NaN       NaN       NaN
(0.55,0.60]        0        NaN          NaN       NaN       NaN       NaN
(0.60,0.65]        0        NaN          NaN       NaN       NaN       NaN
(0.65,0.70]        0        NaN          NaN       NaN       NaN       NaN
(0.70,0.75]        0        NaN          NaN       NaN       NaN       NaN
(0.75,0.80]        0        NaN          NaN       NaN       NaN       NaN
(0.80,0.85]        0        NaN          NaN       NaN       NaN       NaN
(0.85,0.90]        0        NaN          NaN       NaN       NaN       NaN
(0.90,0.95]        0        NaN          NaN       NaN       NaN       NaN
(0.95,1.00]        0        NaN          NaN       NaN       NaN       NaN

y_l
               count  eval_mean  eval_median  eval_std  eval_max  eval_min
pred_range
(-1.00,-0.95]      0        NaN          NaN       NaN       NaN       NaN
(-0.95,-0.90]      0        NaN          NaN       NaN       NaN       NaN
(-0.90,-0.85]      0        NaN          NaN       NaN       NaN       NaN
(-0.85,-0.80]      0        NaN          NaN       NaN       NaN       NaN
(-0.80,-0.75]      0        NaN          NaN       NaN       NaN       NaN
(-0.75,-0.70]      0        NaN          NaN       NaN       NaN       NaN
(-0.70,-0.65]      0        NaN          NaN       NaN       NaN       NaN
(-0.65,-0.60]      0        NaN          NaN       NaN       NaN       NaN
(-0.60,-0.55]      0        NaN          NaN       NaN       NaN       NaN
(-0.55,-0.50]      0        NaN          NaN       NaN       NaN       NaN
(-0.50,-0.45]      0        NaN          NaN       NaN       NaN       NaN
(-0.45,-0.40]      0        NaN          NaN       NaN       NaN       NaN
(-0.40,-0.35]      0        NaN          NaN       NaN       NaN       NaN
(-0.35,-0.30]      0        NaN          NaN       NaN       NaN       NaN
(-0.30,-0.25]      0        NaN          NaN       NaN       NaN       NaN
(-0.25,-0.20]      0        NaN          NaN       NaN       NaN       NaN
(-0.20,-0.15]      0        NaN          NaN       NaN       NaN       NaN
(-0.15,-0.10]      4      0.000       -0.000     0.145     0.138    -0.136
(-0.10,-0.05]    149      0.004        0.000     0.161     0.975    -0.225
(-0.05,0.00]    9537      0.026        0.000     0.133     0.988    -0.431
(0.00,0.05]    23385      0.020        0.000     0.135     0.965    -0.398
(0.05,0.10]     1500      0.032        0.056     0.172     2.043    -0.319
(0.10,0.15]       94      0.015        0.024     0.157     0.432    -0.233
(0.15,0.20]        9      0.037       -0.062     0.194     0.413    -0.140
(0.20,0.25]        0        NaN          NaN       NaN       NaN       NaN
(0.25,0.30]        0        NaN          NaN       NaN       NaN       NaN
(0.30,0.35]        0        NaN          NaN       NaN       NaN       NaN
(0.35,0.40]        0        NaN          NaN       NaN       NaN       NaN
(0.40,0.45]        0        NaN          NaN       NaN       NaN       NaN
(0.45,0.50]        0        NaN          NaN       NaN       NaN       NaN
(0.50,0.55]        0        NaN          NaN       NaN       NaN       NaN
(0.55,0.60]        0        NaN          NaN       NaN       NaN       NaN
(0.60,0.65]        0        NaN          NaN       NaN       NaN       NaN
(0.65,0.70]        0        NaN          NaN       NaN       NaN       NaN
(0.70,0.75]        0        NaN          NaN       NaN       NaN       NaN
(0.75,0.80]        0        NaN          NaN       NaN       NaN       NaN
(0.80,0.85]        0        NaN          NaN       NaN       NaN       NaN
(0.85,0.90]        0        NaN          NaN       NaN       NaN       NaN
(0.90,0.95]        0        NaN          NaN       NaN       NaN       NaN
(0.95,1.00]        0        NaN          NaN       NaN       NaN       NaN

y_l_avg
               count  eval_mean  eval_median  eval_std  eval_max  eval_min
pred_range
(-1.00,-0.95]      0        NaN          NaN       NaN       NaN       NaN
(-0.95,-0.90]      0        NaN          NaN       NaN       NaN       NaN
(-0.90,-0.85]      0        NaN          NaN       NaN       NaN       NaN
(-0.85,-0.80]      0        NaN          NaN       NaN       NaN       NaN
(-0.80,-0.75]      0        NaN          NaN       NaN       NaN       NaN
(-0.75,-0.70]      0        NaN          NaN       NaN       NaN       NaN
(-0.70,-0.65]      0        NaN          NaN       NaN       NaN       NaN
(-0.65,-0.60]      0        NaN          NaN       NaN       NaN       NaN
(-0.60,-0.55]      0        NaN          NaN       NaN       NaN       NaN
(-0.55,-0.50]      0        NaN          NaN       NaN       NaN       NaN
(-0.50,-0.45]      0        NaN          NaN       NaN       NaN       NaN
(-0.45,-0.40]      0        NaN          NaN       NaN       NaN       NaN
(-0.40,-0.35]      0        NaN          NaN       NaN       NaN       NaN
(-0.35,-0.30]      0        NaN          NaN       NaN       NaN       NaN
(-0.30,-0.25]      0        NaN          NaN       NaN       NaN       NaN
(-0.25,-0.20]      0        NaN          NaN       NaN       NaN       NaN
(-0.20,-0.15]      0        NaN          NaN       NaN       NaN       NaN
(-0.15,-0.10]      4     -0.005       -0.012     0.027     0.031    -0.028
(-0.10,-0.05]    149      0.004       -0.002     0.065     0.304    -0.134
(-0.05,0.00]    9537      0.012        0.000     0.059     0.497    -0.261
(0.00,0.05]    23385      0.010        0.000     0.060     0.525    -0.236
(0.05,0.10]     1500      0.014        0.004     0.076     0.793    -0.197
(0.10,0.15]       94      0.004       -0.000     0.074     0.261    -0.138
(0.15,0.20]        9      0.022       -0.015     0.092     0.223    -0.086
(0.20,0.25]        0        NaN          NaN       NaN       NaN       NaN
(0.25,0.30]        0        NaN          NaN       NaN       NaN       NaN
(0.30,0.35]        0        NaN          NaN       NaN       NaN       NaN
(0.35,0.40]        0        NaN          NaN       NaN       NaN       NaN
(0.40,0.45]        0        NaN          NaN       NaN       NaN       NaN
(0.45,0.50]        0        NaN          NaN       NaN       NaN       NaN
(0.50,0.55]        0        NaN          NaN       NaN       NaN       NaN
(0.55,0.60]        0        NaN          NaN       NaN       NaN       NaN
(0.60,0.65]        0        NaN          NaN       NaN       NaN       NaN
(0.65,0.70]        0        NaN          NaN       NaN       NaN       NaN
(0.70,0.75]        0        NaN          NaN       NaN       NaN       NaN
(0.75,0.80]        0        NaN          NaN       NaN       NaN       NaN
(0.80,0.85]        0        NaN          NaN       NaN       NaN       NaN
(0.85,0.90]        0        NaN          NaN       NaN       NaN       NaN
(0.90,0.95]        0        NaN          NaN       NaN       NaN       NaN
(0.95,1.00]        0        NaN          NaN       NaN       NaN       NaN

y_l_rise
               count  eval_mean  eval_median  eval_std  eval_max  eval_min
pred_range
(-1.00,-0.95]      0        NaN          NaN       NaN       NaN       NaN
(-0.95,-0.90]      0        NaN          NaN       NaN       NaN       NaN
(-0.90,-0.85]      0        NaN          NaN       NaN       NaN       NaN
(-0.85,-0.80]      0        NaN          NaN       NaN       NaN       NaN
(-0.80,-0.75]      0        NaN          NaN       NaN       NaN       NaN
(-0.75,-0.70]      0        NaN          NaN       NaN       NaN       NaN
(-0.70,-0.65]      0        NaN          NaN       NaN       NaN       NaN
(-0.65,-0.60]      0        NaN          NaN       NaN       NaN       NaN
(-0.60,-0.55]      0        NaN          NaN       NaN       NaN       NaN
(-0.55,-0.50]      0        NaN          NaN       NaN       NaN       NaN
(-0.50,-0.45]      0        NaN          NaN       NaN       NaN       NaN
(-0.45,-0.40]      0        NaN          NaN       NaN       NaN       NaN
(-0.40,-0.35]      0        NaN          NaN       NaN       NaN       NaN
(-0.35,-0.30]      0        NaN          NaN       NaN       NaN       NaN
(-0.30,-0.25]      0        NaN          NaN       NaN       NaN       NaN
(-0.25,-0.20]      0        NaN          NaN       NaN       NaN       NaN
(-0.20,-0.15]      0        NaN          NaN       NaN       NaN       NaN
(-0.15,-0.10]      4      0.084        0.084     0.050     0.138     0.029
(-0.10,-0.05]    149      0.082        0.053     0.111     0.975     0.000
(-0.05,0.00]    9537      0.077        0.051     0.088     0.988     0.000
(0.00,0.05]    23385      0.079        0.053     0.086     0.965     0.000
(0.05,0.10]     1500      0.099        0.068     0.121     2.043     0.000
(0.10,0.15]       94      0.094        0.077     0.085     0.432     0.000
(0.15,0.20]        9      0.116        0.089     0.130     0.413     0.000
(0.20,0.25]        0        NaN          NaN       NaN       NaN       NaN
(0.25,0.30]        0        NaN          NaN       NaN       NaN       NaN
(0.30,0.35]        0        NaN          NaN       NaN       NaN       NaN
(0.35,0.40]        0        NaN          NaN       NaN       NaN       NaN
(0.40,0.45]        0        NaN          NaN       NaN       NaN       NaN
(0.45,0.50]        0        NaN          NaN       NaN       NaN       NaN
(0.50,0.55]        0        NaN          NaN       NaN       NaN       NaN
(0.55,0.60]        0        NaN          NaN       NaN       NaN       NaN
(0.60,0.65]        0        NaN          NaN       NaN       NaN       NaN
(0.65,0.70]        0        NaN          NaN       NaN       NaN       NaN
(0.70,0.75]        0        NaN          NaN       NaN       NaN       NaN
(0.75,0.80]        0        NaN          NaN       NaN       NaN       NaN
(0.80,0.85]        0        NaN          NaN       NaN       NaN       NaN
(0.85,0.90]        0        NaN          NaN       NaN       NaN       NaN
(0.90,0.95]        0        NaN          NaN       NaN       NaN       NaN
(0.95,1.00]        0        NaN          NaN       NaN       NaN       NaN

test period:20180101-20180701
(298328, 2036) (33929, 2036)

--------------------Train network--------------------

 (298328, 2036) (298328,) {'fit': {'categorical_feature': ['area', 'market', 'exchange', 'is_hs']}, 'train_indexes': (0, None)}

----------Train layer 0----------
slice(0, None, None)

Train l2_y_l
C:\Users\dell-pc\Anaconda3.6\lib\site-packages\lightgbm\basic.py:1042: UserWarning: categorical_feature in Dataset is overridden. New categorical_feature is ['area', 'exchange', 'is_hs', 'market']
  warnings.warn('categorical_feature in Dataset is overridden. New categorical_feature is {}'.format(sorted(list(categorical_feature))))
[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves
[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves
Time usage: 271.61s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=0.1, max_depth=12, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=50,
       n_jobs=-1, num_leaves=31, objective=None, random_state=0,
       reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,
       subsample_for_bin=200000, subsample_freq=0)
                                    feature  importance_raw  \
1865                               sz50_vol             102
2025                                 sz_vol              98
1705                                 sh_vol              86
895                               hs300_vol              49
567                                     amt              36
1526        p80mv_(20k_low/p20mv_20k_low-1)              29
454                          (high-low)/avg              27
732                                 cyb_vol              27
1321        p40mv_(20k_avg/p20mv_20k_avg-1)              17
1466        p60mv_(20k_low/p20mv_20k_low-1)              16
1268           p360mv_lower_shadow/120k_avg              15
1120       p20mv_(20k_low-20k_open)/20k_avg              14
986     p120mv_(60k_close-60k_open)/60k_avg              13
1449  p600mv_(120k_low-120k_close)/120k_avg              13
1138             p20mv_lower_shadow/20k_avg              11
1061       p180mv_(60k_amt/p60mv_60k_amt-1)              11
1112        p20mv_(20k_avg/p20mv_20k_avg-1)              11
453                        (high-close)/avg              11
937      p100mv_(20k_open/p20mv_20k_open-1)              10
1346   p480mv_(120k_low-120k_open)/120k_avg              10

      importance_percent
1865                6.80
2025                6.53
1705                5.73
895                 3.27
567                 2.40
1526                1.93
454                 1.80
732                 1.80
1321                1.13
1466                1.07
1268                1.00
1120                0.93
986                 0.87
1449                0.87
1138                0.73
1061                0.73
1112                0.73
453                 0.73
937                 0.67
1346                0.67
Among 2036 features, 1612 features are not used in the model

--------------------Predict--------------------

----------Layer 0 predicts----------

y_l_r
               count  eval_mean  eval_median  eval_std  eval_max  eval_min
pred_range
(-1.00,-0.95]      0        NaN          NaN       NaN       NaN       NaN
(-0.95,-0.90]      0        NaN          NaN       NaN       NaN       NaN
(-0.90,-0.85]      0        NaN          NaN       NaN       NaN       NaN
(-0.85,-0.80]      0        NaN          NaN       NaN       NaN       NaN
(-0.80,-0.75]      0        NaN          NaN       NaN       NaN       NaN
(-0.75,-0.70]      0        NaN          NaN       NaN       NaN       NaN
(-0.70,-0.65]      0        NaN          NaN       NaN       NaN       NaN
(-0.65,-0.60]      0        NaN          NaN       NaN       NaN       NaN
(-0.60,-0.55]      0        NaN          NaN       NaN       NaN       NaN
(-0.55,-0.50]      0        NaN          NaN       NaN       NaN       NaN
(-0.50,-0.45]      0        NaN          NaN       NaN       NaN       NaN
(-0.45,-0.40]      0        NaN          NaN       NaN       NaN       NaN
(-0.40,-0.35]      0        NaN          NaN       NaN       NaN       NaN
(-0.35,-0.30]      0        NaN          NaN       NaN       NaN       NaN
(-0.30,-0.25]      0        NaN          NaN       NaN       NaN       NaN
(-0.25,-0.20]      0        NaN          NaN       NaN       NaN       NaN
(-0.20,-0.15]      0        NaN          NaN       NaN       NaN       NaN
(-0.15,-0.10]     10     -0.126       -0.150     0.149     0.139    -0.298
(-0.10,-0.05]     40     -0.042       -0.091     0.179     0.358    -0.262
(-0.05,0.00]    1432     -0.041       -0.044     0.128     0.737    -0.430
(0.00,0.05]    25049     -0.024       -0.054     0.127     0.838    -0.619
(0.05,0.10]     6549     -0.009       -0.061     0.156     1.151    -0.568
(0.10,0.15]      756      0.044        0.084     0.197     0.688    -0.546
(0.15,0.20]       75      0.092        0.120     0.202     0.665    -0.261
(0.20,0.25]       15      0.079       -0.062     0.240     0.434    -0.182
(0.25,0.30]        3      0.020        0.125     0.195     0.141    -0.205
(0.30,0.35]        0        NaN          NaN       NaN       NaN       NaN
(0.35,0.40]        0        NaN          NaN       NaN       NaN       NaN
(0.40,0.45]        0        NaN          NaN       NaN       NaN       NaN
(0.45,0.50]        0        NaN          NaN       NaN       NaN       NaN
(0.50,0.55]        0        NaN          NaN       NaN       NaN       NaN
(0.55,0.60]        0        NaN          NaN       NaN       NaN       NaN
(0.60,0.65]        0        NaN          NaN       NaN       NaN       NaN
(0.65,0.70]        0        NaN          NaN       NaN       NaN       NaN
(0.70,0.75]        0        NaN          NaN       NaN       NaN       NaN
(0.75,0.80]        0        NaN          NaN       NaN       NaN       NaN
(0.80,0.85]        0        NaN          NaN       NaN       NaN       NaN
(0.85,0.90]        0        NaN          NaN       NaN       NaN       NaN
(0.90,0.95]        0        NaN          NaN       NaN       NaN       NaN
(0.95,1.00]        0        NaN          NaN       NaN       NaN       NaN
C:\Users\dell-pc\Anaconda3.6\lib\site-packages\matplotlib\pyplot.py:537: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  max_open_warning, RuntimeWarning)

y_l
               count  eval_mean  eval_median  eval_std  eval_max  eval_min
pred_range
(-1.00,-0.95]      0        NaN          NaN       NaN       NaN       NaN
(-0.95,-0.90]      0        NaN          NaN       NaN       NaN       NaN
(-0.90,-0.85]      0        NaN          NaN       NaN       NaN       NaN
(-0.85,-0.80]      0        NaN          NaN       NaN       NaN       NaN
(-0.80,-0.75]      0        NaN          NaN       NaN       NaN       NaN
(-0.75,-0.70]      0        NaN          NaN       NaN       NaN       NaN
(-0.70,-0.65]      0        NaN          NaN       NaN       NaN       NaN
(-0.65,-0.60]      0        NaN          NaN       NaN       NaN       NaN
(-0.60,-0.55]      0        NaN          NaN       NaN       NaN       NaN
(-0.55,-0.50]      0        NaN          NaN       NaN       NaN       NaN
(-0.50,-0.45]      0        NaN          NaN       NaN       NaN       NaN
(-0.45,-0.40]      0        NaN          NaN       NaN       NaN       NaN
(-0.40,-0.35]      0        NaN          NaN       NaN       NaN       NaN
(-0.35,-0.30]      0        NaN          NaN       NaN       NaN       NaN
(-0.30,-0.25]      0        NaN          NaN       NaN       NaN       NaN
(-0.25,-0.20]      0        NaN          NaN       NaN       NaN       NaN
(-0.20,-0.15]      0        NaN          NaN       NaN       NaN       NaN
(-0.15,-0.10]     10     -0.155       -0.186     0.178     0.155    -0.352
(-0.10,-0.05]     40     -0.058       -0.117     0.207     0.411    -0.301
(-0.05,0.00]    1432     -0.052       -0.066     0.149     0.824    -0.536
(0.00,0.05]    25049     -0.035       -0.077     0.148     0.915    -0.631
(0.05,0.10]     6549     -0.020       -0.090     0.182     1.326    -0.598
(0.10,0.15]      756      0.042        0.096     0.228     0.771    -0.563
(0.15,0.20]       75      0.098        0.145     0.237     0.741    -0.300
(0.20,0.25]       15      0.105        0.092     0.274     0.494    -0.221
(0.25,0.30]        3      0.035        0.165     0.243     0.184    -0.245
(0.30,0.35]        0        NaN          NaN       NaN       NaN       NaN
(0.35,0.40]        0        NaN          NaN       NaN       NaN       NaN
(0.40,0.45]        0        NaN          NaN       NaN       NaN       NaN
(0.45,0.50]        0        NaN          NaN       NaN       NaN       NaN
(0.50,0.55]        0        NaN          NaN       NaN       NaN       NaN
(0.55,0.60]        0        NaN          NaN       NaN       NaN       NaN
(0.60,0.65]        0        NaN          NaN       NaN       NaN       NaN
(0.65,0.70]        0        NaN          NaN       NaN       NaN       NaN
(0.70,0.75]        0        NaN          NaN       NaN       NaN       NaN
(0.75,0.80]        0        NaN          NaN       NaN       NaN       NaN
(0.80,0.85]        0        NaN          NaN       NaN       NaN       NaN
(0.85,0.90]        0        NaN          NaN       NaN       NaN       NaN
(0.90,0.95]        0        NaN          NaN       NaN       NaN       NaN
(0.95,1.00]        0        NaN          NaN       NaN       NaN       NaN

y_l_avg
               count  eval_mean  eval_median  eval_std  eval_max  eval_min
pred_range
(-1.00,-0.95]      0        NaN          NaN       NaN       NaN       NaN
(-0.95,-0.90]      0        NaN          NaN       NaN       NaN       NaN
(-0.90,-0.85]      0        NaN          NaN       NaN       NaN       NaN
(-0.85,-0.80]      0        NaN          NaN       NaN       NaN       NaN
(-0.80,-0.75]      0        NaN          NaN       NaN       NaN       NaN
(-0.75,-0.70]      0        NaN          NaN       NaN       NaN       NaN
(-0.70,-0.65]      0        NaN          NaN       NaN       NaN       NaN
(-0.65,-0.60]      0        NaN          NaN       NaN       NaN       NaN
(-0.60,-0.55]      0        NaN          NaN       NaN       NaN       NaN
(-0.55,-0.50]      0        NaN          NaN       NaN       NaN       NaN
(-0.50,-0.45]      0        NaN          NaN       NaN       NaN       NaN
(-0.45,-0.40]      0        NaN          NaN       NaN       NaN       NaN
(-0.40,-0.35]      0        NaN          NaN       NaN       NaN       NaN
(-0.35,-0.30]      0        NaN          NaN       NaN       NaN       NaN
(-0.30,-0.25]      0        NaN          NaN       NaN       NaN       NaN
(-0.25,-0.20]      0        NaN          NaN       NaN       NaN       NaN
(-0.20,-0.15]      0        NaN          NaN       NaN       NaN       NaN
(-0.15,-0.10]     10     -0.039       -0.046     0.068     0.090    -0.136
(-0.10,-0.05]     40     -0.017       -0.029     0.092     0.214    -0.145
(-0.05,0.00]    1432     -0.018       -0.004     0.068     0.474    -0.317
(0.00,0.05]    25049     -0.010       -0.009     0.066     0.609    -0.583
(0.05,0.10]     6549     -0.001       -0.008     0.083     0.625    -0.475
(0.10,0.15]      756      0.028        0.021     0.113     0.517    -0.494
(0.15,0.20]       75      0.051        0.042     0.113     0.436    -0.144
(0.20,0.25]       15      0.059       -0.002     0.122     0.261    -0.065
(0.25,0.30]        3     -0.023        0.004     0.054     0.012    -0.086
(0.30,0.35]        0        NaN          NaN       NaN       NaN       NaN
(0.35,0.40]        0        NaN          NaN       NaN       NaN       NaN
(0.40,0.45]        0        NaN          NaN       NaN       NaN       NaN
(0.45,0.50]        0        NaN          NaN       NaN       NaN       NaN
(0.50,0.55]        0        NaN          NaN       NaN       NaN       NaN
(0.55,0.60]        0        NaN          NaN       NaN       NaN       NaN
(0.60,0.65]        0        NaN          NaN       NaN       NaN       NaN
(0.65,0.70]        0        NaN          NaN       NaN       NaN       NaN
(0.70,0.75]        0        NaN          NaN       NaN       NaN       NaN
(0.75,0.80]        0        NaN          NaN       NaN       NaN       NaN
(0.80,0.85]        0        NaN          NaN       NaN       NaN       NaN
(0.85,0.90]        0        NaN          NaN       NaN       NaN       NaN
(0.90,0.95]        0        NaN          NaN       NaN       NaN       NaN
(0.95,1.00]        0        NaN          NaN       NaN       NaN       NaN

y_l_rise
               count  eval_mean  eval_median  eval_std  eval_max  eval_min
pred_range
(-1.00,-0.95]      0        NaN          NaN       NaN       NaN       NaN
(-0.95,-0.90]      0        NaN          NaN       NaN       NaN       NaN
(-0.90,-0.85]      0        NaN          NaN       NaN       NaN       NaN
(-0.85,-0.80]      0        NaN          NaN       NaN       NaN       NaN
(-0.80,-0.75]      0        NaN          NaN       NaN       NaN       NaN
(-0.75,-0.70]      0        NaN          NaN       NaN       NaN       NaN
(-0.70,-0.65]      0        NaN          NaN       NaN       NaN       NaN
(-0.65,-0.60]      0        NaN          NaN       NaN       NaN       NaN
(-0.60,-0.55]      0        NaN          NaN       NaN       NaN       NaN
(-0.55,-0.50]      0        NaN          NaN       NaN       NaN       NaN
(-0.50,-0.45]      0        NaN          NaN       NaN       NaN       NaN
(-0.45,-0.40]      0        NaN          NaN       NaN       NaN       NaN
(-0.40,-0.35]      0        NaN          NaN       NaN       NaN       NaN
(-0.35,-0.30]      0        NaN          NaN       NaN       NaN       NaN
(-0.30,-0.25]      0        NaN          NaN       NaN       NaN       NaN
(-0.25,-0.20]      0        NaN          NaN       NaN       NaN       NaN
(-0.20,-0.15]      0        NaN          NaN       NaN       NaN       NaN
(-0.15,-0.10]     10      0.079        0.075     0.051     0.155     0.010
(-0.10,-0.05]     40      0.093        0.059     0.099     0.411     0.002
(-0.05,0.00]    1432      0.054        0.027     0.075     0.824     0.000
(0.00,0.05]    25049      0.068        0.044     0.075     0.915     0.000
(0.05,0.10]     6549      0.095        0.066     0.095     1.326     0.000
(0.10,0.15]      756      0.146        0.112     0.127     0.771     0.000
(0.15,0.20]       75      0.179        0.145     0.148     0.741     0.000
(0.20,0.25]       15      0.203        0.100     0.180     0.494     0.019
(0.25,0.30]        3      0.132        0.165     0.074     0.184     0.047
(0.30,0.35]        0        NaN          NaN       NaN       NaN       NaN
(0.35,0.40]        0        NaN          NaN       NaN       NaN       NaN
(0.40,0.45]        0        NaN          NaN       NaN       NaN       NaN
(0.45,0.50]        0        NaN          NaN       NaN       NaN       NaN
(0.50,0.55]        0        NaN          NaN       NaN       NaN       NaN
(0.55,0.60]        0        NaN          NaN       NaN       NaN       NaN
(0.60,0.65]        0        NaN          NaN       NaN       NaN       NaN
(0.65,0.70]        0        NaN          NaN       NaN       NaN       NaN
(0.70,0.75]        0        NaN          NaN       NaN       NaN       NaN
(0.75,0.80]        0        NaN          NaN       NaN       NaN       NaN
(0.80,0.85]        0        NaN          NaN       NaN       NaN       NaN
(0.85,0.90]        0        NaN          NaN       NaN       NaN       NaN
(0.90,0.95]        0        NaN          NaN       NaN       NaN       NaN
(0.95,1.00]        0        NaN          NaN       NaN       NaN       NaN

test period:20180701-20190101
C:\Users\dell-pc\Anaconda3.6\lib\site-packages\matplotlib\pyplot.py:537: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  max_open_warning, RuntimeWarning)
(332099, 2036) (35524, 2036)
C:\Users\dell-pc\Anaconda3.6\lib\site-packages\lightgbm\basic.py:1042: UserWarning: categorical_feature in Dataset is overridden. New categorical_feature is ['area', 'exchange', 'is_hs', 'market']
  warnings.warn('categorical_feature in Dataset is overridden. New categorical_feature is {}'.format(sorted(list(categorical_feature))))

--------------------Train network--------------------

 (332099, 2036) (332099,) {'fit': {'categorical_feature': ['area', 'market', 'exchange', 'is_hs']}, 'train_indexes': (0, None)}

----------Train layer 0----------
slice(0, None, None)

Train l2_y_l
[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves
[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves
Time usage: 341.37s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=0.1, max_depth=12, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=50,
       n_jobs=-1, num_leaves=31, objective=None, random_state=0,
       reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,
       subsample_for_bin=200000, subsample_freq=0)
                                    feature  importance_raw  \
2025                                 sz_vol             110
1865                               sz50_vol             106
1705                                 sh_vol              87
895                               hs300_vol              45
567                                     amt              44
732                                 cyb_vol              34
1526        p80mv_(20k_low/p20mv_20k_low-1)              26
1449  p600mv_(120k_low-120k_close)/120k_avg              22
454                          (high-low)/avg              21
1466        p60mv_(20k_low/p20mv_20k_low-1)              19
1268           p360mv_lower_shadow/120k_avg              17
1321        p40mv_(20k_avg/p20mv_20k_avg-1)              15
937      p100mv_(20k_open/p20mv_20k_open-1)              14
1241        p30mv_(10k_avg/p10mv_10k_avg-1)              14
1350           p480mv_lower_shadow/120k_avg              13
1457        p60mv_(20k_avg/p20mv_20k_avg-1)              13
1061       p180mv_(60k_amt/p60mv_60k_amt-1)              12
1480      p60mv_(60k_open/p60mv_60k_open-1)              11
1450   p600mv_(120k_low-120k_open)/120k_avg              11
1120       p20mv_(20k_low-20k_open)/20k_avg              11

      importance_percent
2025                7.33
1865                7.07
1705                5.80
895                 3.00
567                 2.93
732                 2.27
1526                1.73
1449                1.47
454                 1.40
1466                1.27
1268                1.13
1321                1.00
937                 0.93
1241                0.93
1350                0.87
1457                0.87
1061                0.80
1480                0.73
1450                0.73
1120                0.73
Among 2036 features, 1636 features are not used in the model

--------------------Predict--------------------

----------Layer 0 predicts----------

y_l_r
               count  eval_mean  eval_median  eval_std  eval_max  eval_min
pred_range
(-1.00,-0.95]      0        NaN          NaN       NaN       NaN       NaN
(-0.95,-0.90]      0        NaN          NaN       NaN       NaN       NaN
(-0.90,-0.85]      0        NaN          NaN       NaN       NaN       NaN
(-0.85,-0.80]      0        NaN          NaN       NaN       NaN       NaN
(-0.80,-0.75]      0        NaN          NaN       NaN       NaN       NaN
(-0.75,-0.70]      0        NaN          NaN       NaN       NaN       NaN
(-0.70,-0.65]      0        NaN          NaN       NaN       NaN       NaN
(-0.65,-0.60]      0        NaN          NaN       NaN       NaN       NaN
(-0.60,-0.55]      0        NaN          NaN       NaN       NaN       NaN
(-0.55,-0.50]      0        NaN          NaN       NaN       NaN       NaN
(-0.50,-0.45]      0        NaN          NaN       NaN       NaN       NaN
(-0.45,-0.40]      0        NaN          NaN       NaN       NaN       NaN
(-0.40,-0.35]      0        NaN          NaN       NaN       NaN       NaN
(-0.35,-0.30]      0        NaN          NaN       NaN       NaN       NaN
(-0.30,-0.25]      0        NaN          NaN       NaN       NaN       NaN
(-0.25,-0.20]      0        NaN          NaN       NaN       NaN       NaN
(-0.20,-0.15]      0        NaN          NaN       NaN       NaN       NaN
(-0.15,-0.10]      3      0.008       -0.066     0.138     0.167    -0.077
(-0.10,-0.05]     49     -0.069       -0.114     0.172     0.650    -0.300
(-0.05,0.00]    3576     -0.044       -0.070     0.123     0.726    -0.434
(0.00,0.05]    25324     -0.016       -0.046     0.124     0.924    -0.643
(0.05,0.10]     5054      0.013        0.046     0.153     1.178    -0.483
(0.10,0.15]     1121      0.047        0.090     0.185     0.977    -0.420
(0.15,0.20]      348      0.039        0.091     0.188     0.563    -0.366
(0.20,0.25]       44      0.062        0.131     0.201     0.330    -0.305
(0.25,0.30]        5      0.216        0.234     0.064     0.293     0.141
(0.30,0.35]        0        NaN          NaN       NaN       NaN       NaN
(0.35,0.40]        0        NaN          NaN       NaN       NaN       NaN
(0.40,0.45]        0        NaN          NaN       NaN       NaN       NaN
(0.45,0.50]        0        NaN          NaN       NaN       NaN       NaN
(0.50,0.55]        0        NaN          NaN       NaN       NaN       NaN
(0.55,0.60]        0        NaN          NaN       NaN       NaN       NaN
(0.60,0.65]        0        NaN          NaN       NaN       NaN       NaN
(0.65,0.70]        0        NaN          NaN       NaN       NaN       NaN
(0.70,0.75]        0        NaN          NaN       NaN       NaN       NaN
(0.75,0.80]        0        NaN          NaN       NaN       NaN       NaN
(0.80,0.85]        0        NaN          NaN       NaN       NaN       NaN
(0.85,0.90]        0        NaN          NaN       NaN       NaN       NaN
(0.90,0.95]        0        NaN          NaN       NaN       NaN       NaN
(0.95,1.00]        0        NaN          NaN       NaN       NaN       NaN

y_l
               count  eval_mean  eval_median  eval_std  eval_max  eval_min
pred_range
(-1.00,-0.95]      0        NaN          NaN       NaN       NaN       NaN
(-0.95,-0.90]      0        NaN          NaN       NaN       NaN       NaN
(-0.90,-0.85]      0        NaN          NaN       NaN       NaN       NaN
(-0.85,-0.80]      0        NaN          NaN       NaN       NaN       NaN
(-0.80,-0.75]      0        NaN          NaN       NaN       NaN       NaN
(-0.75,-0.70]      0        NaN          NaN       NaN       NaN       NaN
(-0.70,-0.65]      0        NaN          NaN       NaN       NaN       NaN
(-0.65,-0.60]      0        NaN          NaN       NaN       NaN       NaN
(-0.60,-0.55]      0        NaN          NaN       NaN       NaN       NaN
(-0.55,-0.50]      0        NaN          NaN       NaN       NaN       NaN
(-0.50,-0.45]      0        NaN          NaN       NaN       NaN       NaN
(-0.45,-0.40]      0        NaN          NaN       NaN       NaN       NaN
(-0.40,-0.35]      0        NaN          NaN       NaN       NaN       NaN
(-0.35,-0.30]      0        NaN          NaN       NaN       NaN       NaN
(-0.30,-0.25]      0        NaN          NaN       NaN       NaN       NaN
(-0.25,-0.20]      0        NaN          NaN       NaN       NaN       NaN
(-0.20,-0.15]      0        NaN          NaN       NaN       NaN       NaN
(-0.15,-0.10]      3      0.008       -0.079     0.159     0.191    -0.090
(-0.10,-0.05]     49     -0.078       -0.138     0.202     0.765    -0.333
(-0.05,0.00]    3576     -0.056       -0.090     0.142     0.813    -0.463
(0.00,0.05]    25324     -0.024       -0.065     0.144     1.018    -0.670
(0.05,0.10]     5054      0.008       -0.048     0.181     1.328    -0.534
(0.10,0.15]     1121      0.046        0.106     0.220     1.062    -0.467
(0.15,0.20]      348      0.044        0.114     0.222     0.630    -0.409
(0.20,0.25]       44      0.069        0.165     0.243     0.382    -0.361
(0.25,0.30]        5      0.253        0.266     0.068     0.334     0.167
(0.30,0.35]        0        NaN          NaN       NaN       NaN       NaN
(0.35,0.40]        0        NaN          NaN       NaN       NaN       NaN
(0.40,0.45]        0        NaN          NaN       NaN       NaN       NaN
(0.45,0.50]        0        NaN          NaN       NaN       NaN       NaN
(0.50,0.55]        0        NaN          NaN       NaN       NaN       NaN
(0.55,0.60]        0        NaN          NaN       NaN       NaN       NaN
(0.60,0.65]        0        NaN          NaN       NaN       NaN       NaN
(0.65,0.70]        0        NaN          NaN       NaN       NaN       NaN
(0.70,0.75]        0        NaN          NaN       NaN       NaN       NaN
(0.75,0.80]        0        NaN          NaN       NaN       NaN       NaN
(0.80,0.85]        0        NaN          NaN       NaN       NaN       NaN
(0.85,0.90]        0        NaN          NaN       NaN       NaN       NaN
(0.90,0.95]        0        NaN          NaN       NaN       NaN       NaN
(0.95,1.00]        0        NaN          NaN       NaN       NaN       NaN

y_l_avg
               count  eval_mean  eval_median  eval_std  eval_max  eval_min
pred_range
(-1.00,-0.95]      0        NaN          NaN       NaN       NaN       NaN
(-0.95,-0.90]      0        NaN          NaN       NaN       NaN       NaN
(-0.90,-0.85]      0        NaN          NaN       NaN       NaN       NaN
(-0.85,-0.80]      0        NaN          NaN       NaN       NaN       NaN
(-0.80,-0.75]      0        NaN          NaN       NaN       NaN       NaN
(-0.75,-0.70]      0        NaN          NaN       NaN       NaN       NaN
(-0.70,-0.65]      0        NaN          NaN       NaN       NaN       NaN
(-0.65,-0.60]      0        NaN          NaN       NaN       NaN       NaN
(-0.60,-0.55]      0        NaN          NaN       NaN       NaN       NaN
(-0.55,-0.50]      0        NaN          NaN       NaN       NaN       NaN
(-0.50,-0.45]      0        NaN          NaN       NaN       NaN       NaN
(-0.45,-0.40]      0        NaN          NaN       NaN       NaN       NaN
(-0.40,-0.35]      0        NaN          NaN       NaN       NaN       NaN
(-0.35,-0.30]      0        NaN          NaN       NaN       NaN       NaN
(-0.30,-0.25]      0        NaN          NaN       NaN       NaN       NaN
(-0.25,-0.20]      0        NaN          NaN       NaN       NaN       NaN
(-0.20,-0.15]      0        NaN          NaN       NaN       NaN       NaN
(-0.15,-0.10]      3      0.008       -0.030     0.074     0.093    -0.039
(-0.10,-0.05]     49     -0.041       -0.050     0.090     0.305    -0.226
(-0.05,0.00]    3576     -0.022       -0.019     0.067     0.472    -0.356
(0.00,0.05]    25324     -0.007       -0.006     0.065     0.660    -0.564
(0.05,0.10]     5054      0.009        0.003     0.080     0.730    -0.329
(0.10,0.15]     1121      0.024        0.019     0.098     0.722    -0.278
(0.15,0.20]      348      0.020        0.011     0.093     0.363    -0.246
(0.20,0.25]       44      0.038        0.044     0.091     0.186    -0.173
(0.25,0.30]        5      0.106        0.123     0.055     0.169     0.037
(0.30,0.35]        0        NaN          NaN       NaN       NaN       NaN
(0.35,0.40]        0        NaN          NaN       NaN       NaN       NaN
(0.40,0.45]        0        NaN          NaN       NaN       NaN       NaN
(0.45,0.50]        0        NaN          NaN       NaN       NaN       NaN
(0.50,0.55]        0        NaN          NaN       NaN       NaN       NaN
(0.55,0.60]        0        NaN          NaN       NaN       NaN       NaN
(0.60,0.65]        0        NaN          NaN       NaN       NaN       NaN
(0.65,0.70]        0        NaN          NaN       NaN       NaN       NaN
(0.70,0.75]        0        NaN          NaN       NaN       NaN       NaN
(0.75,0.80]        0        NaN          NaN       NaN       NaN       NaN
(0.80,0.85]        0        NaN          NaN       NaN       NaN       NaN
(0.85,0.90]        0        NaN          NaN       NaN       NaN       NaN
(0.90,0.95]        0        NaN          NaN       NaN       NaN       NaN
(0.95,1.00]        0        NaN          NaN       NaN       NaN       NaN

y_l_rise
               count  eval_mean  eval_median  eval_std  eval_max  eval_min
pred_range
(-1.00,-0.95]      0        NaN          NaN       NaN       NaN       NaN
(-0.95,-0.90]      0        NaN          NaN       NaN       NaN       NaN
(-0.90,-0.85]      0        NaN          NaN       NaN       NaN       NaN
(-0.85,-0.80]      0        NaN          NaN       NaN       NaN       NaN
(-0.80,-0.75]      0        NaN          NaN       NaN       NaN       NaN
(-0.75,-0.70]      0        NaN          NaN       NaN       NaN       NaN
(-0.70,-0.65]      0        NaN          NaN       NaN       NaN       NaN
(-0.65,-0.60]      0        NaN          NaN       NaN       NaN       NaN
(-0.60,-0.55]      0        NaN          NaN       NaN       NaN       NaN
(-0.55,-0.50]      0        NaN          NaN       NaN       NaN       NaN
(-0.50,-0.45]      0        NaN          NaN       NaN       NaN       NaN
(-0.45,-0.40]      0        NaN          NaN       NaN       NaN       NaN
(-0.40,-0.35]      0        NaN          NaN       NaN       NaN       NaN
(-0.35,-0.30]      0        NaN          NaN       NaN       NaN       NaN
(-0.30,-0.25]      0        NaN          NaN       NaN       NaN       NaN
(-0.25,-0.20]      0        NaN          NaN       NaN       NaN       NaN
(-0.20,-0.15]      0        NaN          NaN       NaN       NaN       NaN
(-0.15,-0.10]      3      0.084        0.035     0.093     0.191     0.026
(-0.10,-0.05]     49      0.074        0.035     0.126     0.765     0.000
(-0.05,0.00]    3576      0.058        0.038     0.068     0.813     0.000
(0.00,0.05]    25324      0.071        0.051     0.072     1.018     0.000
(0.05,0.10]     5054      0.106        0.082     0.098     1.328     0.000
(0.10,0.15]     1121      0.146        0.117     0.122     1.062     0.000
(0.15,0.20]      348      0.152        0.128     0.119     0.630     0.000
(0.20,0.25]       44      0.182        0.168     0.107     0.382     0.012
(0.25,0.30]        5      0.253        0.266     0.068     0.334     0.167
(0.30,0.35]        0        NaN          NaN       NaN       NaN       NaN
(0.35,0.40]        0        NaN          NaN       NaN       NaN       NaN
(0.40,0.45]        0        NaN          NaN       NaN       NaN       NaN
(0.45,0.50]        0        NaN          NaN       NaN       NaN       NaN
(0.50,0.55]        0        NaN          NaN       NaN       NaN       NaN
(0.55,0.60]        0        NaN          NaN       NaN       NaN       NaN
(0.60,0.65]        0        NaN          NaN       NaN       NaN       NaN
(0.65,0.70]        0        NaN          NaN       NaN       NaN       NaN
(0.70,0.75]        0        NaN          NaN       NaN       NaN       NaN
(0.75,0.80]        0        NaN          NaN       NaN       NaN       NaN
(0.80,0.85]        0        NaN          NaN       NaN       NaN       NaN
(0.85,0.90]        0        NaN          NaN       NaN       NaN       NaN
(0.90,0.95]        0        NaN          NaN       NaN       NaN       NaN
(0.95,1.00]        0        NaN          NaN       NaN       NaN       NaN












----------------
C:\Users\dell-pc\Anaconda3.6\python.exe C:/Users/dell-pc/Quant/Quant/ml_model.py
2013-01-01 2018-12-31
Time slice keys in hdf5: 2013/0101-0101,2014/0101-0101,2015/0101-0101,2016/0101-0101,2017/0101-0101,2018/0101-0101

Current key: 2013/0101-0101
Current slice size(length): 278061
Current subsample size(length): 55612

Current key: 2014/0101-0101
Current slice size(length): 291574
Current subsample size(length): 58314

Current key: 2015/0101-0101
Current slice size(length): 304680
Current subsample size(length): 60936

Current key: 2016/0101-0101
Current slice size(length): 313767
Current subsample size(length): 62753

Current key: 2017/0101-0101
Current slice size(length): 333371
Current subsample size(length): 66674

Current key: 2018/0101-0101
Current slice size(length): 347712
Current subsample size(length): 69542

Total concatenating size: 373831
Result dataset size: 373831
<class 'pandas.core.frame.DataFrame'>
Int64Index: 373831 entries, 20130607 to 20180925
Columns: 2037 entries, (10MA/20MA-1) to vol0
dtypes: float16(1987), float64(44), int64(1), uint8(5)
memory usage: 1.5 GB
None
(185, 8)
          y_l_rise  y_l_decline  y_l_avg  y_s_rise  y_s_decline  y_s_avg  y_l  \
date
20161202       0.0          0.0      NaN       0.0          0.0      NaN  0.0
20161216       0.0          0.0      NaN       0.0          0.0      NaN  0.0
20161121       0.0          0.0      NaN       0.0          0.0      NaN  0.0
20161208       0.0          0.0      NaN       0.0          0.0      NaN  0.0
20161205       0.0          0.0      NaN       0.0          0.0      NaN  0.0
20161025       0.0          0.0      NaN       0.0          0.0      NaN  0.0
20161103       0.0          0.0      NaN       0.0          0.0      NaN  0.0
20161111       0.0          0.0      NaN       0.0          0.0      NaN  0.0
20161026       0.0          0.0      NaN       0.0          0.0      NaN  0.0
20161108       0.0          0.0      NaN       0.0          0.0      NaN  0.0
20161125       0.0          0.0      NaN       0.0          0.0      NaN  0.0
20161010       0.0          0.0      NaN       0.0          0.0      NaN  0.0
20161027       0.0          0.0      NaN       0.0          0.0      NaN  0.0
20161128       0.0          0.0      NaN       0.0          0.0      NaN  0.0
20161117       0.0          0.0      NaN       0.0          0.0      NaN  0.0
20161102       0.0          0.0      NaN       0.0          0.0      NaN  0.0
20161102       0.0          0.0      NaN       0.0          0.0      NaN  0.0
20160927       0.0          0.0      NaN       0.0          0.0      NaN  0.0
20161214       0.0          0.0      NaN       0.0          0.0      NaN  0.0
20160926       0.0          0.0      NaN       0.0          0.0      NaN  0.0

          y_l_r
date
20161202    NaN
20161216    NaN
20161121    NaN
20161208    NaN
20161205    NaN
20161025    NaN
20161103    NaN
20161111    NaN
20161026    NaN
20161108    NaN
20161125    NaN
20161010    NaN
20161027    NaN
20161128    NaN
20161117    NaN
20161102    NaN
20161102    NaN
20160927    NaN
20161214    NaN
20160926    NaN

test period:20160701-20170101
(200091, 2036) (32118, 2036)

--------------------Train network--------------------

 (200091, 2036) (200091,) {'fit': {'categorical_feature': ['area', 'market', 'exchange', 'is_hs']}, 'train_indexes': (0, None)}

----------Train layer 0----------
slice(0, None, None)

Train l2_y_l
C:\Users\dell-pc\Anaconda3.6\lib\site-packages\lightgbm\basic.py:1042: UserWarning: categorical_feature in Dataset is overridden. New categorical_feature is ['area', 'exchange', 'is_hs', 'market']
  warnings.warn('categorical_feature in Dataset is overridden. New categorical_feature is {}'.format(sorted(list(categorical_feature))))
[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves
[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves
Time usage: 170.96s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=0.1, max_depth=12, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=50,
       n_jobs=-1, num_leaves=31, objective=None, random_state=0,
       reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,
       subsample_for_bin=200000, subsample_freq=0)
                                    feature  importance_raw  \
2025                                 sz_vol             114
1865                               sz50_vol             109
1705                                 sh_vol              82
567                                     amt              45
895                               hs300_vol              40
1526        p80mv_(20k_low/p20mv_20k_low-1)              26
732                                 cyb_vol              23
454                          (high-low)/avg              22
1466        p60mv_(20k_low/p20mv_20k_low-1)              22
1457        p60mv_(20k_avg/p20mv_20k_avg-1)              18
1449  p600mv_(120k_low-120k_close)/120k_avg              17
1350           p480mv_lower_shadow/120k_avg              17
1120       p20mv_(20k_low-20k_open)/20k_avg              16
1241        p30mv_(10k_avg/p10mv_10k_avg-1)              15
1268           p360mv_lower_shadow/120k_avg              14
453                        (high-close)/avg              14
1238            p300mv_lower_shadow/60k_avg              13
986     p120mv_(60k_close-60k_open)/60k_avg              12
2035                                   vol0              12
1235       p300mv_(60k_low/p60mv_60k_low-1)              11

      importance_percent
2025                7.60
1865                7.27
1705                5.47
567                 3.00
895                 2.67
1526                1.73
732                 1.53
454                 1.47
1466                1.47
1457                1.20
1449                1.13
1350                1.13
1120                1.07
1241                1.00
1268                0.93
453                 0.93
1238                0.87
986                 0.80
2035                0.80
1235                0.73
Among 2036 features, 1624 features are not used in the model

--------------------Predict--------------------

----------Layer 0 predicts----------

y_l_r
               count  eval_mean  eval_median  eval_std  eval_max  eval_min
pred_range
(-1.00,-0.95]      0        NaN          NaN       NaN       NaN       NaN
(-0.95,-0.90]      0        NaN          NaN       NaN       NaN       NaN
(-0.90,-0.85]      0        NaN          NaN       NaN       NaN       NaN
(-0.85,-0.80]      0        NaN          NaN       NaN       NaN       NaN
(-0.80,-0.75]      0        NaN          NaN       NaN       NaN       NaN
(-0.75,-0.70]      0        NaN          NaN       NaN       NaN       NaN
(-0.70,-0.65]      0        NaN          NaN       NaN       NaN       NaN
(-0.65,-0.60]      0        NaN          NaN       NaN       NaN       NaN
(-0.60,-0.55]      0        NaN          NaN       NaN       NaN       NaN
(-0.55,-0.50]      0        NaN          NaN       NaN       NaN       NaN
(-0.50,-0.45]      0        NaN          NaN       NaN       NaN       NaN
(-0.45,-0.40]      0        NaN          NaN       NaN       NaN       NaN
(-0.40,-0.35]      0        NaN          NaN       NaN       NaN       NaN
(-0.35,-0.30]      0        NaN          NaN       NaN       NaN       NaN
(-0.30,-0.25]      0        NaN          NaN       NaN       NaN       NaN
(-0.25,-0.20]      0        NaN          NaN       NaN       NaN       NaN
(-0.20,-0.15]      6     -0.107       -0.125     0.108     0.076    -0.206
(-0.15,-0.10]     59     -0.061       -0.096     0.123     0.204    -0.264
(-0.10,-0.05]    860     -0.013       -0.054     0.115     0.599    -0.294
(-0.05,0.00]    6235      0.013        0.000     0.102     0.858    -0.309
(0.00,0.05]    16726      0.017        0.022     0.099     1.046    -0.341
(0.05,0.10]     6494      0.012        0.025     0.114     1.063    -0.332
(0.10,0.15]     1258     -0.024       -0.060     0.114     0.607    -0.299
(0.15,0.20]      375     -0.035       -0.064     0.103     0.368    -0.299
(0.20,0.25]       74     -0.034       -0.067     0.122     0.310    -0.223
(0.25,0.30]       28     -0.011       -0.079     0.131     0.222    -0.212
(0.30,0.35]        3     -0.151       -0.143     0.031    -0.125    -0.185
(0.35,0.40]        0        NaN          NaN       NaN       NaN       NaN
(0.40,0.45]        0        NaN          NaN       NaN       NaN       NaN
(0.45,0.50]        0        NaN          NaN       NaN       NaN       NaN
(0.50,0.55]        0        NaN          NaN       NaN       NaN       NaN
(0.55,0.60]        0        NaN          NaN       NaN       NaN       NaN
(0.60,0.65]        0        NaN          NaN       NaN       NaN       NaN
(0.65,0.70]        0        NaN          NaN       NaN       NaN       NaN
(0.70,0.75]        0        NaN          NaN       NaN       NaN       NaN
(0.75,0.80]        0        NaN          NaN       NaN       NaN       NaN
(0.80,0.85]        0        NaN          NaN       NaN       NaN       NaN
(0.85,0.90]        0        NaN          NaN       NaN       NaN       NaN
(0.90,0.95]        0        NaN          NaN       NaN       NaN       NaN
(0.95,1.00]        0        NaN          NaN       NaN       NaN       NaN

y_l
               count  eval_mean  eval_median  eval_std  eval_max  eval_min
pred_range
(-1.00,-0.95]      0        NaN          NaN       NaN       NaN       NaN
(-0.95,-0.90]      0        NaN          NaN       NaN       NaN       NaN
(-0.90,-0.85]      0        NaN          NaN       NaN       NaN       NaN
(-0.85,-0.80]      0        NaN          NaN       NaN       NaN       NaN
(-0.80,-0.75]      0        NaN          NaN       NaN       NaN       NaN
(-0.75,-0.70]      0        NaN          NaN       NaN       NaN       NaN
(-0.70,-0.65]      0        NaN          NaN       NaN       NaN       NaN
(-0.65,-0.60]      0        NaN          NaN       NaN       NaN       NaN
(-0.60,-0.55]      0        NaN          NaN       NaN       NaN       NaN
(-0.55,-0.50]      0        NaN          NaN       NaN       NaN       NaN
(-0.50,-0.45]      0        NaN          NaN       NaN       NaN       NaN
(-0.45,-0.40]      0        NaN          NaN       NaN       NaN       NaN
(-0.40,-0.35]      0        NaN          NaN       NaN       NaN       NaN
(-0.35,-0.30]      0        NaN          NaN       NaN       NaN       NaN
(-0.30,-0.25]      0        NaN          NaN       NaN       NaN       NaN
(-0.25,-0.20]      0        NaN          NaN       NaN       NaN       NaN
(-0.20,-0.15]      6     -0.125       -0.150     0.129     0.096    -0.239
(-0.15,-0.10]     59     -0.071       -0.118     0.145     0.248    -0.300
(-0.10,-0.05]    860     -0.019       -0.073     0.136     0.689    -0.337
(-0.05,0.00]    6235      0.013        0.000     0.120     0.956    -0.334
(0.00,0.05]    16726      0.018        0.000     0.117     1.274    -0.393
(0.05,0.10]     6494      0.011        0.026     0.134     1.213    -0.372
(0.10,0.15]     1258     -0.029       -0.073     0.134     0.692    -0.341
(0.15,0.20]      375     -0.043       -0.077     0.121     0.430    -0.338
(0.20,0.25]       74     -0.033       -0.079     0.145     0.376    -0.240
(0.25,0.30]       28     -0.017       -0.095     0.154     0.263    -0.239
(0.30,0.35]        3     -0.174       -0.165     0.032    -0.148    -0.209
(0.35,0.40]        0        NaN          NaN       NaN       NaN       NaN
(0.40,0.45]        0        NaN          NaN       NaN       NaN       NaN
(0.45,0.50]        0        NaN          NaN       NaN       NaN       NaN
(0.50,0.55]        0        NaN          NaN       NaN       NaN       NaN
(0.55,0.60]        0        NaN          NaN       NaN       NaN       NaN
(0.60,0.65]        0        NaN          NaN       NaN       NaN       NaN
(0.65,0.70]        0        NaN          NaN       NaN       NaN       NaN
(0.70,0.75]        0        NaN          NaN       NaN       NaN       NaN
(0.75,0.80]        0        NaN          NaN       NaN       NaN       NaN
(0.80,0.85]        0        NaN          NaN       NaN       NaN       NaN
(0.85,0.90]        0        NaN          NaN       NaN       NaN       NaN
(0.90,0.95]        0        NaN          NaN       NaN       NaN       NaN
(0.95,1.00]        0        NaN          NaN       NaN       NaN       NaN

y_l_avg
               count  eval_mean  eval_median  eval_std  eval_max  eval_min
pred_range
(-1.00,-0.95]      0        NaN          NaN       NaN       NaN       NaN
(-0.95,-0.90]      0        NaN          NaN       NaN       NaN       NaN
(-0.90,-0.85]      0        NaN          NaN       NaN       NaN       NaN
(-0.85,-0.80]      0        NaN          NaN       NaN       NaN       NaN
(-0.80,-0.75]      0        NaN          NaN       NaN       NaN       NaN
(-0.75,-0.70]      0        NaN          NaN       NaN       NaN       NaN
(-0.70,-0.65]      0        NaN          NaN       NaN       NaN       NaN
(-0.65,-0.60]      0        NaN          NaN       NaN       NaN       NaN
(-0.60,-0.55]      0        NaN          NaN       NaN       NaN       NaN
(-0.55,-0.50]      0        NaN          NaN       NaN       NaN       NaN
(-0.50,-0.45]      0        NaN          NaN       NaN       NaN       NaN
(-0.45,-0.40]      0        NaN          NaN       NaN       NaN       NaN
(-0.40,-0.35]      0        NaN          NaN       NaN       NaN       NaN
(-0.35,-0.30]      0        NaN          NaN       NaN       NaN       NaN
(-0.30,-0.25]      0        NaN          NaN       NaN       NaN       NaN
(-0.25,-0.20]      0        NaN          NaN       NaN       NaN       NaN
(-0.20,-0.15]      6     -0.054       -0.050     0.046     0.013    -0.108
(-0.15,-0.10]     59     -0.030       -0.032     0.059     0.094    -0.155
(-0.10,-0.05]    860     -0.005       -0.010     0.056     0.329    -0.165
(-0.05,0.00]    6235      0.007        0.000     0.051     0.564    -0.234
(0.00,0.05]    16726      0.010        0.001     0.050     0.550    -0.195
(0.05,0.10]     6494      0.007        0.001     0.058     0.613    -0.230
(0.10,0.15]     1258     -0.012       -0.020     0.059     0.359    -0.182
(0.15,0.20]      375     -0.018       -0.020     0.052     0.180    -0.184
(0.20,0.25]       74     -0.021       -0.022     0.061     0.141    -0.173
(0.25,0.30]       28     -0.010       -0.028     0.061     0.101    -0.133
(0.30,0.35]        3     -0.082       -0.075     0.028    -0.058    -0.113
(0.35,0.40]        0        NaN          NaN       NaN       NaN       NaN
(0.40,0.45]        0        NaN          NaN       NaN       NaN       NaN
(0.45,0.50]        0        NaN          NaN       NaN       NaN       NaN
(0.50,0.55]        0        NaN          NaN       NaN       NaN       NaN
(0.55,0.60]        0        NaN          NaN       NaN       NaN       NaN
(0.60,0.65]        0        NaN          NaN       NaN       NaN       NaN
(0.65,0.70]        0        NaN          NaN       NaN       NaN       NaN
(0.70,0.75]        0        NaN          NaN       NaN       NaN       NaN
(0.75,0.80]        0        NaN          NaN       NaN       NaN       NaN
(0.80,0.85]        0        NaN          NaN       NaN       NaN       NaN
(0.85,0.90]        0        NaN          NaN       NaN       NaN       NaN
(0.90,0.95]        0        NaN          NaN       NaN       NaN       NaN
(0.95,1.00]        0        NaN          NaN       NaN       NaN       NaN

y_l_rise
               count  eval_mean  eval_median  eval_std  eval_max  eval_min
pred_range
(-1.00,-0.95]      0        NaN          NaN       NaN       NaN       NaN
(-0.95,-0.90]      0        NaN          NaN       NaN       NaN       NaN
(-0.90,-0.85]      0        NaN          NaN       NaN       NaN       NaN
(-0.85,-0.80]      0        NaN          NaN       NaN       NaN       NaN
(-0.80,-0.75]      0        NaN          NaN       NaN       NaN       NaN
(-0.75,-0.70]      0        NaN          NaN       NaN       NaN       NaN
(-0.70,-0.65]      0        NaN          NaN       NaN       NaN       NaN
(-0.65,-0.60]      0        NaN          NaN       NaN       NaN       NaN
(-0.60,-0.55]      0        NaN          NaN       NaN       NaN       NaN
(-0.55,-0.50]      0        NaN          NaN       NaN       NaN       NaN
(-0.50,-0.45]      0        NaN          NaN       NaN       NaN       NaN
(-0.45,-0.40]      0        NaN          NaN       NaN       NaN       NaN
(-0.40,-0.35]      0        NaN          NaN       NaN       NaN       NaN
(-0.35,-0.30]      0        NaN          NaN       NaN       NaN       NaN
(-0.30,-0.25]      0        NaN          NaN       NaN       NaN       NaN
(-0.25,-0.20]      0        NaN          NaN       NaN       NaN       NaN
(-0.20,-0.15]      6      0.044        0.041     0.032     0.096     0.006
(-0.15,-0.10]     59      0.060        0.040     0.061     0.248     0.000
(-0.10,-0.05]    860      0.071        0.050     0.075     0.689     0.000
(-0.05,0.00]    6235      0.069        0.049     0.074     0.956     0.000
(0.00,0.05]    16726      0.067        0.047     0.075     1.274     0.000
(0.05,0.10]     6494      0.075        0.053     0.083     1.213     0.000
(0.10,0.15]     1258      0.062        0.038     0.076     0.692     0.000
(0.15,0.20]      375      0.057        0.038     0.060     0.430     0.000
(0.20,0.25]       74      0.065        0.041     0.075     0.376     0.000
(0.25,0.30]       28      0.084        0.063     0.076     0.263     0.000
(0.30,0.35]        3      0.039        0.027     0.038     0.082     0.008
(0.35,0.40]        0        NaN          NaN       NaN       NaN       NaN
(0.40,0.45]        0        NaN          NaN       NaN       NaN       NaN
(0.45,0.50]        0        NaN          NaN       NaN       NaN       NaN
(0.50,0.55]        0        NaN          NaN       NaN       NaN       NaN
(0.55,0.60]        0        NaN          NaN       NaN       NaN       NaN
(0.60,0.65]        0        NaN          NaN       NaN       NaN       NaN
(0.65,0.70]        0        NaN          NaN       NaN       NaN       NaN
(0.70,0.75]        0        NaN          NaN       NaN       NaN       NaN
(0.75,0.80]        0        NaN          NaN       NaN       NaN       NaN
(0.80,0.85]        0        NaN          NaN       NaN       NaN       NaN
(0.85,0.90]        0        NaN          NaN       NaN       NaN       NaN
(0.90,0.95]        0        NaN          NaN       NaN       NaN       NaN
(0.95,1.00]        0        NaN          NaN       NaN       NaN       NaN

test period:20170101-20170701
(232010, 2036) (31925, 2036)

--------------------Train network--------------------

 (232010, 2036) (232010,) {'fit': {'categorical_feature': ['area', 'market', 'exchange', 'is_hs']}, 'train_indexes': (0, None)}

----------Train layer 0----------
slice(0, None, None)

Train l2_y_l
C:\Users\dell-pc\Anaconda3.6\lib\site-packages\lightgbm\basic.py:1042: UserWarning: categorical_feature in Dataset is overridden. New categorical_feature is ['area', 'exchange', 'is_hs', 'market']
  warnings.warn('categorical_feature in Dataset is overridden. New categorical_feature is {}'.format(sorted(list(categorical_feature))))
[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves
[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves
Time usage: 180.42s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=0.1, max_depth=12, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=50,
       n_jobs=-1, num_leaves=31, objective=None, random_state=0,
       reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,
       subsample_for_bin=200000, subsample_freq=0)
                                    feature  importance_raw  \
1865                               sz50_vol             123
1705                                 sh_vol              96
2025                                 sz_vol              81
567                                     amt              45
895                               hs300_vol              45
454                          (high-low)/avg              28
1526        p80mv_(20k_low/p20mv_20k_low-1)              26
732                                 cyb_vol              25
1449  p600mv_(120k_low-120k_close)/120k_avg              17
1466        p60mv_(20k_low/p20mv_20k_low-1)              17
1241        p30mv_(10k_avg/p10mv_10k_avg-1)              17
1268           p360mv_lower_shadow/120k_avg              15
1457        p60mv_(20k_avg/p20mv_20k_avg-1)              15
453                        (high-close)/avg              13
927        p100mv_(20k_avg/p20mv_20k_avg-1)              12
1061       p180mv_(60k_amt/p60mv_60k_amt-1)              11
1350           p480mv_lower_shadow/120k_avg              11
1120       p20mv_(20k_low-20k_open)/20k_avg              10
1235       p300mv_(60k_low/p60mv_60k_low-1)              10
1347    p480mv_(120k_low/p120mv_120k_low-1)              10

      importance_percent
1865                8.20
1705                6.40
2025                5.40
567                 3.00
895                 3.00
454                 1.87
1526                1.73
732                 1.67
1449                1.13
1466                1.13
1241                1.13
1268                1.00
1457                1.00
453                 0.87
927                 0.80
1061                0.73
1350                0.73
1120                0.67
1235                0.67
1347                0.67
Among 2036 features, 1614 features are not used in the model

--------------------Predict--------------------

----------Layer 0 predicts----------

y_l_r
               count  eval_mean  eval_median  eval_std  eval_max  eval_min
pred_range
(-1.00,-0.95]      0        NaN          NaN       NaN       NaN       NaN
(-0.95,-0.90]      0        NaN          NaN       NaN       NaN       NaN
(-0.90,-0.85]      0        NaN          NaN       NaN       NaN       NaN
(-0.85,-0.80]      0        NaN          NaN       NaN       NaN       NaN
(-0.80,-0.75]      0        NaN          NaN       NaN       NaN       NaN
(-0.75,-0.70]      0        NaN          NaN       NaN       NaN       NaN
(-0.70,-0.65]      0        NaN          NaN       NaN       NaN       NaN
(-0.65,-0.60]      0        NaN          NaN       NaN       NaN       NaN
(-0.60,-0.55]      0        NaN          NaN       NaN       NaN       NaN
(-0.55,-0.50]      0        NaN          NaN       NaN       NaN       NaN
(-0.50,-0.45]      0        NaN          NaN       NaN       NaN       NaN
(-0.45,-0.40]      0        NaN          NaN       NaN       NaN       NaN
(-0.40,-0.35]      0        NaN          NaN       NaN       NaN       NaN
(-0.35,-0.30]      0        NaN          NaN       NaN       NaN       NaN
(-0.30,-0.25]      0        NaN          NaN       NaN       NaN       NaN
(-0.25,-0.20]      0        NaN          NaN       NaN       NaN       NaN
(-0.20,-0.15]      0        NaN          NaN       NaN       NaN       NaN
(-0.15,-0.10]      0        NaN          NaN       NaN       NaN       NaN
(-0.10,-0.05]     20     -0.057       -0.071     0.110     0.161    -0.211
(-0.05,0.00]     907     -0.016        0.000     0.128     0.918    -0.337
(0.00,0.05]    14386      0.000        0.000     0.114     1.054    -0.454
(0.05,0.10]    16036      0.020        0.040     0.114     1.219    -0.444
(0.10,0.15]      526      0.053        0.071     0.127     1.022    -0.230
(0.15,0.20]       37      0.062        0.103     0.173     0.507    -0.187
(0.20,0.25]       11      0.038       -0.049     0.201     0.457    -0.150
(0.25,0.30]        1     -0.150       -0.150       NaN    -0.150    -0.150
(0.30,0.35]        1      0.152        0.152       NaN     0.152     0.152
(0.35,0.40]        0        NaN          NaN       NaN       NaN       NaN
(0.40,0.45]        0        NaN          NaN       NaN       NaN       NaN
(0.45,0.50]        0        NaN          NaN       NaN       NaN       NaN
(0.50,0.55]        0        NaN          NaN       NaN       NaN       NaN
(0.55,0.60]        0        NaN          NaN       NaN       NaN       NaN
(0.60,0.65]        0        NaN          NaN       NaN       NaN       NaN
(0.65,0.70]        0        NaN          NaN       NaN       NaN       NaN
(0.70,0.75]        0        NaN          NaN       NaN       NaN       NaN
(0.75,0.80]        0        NaN          NaN       NaN       NaN       NaN
(0.80,0.85]        0        NaN          NaN       NaN       NaN       NaN
(0.85,0.90]        0        NaN          NaN       NaN       NaN       NaN
(0.90,0.95]        0        NaN          NaN       NaN       NaN       NaN
(0.95,1.00]        0        NaN          NaN       NaN       NaN       NaN

y_l
               count  eval_mean  eval_median  eval_std  eval_max  eval_min
pred_range
(-1.00,-0.95]      0        NaN          NaN       NaN       NaN       NaN
(-0.95,-0.90]      0        NaN          NaN       NaN       NaN       NaN
(-0.90,-0.85]      0        NaN          NaN       NaN       NaN       NaN
(-0.85,-0.80]      0        NaN          NaN       NaN       NaN       NaN
(-0.80,-0.75]      0        NaN          NaN       NaN       NaN       NaN
(-0.75,-0.70]      0        NaN          NaN       NaN       NaN       NaN
(-0.70,-0.65]      0        NaN          NaN       NaN       NaN       NaN
(-0.65,-0.60]      0        NaN          NaN       NaN       NaN       NaN
(-0.60,-0.55]      0        NaN          NaN       NaN       NaN       NaN
(-0.55,-0.50]      0        NaN          NaN       NaN       NaN       NaN
(-0.50,-0.45]      0        NaN          NaN       NaN       NaN       NaN
(-0.45,-0.40]      0        NaN          NaN       NaN       NaN       NaN
(-0.40,-0.35]      0        NaN          NaN       NaN       NaN       NaN
(-0.35,-0.30]      0        NaN          NaN       NaN       NaN       NaN
(-0.30,-0.25]      0        NaN          NaN       NaN       NaN       NaN
(-0.25,-0.20]      0        NaN          NaN       NaN       NaN       NaN
(-0.20,-0.15]      0        NaN          NaN       NaN       NaN       NaN
(-0.15,-0.10]      0        NaN          NaN       NaN       NaN       NaN
(-0.10,-0.05]     20     -0.074       -0.089     0.129     0.200    -0.253
(-0.05,0.00]     907     -0.022        0.000     0.150     1.061    -0.408
(0.00,0.05]    14386     -0.004        0.000     0.134     1.241    -0.491
(0.05,0.10]    16036      0.019        0.045     0.134     1.303    -0.466
(0.10,0.15]      526      0.059        0.083     0.149     1.130    -0.274
(0.15,0.20]       37      0.069        0.125     0.199     0.551    -0.229
(0.20,0.25]       11      0.038       -0.060     0.234     0.527    -0.170
(0.25,0.30]        1     -0.181       -0.181       NaN    -0.181    -0.181
(0.30,0.35]        1      0.171        0.171       NaN     0.171     0.171
(0.35,0.40]        0        NaN          NaN       NaN       NaN       NaN
(0.40,0.45]        0        NaN          NaN       NaN       NaN       NaN
(0.45,0.50]        0        NaN          NaN       NaN       NaN       NaN
(0.50,0.55]        0        NaN          NaN       NaN       NaN       NaN
(0.55,0.60]        0        NaN          NaN       NaN       NaN       NaN
(0.60,0.65]        0        NaN          NaN       NaN       NaN       NaN
(0.65,0.70]        0        NaN          NaN       NaN       NaN       NaN
(0.70,0.75]        0        NaN          NaN       NaN       NaN       NaN
(0.75,0.80]        0        NaN          NaN       NaN       NaN       NaN
(0.80,0.85]        0        NaN          NaN       NaN       NaN       NaN
(0.85,0.90]        0        NaN          NaN       NaN       NaN       NaN
(0.90,0.95]        0        NaN          NaN       NaN       NaN       NaN
(0.95,1.00]        0        NaN          NaN       NaN       NaN       NaN

y_l_avg
               count  eval_mean  eval_median  eval_std  eval_max  eval_min
pred_range
(-1.00,-0.95]      0        NaN          NaN       NaN       NaN       NaN
(-0.95,-0.90]      0        NaN          NaN       NaN       NaN       NaN
(-0.90,-0.85]      0        NaN          NaN       NaN       NaN       NaN
(-0.85,-0.80]      0        NaN          NaN       NaN       NaN       NaN
(-0.80,-0.75]      0        NaN          NaN       NaN       NaN       NaN
(-0.75,-0.70]      0        NaN          NaN       NaN       NaN       NaN
(-0.70,-0.65]      0        NaN          NaN       NaN       NaN       NaN
(-0.65,-0.60]      0        NaN          NaN       NaN       NaN       NaN
(-0.60,-0.55]      0        NaN          NaN       NaN       NaN       NaN
(-0.55,-0.50]      0        NaN          NaN       NaN       NaN       NaN
(-0.50,-0.45]      0        NaN          NaN       NaN       NaN       NaN
(-0.45,-0.40]      0        NaN          NaN       NaN       NaN       NaN
(-0.40,-0.35]      0        NaN          NaN       NaN       NaN       NaN
(-0.35,-0.30]      0        NaN          NaN       NaN       NaN       NaN
(-0.30,-0.25]      0        NaN          NaN       NaN       NaN       NaN
(-0.25,-0.20]      0        NaN          NaN       NaN       NaN       NaN
(-0.20,-0.15]      0        NaN          NaN       NaN       NaN       NaN
(-0.15,-0.10]      0        NaN          NaN       NaN       NaN       NaN
(-0.10,-0.05]     20     -0.029       -0.019     0.047     0.043    -0.144
(-0.05,0.00]     907     -0.006        0.000     0.067     0.492    -0.218
(0.00,0.05]    14386      0.002        0.000     0.059     0.693    -0.342
(0.05,0.10]    16036      0.012        0.009     0.061     0.968    -0.381
(0.10,0.15]      526      0.030        0.027     0.071     0.698    -0.155
(0.15,0.20]       37      0.044        0.049     0.095     0.375    -0.075
(0.20,0.25]       11      0.039       -0.002     0.104     0.249    -0.089
(0.25,0.30]        1     -0.059       -0.059       NaN    -0.059    -0.059
(0.30,0.35]        1      0.095        0.095       NaN     0.095     0.095
(0.35,0.40]        0        NaN          NaN       NaN       NaN       NaN
(0.40,0.45]        0        NaN          NaN       NaN       NaN       NaN
(0.45,0.50]        0        NaN          NaN       NaN       NaN       NaN
(0.50,0.55]        0        NaN          NaN       NaN       NaN       NaN
(0.55,0.60]        0        NaN          NaN       NaN       NaN       NaN
(0.60,0.65]        0        NaN          NaN       NaN       NaN       NaN
(0.65,0.70]        0        NaN          NaN       NaN       NaN       NaN
(0.70,0.75]        0        NaN          NaN       NaN       NaN       NaN
(0.75,0.80]        0        NaN          NaN       NaN       NaN       NaN
(0.80,0.85]        0        NaN          NaN       NaN       NaN       NaN
(0.85,0.90]        0        NaN          NaN       NaN       NaN       NaN
(0.90,0.95]        0        NaN          NaN       NaN       NaN       NaN
(0.95,1.00]        0        NaN          NaN       NaN       NaN       NaN

y_l_rise
               count  eval_mean  eval_median  eval_std  eval_max  eval_min
pred_range
(-1.00,-0.95]      0        NaN          NaN       NaN       NaN       NaN
(-0.95,-0.90]      0        NaN          NaN       NaN       NaN       NaN
(-0.90,-0.85]      0        NaN          NaN       NaN       NaN       NaN
(-0.85,-0.80]      0        NaN          NaN       NaN       NaN       NaN
(-0.80,-0.75]      0        NaN          NaN       NaN       NaN       NaN
(-0.75,-0.70]      0        NaN          NaN       NaN       NaN       NaN
(-0.70,-0.65]      0        NaN          NaN       NaN       NaN       NaN
(-0.65,-0.60]      0        NaN          NaN       NaN       NaN       NaN
(-0.60,-0.55]      0        NaN          NaN       NaN       NaN       NaN
(-0.55,-0.50]      0        NaN          NaN       NaN       NaN       NaN
(-0.50,-0.45]      0        NaN          NaN       NaN       NaN       NaN
(-0.45,-0.40]      0        NaN          NaN       NaN       NaN       NaN
(-0.40,-0.35]      0        NaN          NaN       NaN       NaN       NaN
(-0.35,-0.30]      0        NaN          NaN       NaN       NaN       NaN
(-0.30,-0.25]      0        NaN          NaN       NaN       NaN       NaN
(-0.25,-0.20]      0        NaN          NaN       NaN       NaN       NaN
(-0.20,-0.15]      0        NaN          NaN       NaN       NaN       NaN
(-0.15,-0.10]      0        NaN          NaN       NaN       NaN       NaN
(-0.10,-0.05]     20      0.039        0.025     0.050     0.200     0.000
(-0.05,0.00]     907      0.060        0.031     0.088     1.061     0.000
(0.00,0.05]    14386      0.064        0.042     0.081     1.241     0.000
(0.05,0.10]    16036      0.078        0.058     0.083     1.303     0.000
(0.10,0.15]      526      0.109        0.087     0.097     1.130     0.000
(0.15,0.20]       37      0.140        0.125     0.126     0.551     0.003
(0.20,0.25]       11      0.135        0.100     0.158     0.527     0.002
(0.25,0.30]        1      0.028        0.028       NaN     0.028     0.028
(0.30,0.35]        1      0.171        0.171       NaN     0.171     0.171
(0.35,0.40]        0        NaN          NaN       NaN       NaN       NaN
(0.40,0.45]        0        NaN          NaN       NaN       NaN       NaN
(0.45,0.50]        0        NaN          NaN       NaN       NaN       NaN
(0.50,0.55]        0        NaN          NaN       NaN       NaN       NaN
(0.55,0.60]        0        NaN          NaN       NaN       NaN       NaN
(0.60,0.65]        0        NaN          NaN       NaN       NaN       NaN
(0.65,0.70]        0        NaN          NaN       NaN       NaN       NaN
(0.70,0.75]        0        NaN          NaN       NaN       NaN       NaN
(0.75,0.80]        0        NaN          NaN       NaN       NaN       NaN
(0.80,0.85]        0        NaN          NaN       NaN       NaN       NaN
(0.85,0.90]        0        NaN          NaN       NaN       NaN       NaN
(0.90,0.95]        0        NaN          NaN       NaN       NaN       NaN
(0.95,1.00]        0        NaN          NaN       NaN       NaN       NaN

test period:20170701-20180101
(263835, 2036) (34678, 2036)

--------------------Train network--------------------

 (263835, 2036) (263835,) {'fit': {'categorical_feature': ['area', 'market', 'exchange', 'is_hs']}, 'train_indexes': (0, None)}

----------Train layer 0----------
slice(0, None, None)

Train l2_y_l
C:\Users\dell-pc\Anaconda3.6\lib\site-packages\lightgbm\basic.py:1042: UserWarning: categorical_feature in Dataset is overridden. New categorical_feature is ['area', 'exchange', 'is_hs', 'market']
  warnings.warn('categorical_feature in Dataset is overridden. New categorical_feature is {}'.format(sorted(list(categorical_feature))))
[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves
[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves
Time usage: 216.45s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=0.1, max_depth=12, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=50,
       n_jobs=-1, num_leaves=31, objective=None, random_state=0,
       reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,
       subsample_for_bin=200000, subsample_freq=0)
                                    feature  importance_raw  \
1865                               sz50_vol             120
2025                                 sz_vol              93
1705                                 sh_vol              92
567                                     amt              43
895                               hs300_vol              37
454                          (high-low)/avg              27
1526        p80mv_(20k_low/p20mv_20k_low-1)              27
732                                 cyb_vol              25
1120       p20mv_(20k_low-20k_open)/20k_avg              15
1466        p60mv_(20k_low/p20mv_20k_low-1)              15
1268           p360mv_lower_shadow/120k_avg              14
986     p120mv_(60k_close-60k_open)/60k_avg              14
1241        p30mv_(10k_avg/p10mv_10k_avg-1)              13
1449  p600mv_(120k_low-120k_close)/120k_avg              13
1186           p250mv_lower_shadow/250k_avg              12
1061       p180mv_(60k_amt/p60mv_60k_amt-1)              12
2035                                   vol0              12
1457        p60mv_(20k_avg/p20mv_20k_avg-1)              11
1350           p480mv_lower_shadow/120k_avg              11
453                        (high-close)/avg              11

      importance_percent
1865                8.00
2025                6.20
1705                6.13
567                 2.87
895                 2.47
454                 1.80
1526                1.80
732                 1.67
1120                1.00
1466                1.00
1268                0.93
986                 0.93
1241                0.87
1449                0.87
1186                0.80
1061                0.80
2035                0.80
1457                0.73
1350                0.73
453                 0.73
Among 2036 features, 1628 features are not used in the model

--------------------Predict--------------------

----------Layer 0 predicts----------

y_l_r
               count  eval_mean  eval_median  eval_std  eval_max  eval_min
pred_range
(-1.00,-0.95]      0        NaN          NaN       NaN       NaN       NaN
(-0.95,-0.90]      0        NaN          NaN       NaN       NaN       NaN
(-0.90,-0.85]      0        NaN          NaN       NaN       NaN       NaN
(-0.85,-0.80]      0        NaN          NaN       NaN       NaN       NaN
(-0.80,-0.75]      0        NaN          NaN       NaN       NaN       NaN
(-0.75,-0.70]      0        NaN          NaN       NaN       NaN       NaN
(-0.70,-0.65]      0        NaN          NaN       NaN       NaN       NaN
(-0.65,-0.60]      0        NaN          NaN       NaN       NaN       NaN
(-0.60,-0.55]      0        NaN          NaN       NaN       NaN       NaN
(-0.55,-0.50]      0        NaN          NaN       NaN       NaN       NaN
(-0.50,-0.45]      0        NaN          NaN       NaN       NaN       NaN
(-0.45,-0.40]      0        NaN          NaN       NaN       NaN       NaN
(-0.40,-0.35]      0        NaN          NaN       NaN       NaN       NaN
(-0.35,-0.30]      0        NaN          NaN       NaN       NaN       NaN
(-0.30,-0.25]      0        NaN          NaN       NaN       NaN       NaN
(-0.25,-0.20]      0        NaN          NaN       NaN       NaN       NaN
(-0.20,-0.15]      2     -0.129       -0.129     0.030    -0.108    -0.151
(-0.15,-0.10]     14     -0.073       -0.090     0.088     0.147    -0.181
(-0.10,-0.05]    682      0.024        0.025     0.120     0.807    -0.375
(-0.05,0.00]   10542      0.022        0.015     0.113     0.812    -0.369
(0.00,0.05]    20941      0.018        0.000     0.115     0.980    -0.353
(0.05,0.10]     2317      0.025        0.037     0.136     1.730    -0.332
(0.10,0.15]      163      0.020        0.044     0.139     0.463    -0.286
(0.15,0.20]       17      0.084        0.096     0.197     0.503    -0.191
(0.20,0.25]        0        NaN          NaN       NaN       NaN       NaN
(0.25,0.30]        0        NaN          NaN       NaN       NaN       NaN
(0.30,0.35]        0        NaN          NaN       NaN       NaN       NaN
(0.35,0.40]        0        NaN          NaN       NaN       NaN       NaN
(0.40,0.45]        0        NaN          NaN       NaN       NaN       NaN
(0.45,0.50]        0        NaN          NaN       NaN       NaN       NaN
(0.50,0.55]        0        NaN          NaN       NaN       NaN       NaN
(0.55,0.60]        0        NaN          NaN       NaN       NaN       NaN
(0.60,0.65]        0        NaN          NaN       NaN       NaN       NaN
(0.65,0.70]        0        NaN          NaN       NaN       NaN       NaN
(0.70,0.75]        0        NaN          NaN       NaN       NaN       NaN
(0.75,0.80]        0        NaN          NaN       NaN       NaN       NaN
(0.80,0.85]        0        NaN          NaN       NaN       NaN       NaN
(0.85,0.90]        0        NaN          NaN       NaN       NaN       NaN
(0.90,0.95]        0        NaN          NaN       NaN       NaN       NaN
(0.95,1.00]        0        NaN          NaN       NaN       NaN       NaN

y_l
               count  eval_mean  eval_median  eval_std  eval_max  eval_min
pred_range
(-1.00,-0.95]      0        NaN          NaN       NaN       NaN       NaN
(-0.95,-0.90]      0        NaN          NaN       NaN       NaN       NaN
(-0.90,-0.85]      0        NaN          NaN       NaN       NaN       NaN
(-0.85,-0.80]      0        NaN          NaN       NaN       NaN       NaN
(-0.80,-0.75]      0        NaN          NaN       NaN       NaN       NaN
(-0.75,-0.70]      0        NaN          NaN       NaN       NaN       NaN
(-0.70,-0.65]      0        NaN          NaN       NaN       NaN       NaN
(-0.65,-0.60]      0        NaN          NaN       NaN       NaN       NaN
(-0.60,-0.55]      0        NaN          NaN       NaN       NaN       NaN
(-0.55,-0.50]      0        NaN          NaN       NaN       NaN       NaN
(-0.50,-0.45]      0        NaN          NaN       NaN       NaN       NaN
(-0.45,-0.40]      0        NaN          NaN       NaN       NaN       NaN
(-0.40,-0.35]      0        NaN          NaN       NaN       NaN       NaN
(-0.35,-0.30]      0        NaN          NaN       NaN       NaN       NaN
(-0.30,-0.25]      0        NaN          NaN       NaN       NaN       NaN
(-0.25,-0.20]      0        NaN          NaN       NaN       NaN       NaN
(-0.20,-0.15]      2     -0.157       -0.157     0.029    -0.136    -0.177
(-0.15,-0.10]     14     -0.077       -0.110     0.112     0.167    -0.208
(-0.10,-0.05]    682      0.029        0.039     0.140     0.975    -0.431
(-0.05,0.00]   10542      0.025        0.000     0.133     0.934    -0.423
(0.00,0.05]    20941      0.019        0.000     0.135     1.170    -0.394
(0.05,0.10]     2317      0.029        0.049     0.159     2.043    -0.381
(0.10,0.15]      163      0.022        0.057     0.161     0.534    -0.319
(0.15,0.20]       17      0.094        0.114     0.223     0.556    -0.216
(0.20,0.25]        0        NaN          NaN       NaN       NaN       NaN
(0.25,0.30]        0        NaN          NaN       NaN       NaN       NaN
(0.30,0.35]        0        NaN          NaN       NaN       NaN       NaN
(0.35,0.40]        0        NaN          NaN       NaN       NaN       NaN
(0.40,0.45]        0        NaN          NaN       NaN       NaN       NaN
(0.45,0.50]        0        NaN          NaN       NaN       NaN       NaN
(0.50,0.55]        0        NaN          NaN       NaN       NaN       NaN
(0.55,0.60]        0        NaN          NaN       NaN       NaN       NaN
(0.60,0.65]        0        NaN          NaN       NaN       NaN       NaN
(0.65,0.70]        0        NaN          NaN       NaN       NaN       NaN
(0.70,0.75]        0        NaN          NaN       NaN       NaN       NaN
(0.75,0.80]        0        NaN          NaN       NaN       NaN       NaN
(0.80,0.85]        0        NaN          NaN       NaN       NaN       NaN
(0.85,0.90]        0        NaN          NaN       NaN       NaN       NaN
(0.90,0.95]        0        NaN          NaN       NaN       NaN       NaN
(0.95,1.00]        0        NaN          NaN       NaN       NaN       NaN

y_l_avg
               count  eval_mean  eval_median  eval_std  eval_max  eval_min
pred_range
(-1.00,-0.95]      0        NaN          NaN       NaN       NaN       NaN
(-0.95,-0.90]      0        NaN          NaN       NaN       NaN       NaN
(-0.90,-0.85]      0        NaN          NaN       NaN       NaN       NaN
(-0.85,-0.80]      0        NaN          NaN       NaN       NaN       NaN
(-0.80,-0.75]      0        NaN          NaN       NaN       NaN       NaN
(-0.75,-0.70]      0        NaN          NaN       NaN       NaN       NaN
(-0.70,-0.65]      0        NaN          NaN       NaN       NaN       NaN
(-0.65,-0.60]      0        NaN          NaN       NaN       NaN       NaN
(-0.60,-0.55]      0        NaN          NaN       NaN       NaN       NaN
(-0.55,-0.50]      0        NaN          NaN       NaN       NaN       NaN
(-0.50,-0.45]      0        NaN          NaN       NaN       NaN       NaN
(-0.45,-0.40]      0        NaN          NaN       NaN       NaN       NaN
(-0.40,-0.35]      0        NaN          NaN       NaN       NaN       NaN
(-0.35,-0.30]      0        NaN          NaN       NaN       NaN       NaN
(-0.30,-0.25]      0        NaN          NaN       NaN       NaN       NaN
(-0.25,-0.20]      0        NaN          NaN       NaN       NaN       NaN
(-0.20,-0.15]      2     -0.048       -0.048     0.034    -0.023    -0.072
(-0.15,-0.10]     14     -0.029       -0.028     0.046     0.087    -0.102
(-0.10,-0.05]    682      0.012        0.001     0.061     0.304    -0.226
(-0.05,0.00]   10542      0.012        0.000     0.059     0.497    -0.261
(0.00,0.05]    20941      0.010        0.000     0.060     0.525    -0.230
(0.05,0.10]     2317      0.013        0.003     0.071     0.793    -0.218
(0.10,0.15]      163      0.010        0.004     0.076     0.249    -0.189
(0.15,0.20]       17      0.053        0.042     0.120     0.344    -0.116
(0.20,0.25]        0        NaN          NaN       NaN       NaN       NaN
(0.25,0.30]        0        NaN          NaN       NaN       NaN       NaN
(0.30,0.35]        0        NaN          NaN       NaN       NaN       NaN
(0.35,0.40]        0        NaN          NaN       NaN       NaN       NaN
(0.40,0.45]        0        NaN          NaN       NaN       NaN       NaN
(0.45,0.50]        0        NaN          NaN       NaN       NaN       NaN
(0.50,0.55]        0        NaN          NaN       NaN       NaN       NaN
(0.55,0.60]        0        NaN          NaN       NaN       NaN       NaN
(0.60,0.65]        0        NaN          NaN       NaN       NaN       NaN
(0.65,0.70]        0        NaN          NaN       NaN       NaN       NaN
(0.70,0.75]        0        NaN          NaN       NaN       NaN       NaN
(0.75,0.80]        0        NaN          NaN       NaN       NaN       NaN
(0.80,0.85]        0        NaN          NaN       NaN       NaN       NaN
(0.85,0.90]        0        NaN          NaN       NaN       NaN       NaN
(0.90,0.95]        0        NaN          NaN       NaN       NaN       NaN
(0.95,1.00]        0        NaN          NaN       NaN       NaN       NaN

y_l_rise
               count  eval_mean  eval_median  eval_std  eval_max  eval_min
pred_range
(-1.00,-0.95]      0        NaN          NaN       NaN       NaN       NaN
(-0.95,-0.90]      0        NaN          NaN       NaN       NaN       NaN
(-0.90,-0.85]      0        NaN          NaN       NaN       NaN       NaN
(-0.85,-0.80]      0        NaN          NaN       NaN       NaN       NaN
(-0.80,-0.75]      0        NaN          NaN       NaN       NaN       NaN
(-0.75,-0.70]      0        NaN          NaN       NaN       NaN       NaN
(-0.70,-0.65]      0        NaN          NaN       NaN       NaN       NaN
(-0.65,-0.60]      0        NaN          NaN       NaN       NaN       NaN
(-0.60,-0.55]      0        NaN          NaN       NaN       NaN       NaN
(-0.55,-0.50]      0        NaN          NaN       NaN       NaN       NaN
(-0.50,-0.45]      0        NaN          NaN       NaN       NaN       NaN
(-0.45,-0.40]      0        NaN          NaN       NaN       NaN       NaN
(-0.40,-0.35]      0        NaN          NaN       NaN       NaN       NaN
(-0.35,-0.30]      0        NaN          NaN       NaN       NaN       NaN
(-0.30,-0.25]      0        NaN          NaN       NaN       NaN       NaN
(-0.25,-0.20]      0        NaN          NaN       NaN       NaN       NaN
(-0.20,-0.15]      2      0.060        0.060     0.007     0.065     0.055
(-0.15,-0.10]     14      0.045        0.036     0.041     0.167     0.000
(-0.10,-0.05]    682      0.081        0.055     0.094     0.975     0.000
(-0.05,0.00]   10542      0.077        0.052     0.087     0.934     0.000
(0.00,0.05]    20941      0.079        0.053     0.086     1.170     0.000
(0.05,0.10]     2317      0.093        0.065     0.108     2.043     0.000
(0.10,0.15]      163      0.098        0.074     0.092     0.534     0.000
(0.15,0.20]       17      0.163        0.114     0.156     0.556     0.006
(0.20,0.25]        0        NaN          NaN       NaN       NaN       NaN
(0.25,0.30]        0        NaN          NaN       NaN       NaN       NaN
(0.30,0.35]        0        NaN          NaN       NaN       NaN       NaN
(0.35,0.40]        0        NaN          NaN       NaN       NaN       NaN
(0.40,0.45]        0        NaN          NaN       NaN       NaN       NaN
(0.45,0.50]        0        NaN          NaN       NaN       NaN       NaN
(0.50,0.55]        0        NaN          NaN       NaN       NaN       NaN
(0.55,0.60]        0        NaN          NaN       NaN       NaN       NaN
(0.60,0.65]        0        NaN          NaN       NaN       NaN       NaN
(0.65,0.70]        0        NaN          NaN       NaN       NaN       NaN
(0.70,0.75]        0        NaN          NaN       NaN       NaN       NaN
(0.75,0.80]        0        NaN          NaN       NaN       NaN       NaN
(0.80,0.85]        0        NaN          NaN       NaN       NaN       NaN
(0.85,0.90]        0        NaN          NaN       NaN       NaN       NaN
(0.90,0.95]        0        NaN          NaN       NaN       NaN       NaN
(0.95,1.00]        0        NaN          NaN       NaN       NaN       NaN

test period:20180101-20180701
(298328, 2036) (33929, 2036)

--------------------Train network--------------------

 (298328, 2036) (298328,) {'fit': {'categorical_feature': ['area', 'market', 'exchange', 'is_hs']}, 'train_indexes': (0, None)}

----------Train layer 0----------
slice(0, None, None)

Train l2_y_l
C:\Users\dell-pc\Anaconda3.6\lib\site-packages\lightgbm\basic.py:1042: UserWarning: categorical_feature in Dataset is overridden. New categorical_feature is ['area', 'exchange', 'is_hs', 'market']
  warnings.warn('categorical_feature in Dataset is overridden. New categorical_feature is {}'.format(sorted(list(categorical_feature))))
[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves
[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves
Time usage: 277.26s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=0.1, max_depth=12, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=50,
       n_jobs=-1, num_leaves=31, objective=None, random_state=0,
       reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,
       subsample_for_bin=200000, subsample_freq=0)
                                    feature  importance_raw  \
2025                                 sz_vol             107
1865                               sz50_vol             102
1705                                 sh_vol              89
895                               hs300_vol              56
567                                     amt              39
1526        p80mv_(20k_low/p20mv_20k_low-1)              38
732                                 cyb_vol              30
454                          (high-low)/avg              21
1350           p480mv_lower_shadow/120k_avg              19
1466        p60mv_(20k_low/p20mv_20k_low-1)              18
1457        p60mv_(20k_avg/p20mv_20k_avg-1)              16
1321        p40mv_(20k_avg/p20mv_20k_avg-1)              16
1120       p20mv_(20k_low-20k_open)/20k_avg              13
1449  p600mv_(120k_low-120k_close)/120k_avg              13
1061       p180mv_(60k_amt/p60mv_60k_amt-1)              13
986     p120mv_(60k_close-60k_open)/60k_avg              12
1268           p360mv_lower_shadow/120k_avg              11
1241        p30mv_(10k_avg/p10mv_10k_avg-1)              11
1479        p60mv_(60k_low/p60mv_60k_low-1)               9
549                      (vol/p20min_vol-1)               9

      importance_percent
2025                7.13
1865                6.80
1705                5.93
895                 3.73
567                 2.60
1526                2.53
732                 2.00
454                 1.40
1350                1.27
1466                1.20
1457                1.07
1321                1.07
1120                0.87
1449                0.87
1061                0.87
986                 0.80
1268                0.73
1241                0.73
1479                0.60
549                 0.60
Among 2036 features, 1639 features are not used in the model

--------------------Predict--------------------

----------Layer 0 predicts----------

y_l_r
               count  eval_mean  eval_median  eval_std  eval_max  eval_min
pred_range
(-1.00,-0.95]      0        NaN          NaN       NaN       NaN       NaN
(-0.95,-0.90]      0        NaN          NaN       NaN       NaN       NaN
(-0.90,-0.85]      0        NaN          NaN       NaN       NaN       NaN
(-0.85,-0.80]      0        NaN          NaN       NaN       NaN       NaN
(-0.80,-0.75]      0        NaN          NaN       NaN       NaN       NaN
(-0.75,-0.70]      0        NaN          NaN       NaN       NaN       NaN
(-0.70,-0.65]      0        NaN          NaN       NaN       NaN       NaN
(-0.65,-0.60]      0        NaN          NaN       NaN       NaN       NaN
(-0.60,-0.55]      0        NaN          NaN       NaN       NaN       NaN
(-0.55,-0.50]      0        NaN          NaN       NaN       NaN       NaN
(-0.50,-0.45]      0        NaN          NaN       NaN       NaN       NaN
(-0.45,-0.40]      0        NaN          NaN       NaN       NaN       NaN
(-0.40,-0.35]      0        NaN          NaN       NaN       NaN       NaN
(-0.35,-0.30]      0        NaN          NaN       NaN       NaN       NaN
(-0.30,-0.25]      0        NaN          NaN       NaN       NaN       NaN
(-0.25,-0.20]      0        NaN          NaN       NaN       NaN       NaN
(-0.20,-0.15]      1     -0.103       -0.103       NaN    -0.103    -0.103
(-0.15,-0.10]      6     -0.135       -0.158     0.163     0.139    -0.298
(-0.10,-0.05]     59     -0.079       -0.146     0.165     0.539    -0.264
(-0.05,0.00]    1824     -0.049       -0.065     0.126     0.737    -0.527
(0.00,0.05]    22631     -0.025       -0.054     0.126     0.838    -0.619
(0.05,0.10]     7843     -0.006       -0.054     0.149     1.151    -0.568
(0.10,0.15]     1297      0.009       -0.041     0.185     0.735    -0.546
(0.15,0.20]      225      0.035        0.061     0.211     0.688    -0.375
(0.20,0.25]       38      0.055        0.065     0.200     0.434    -0.255
(0.25,0.30]        4      0.195        0.214     0.208     0.412    -0.062
(0.30,0.35]        1     -0.205       -0.205       NaN    -0.205    -0.205
(0.35,0.40]        0        NaN          NaN       NaN       NaN       NaN
(0.40,0.45]        0        NaN          NaN       NaN       NaN       NaN
(0.45,0.50]        0        NaN          NaN       NaN       NaN       NaN
(0.50,0.55]        0        NaN          NaN       NaN       NaN       NaN
(0.55,0.60]        0        NaN          NaN       NaN       NaN       NaN
(0.60,0.65]        0        NaN          NaN       NaN       NaN       NaN
(0.65,0.70]        0        NaN          NaN       NaN       NaN       NaN
(0.70,0.75]        0        NaN          NaN       NaN       NaN       NaN
(0.75,0.80]        0        NaN          NaN       NaN       NaN       NaN
(0.80,0.85]        0        NaN          NaN       NaN       NaN       NaN
(0.85,0.90]        0        NaN          NaN       NaN       NaN       NaN
(0.90,0.95]        0        NaN          NaN       NaN       NaN       NaN
(0.95,1.00]        0        NaN          NaN       NaN       NaN       NaN

y_l
               count  eval_mean  eval_median  eval_std  eval_max  eval_min
pred_range
(-1.00,-0.95]      0        NaN          NaN       NaN       NaN       NaN
(-0.95,-0.90]      0        NaN          NaN       NaN       NaN       NaN
(-0.90,-0.85]      0        NaN          NaN       NaN       NaN       NaN
(-0.85,-0.80]      0        NaN          NaN       NaN       NaN       NaN
(-0.80,-0.75]      0        NaN          NaN       NaN       NaN       NaN
(-0.75,-0.70]      0        NaN          NaN       NaN       NaN       NaN
(-0.70,-0.65]      0        NaN          NaN       NaN       NaN       NaN
(-0.65,-0.60]      0        NaN          NaN       NaN       NaN       NaN
(-0.60,-0.55]      0        NaN          NaN       NaN       NaN       NaN
(-0.55,-0.50]      0        NaN          NaN       NaN       NaN       NaN
(-0.50,-0.45]      0        NaN          NaN       NaN       NaN       NaN
(-0.45,-0.40]      0        NaN          NaN       NaN       NaN       NaN
(-0.40,-0.35]      0        NaN          NaN       NaN       NaN       NaN
(-0.35,-0.30]      0        NaN          NaN       NaN       NaN       NaN
(-0.30,-0.25]      0        NaN          NaN       NaN       NaN       NaN
(-0.25,-0.20]      0        NaN          NaN       NaN       NaN       NaN
(-0.20,-0.15]      1     -0.123       -0.123       NaN    -0.123    -0.123
(-0.15,-0.10]      6     -0.165       -0.197     0.193     0.155    -0.352
(-0.10,-0.05]     59     -0.099       -0.178     0.193     0.624    -0.313
(-0.05,0.00]    1824     -0.063       -0.090     0.145     0.824    -0.576
(0.00,0.05]    22631     -0.036       -0.076     0.147     0.915    -0.631
(0.05,0.10]     7843     -0.016       -0.084     0.175     1.326    -0.598
(0.10,0.15]     1297      0.003       -0.083     0.215     0.817    -0.563
(0.15,0.20]      225      0.032        0.064     0.245     0.771    -0.416
(0.20,0.25]       38      0.060        0.065     0.236     0.494    -0.302
(0.25,0.30]        4      0.266        0.255     0.169     0.463     0.092
(0.30,0.35]        1     -0.245       -0.245       NaN    -0.245    -0.245
(0.35,0.40]        0        NaN          NaN       NaN       NaN       NaN
(0.40,0.45]        0        NaN          NaN       NaN       NaN       NaN
(0.45,0.50]        0        NaN          NaN       NaN       NaN       NaN
(0.50,0.55]        0        NaN          NaN       NaN       NaN       NaN
(0.55,0.60]        0        NaN          NaN       NaN       NaN       NaN
(0.60,0.65]        0        NaN          NaN       NaN       NaN       NaN
(0.65,0.70]        0        NaN          NaN       NaN       NaN       NaN
(0.70,0.75]        0        NaN          NaN       NaN       NaN       NaN
(0.75,0.80]        0        NaN          NaN       NaN       NaN       NaN
(0.80,0.85]        0        NaN          NaN       NaN       NaN       NaN
(0.85,0.90]        0        NaN          NaN       NaN       NaN       NaN
(0.90,0.95]        0        NaN          NaN       NaN       NaN       NaN
(0.95,1.00]        0        NaN          NaN       NaN       NaN       NaN

y_l_avg
               count  eval_mean  eval_median  eval_std  eval_max  eval_min
pred_range
(-1.00,-0.95]      0        NaN          NaN       NaN       NaN       NaN
(-0.95,-0.90]      0        NaN          NaN       NaN       NaN       NaN
(-0.90,-0.85]      0        NaN          NaN       NaN       NaN       NaN
(-0.85,-0.80]      0        NaN          NaN       NaN       NaN       NaN
(-0.80,-0.75]      0        NaN          NaN       NaN       NaN       NaN
(-0.75,-0.70]      0        NaN          NaN       NaN       NaN       NaN
(-0.70,-0.65]      0        NaN          NaN       NaN       NaN       NaN
(-0.65,-0.60]      0        NaN          NaN       NaN       NaN       NaN
(-0.60,-0.55]      0        NaN          NaN       NaN       NaN       NaN
(-0.55,-0.50]      0        NaN          NaN       NaN       NaN       NaN
(-0.50,-0.45]      0        NaN          NaN       NaN       NaN       NaN
(-0.45,-0.40]      0        NaN          NaN       NaN       NaN       NaN
(-0.40,-0.35]      0        NaN          NaN       NaN       NaN       NaN
(-0.35,-0.30]      0        NaN          NaN       NaN       NaN       NaN
(-0.30,-0.25]      0        NaN          NaN       NaN       NaN       NaN
(-0.25,-0.20]      0        NaN          NaN       NaN       NaN       NaN
(-0.20,-0.15]      1     -0.044       -0.044       NaN    -0.044    -0.044
(-0.15,-0.10]      6     -0.042       -0.040     0.078     0.090    -0.136
(-0.10,-0.05]     59     -0.030       -0.043     0.080     0.285    -0.158
(-0.05,0.00]    1824     -0.023       -0.011     0.067     0.474    -0.471
(0.00,0.05]    22631     -0.011       -0.009     0.066     0.609    -0.583
(0.05,0.10]     7843      0.001       -0.006     0.079     0.625    -0.475
(0.10,0.15]     1297      0.010       -0.001     0.103     0.517    -0.494
(0.15,0.20]      225      0.019        0.006     0.120     0.439    -0.251
(0.20,0.25]       38      0.031        0.007     0.099     0.255    -0.115
(0.25,0.30]        4      0.111        0.093     0.132     0.261    -0.002
(0.30,0.35]        1     -0.086       -0.086       NaN    -0.086    -0.086
(0.35,0.40]        0        NaN          NaN       NaN       NaN       NaN
(0.40,0.45]        0        NaN          NaN       NaN       NaN       NaN
(0.45,0.50]        0        NaN          NaN       NaN       NaN       NaN
(0.50,0.55]        0        NaN          NaN       NaN       NaN       NaN
(0.55,0.60]        0        NaN          NaN       NaN       NaN       NaN
(0.60,0.65]        0        NaN          NaN       NaN       NaN       NaN
(0.65,0.70]        0        NaN          NaN       NaN       NaN       NaN
(0.70,0.75]        0        NaN          NaN       NaN       NaN       NaN
(0.75,0.80]        0        NaN          NaN       NaN       NaN       NaN
(0.80,0.85]        0        NaN          NaN       NaN       NaN       NaN
(0.85,0.90]        0        NaN          NaN       NaN       NaN       NaN
(0.90,0.95]        0        NaN          NaN       NaN       NaN       NaN
(0.95,1.00]        0        NaN          NaN       NaN       NaN       NaN

y_l_rise
               count  eval_mean  eval_median  eval_std  eval_max  eval_min
pred_range
(-1.00,-0.95]      0        NaN          NaN       NaN       NaN       NaN
(-0.95,-0.90]      0        NaN          NaN       NaN       NaN       NaN
(-0.90,-0.85]      0        NaN          NaN       NaN       NaN       NaN
(-0.85,-0.80]      0        NaN          NaN       NaN       NaN       NaN
(-0.80,-0.75]      0        NaN          NaN       NaN       NaN       NaN
(-0.75,-0.70]      0        NaN          NaN       NaN       NaN       NaN
(-0.70,-0.65]      0        NaN          NaN       NaN       NaN       NaN
(-0.65,-0.60]      0        NaN          NaN       NaN       NaN       NaN
(-0.60,-0.55]      0        NaN          NaN       NaN       NaN       NaN
(-0.55,-0.50]      0        NaN          NaN       NaN       NaN       NaN
(-0.50,-0.45]      0        NaN          NaN       NaN       NaN       NaN
(-0.45,-0.40]      0        NaN          NaN       NaN       NaN       NaN
(-0.40,-0.35]      0        NaN          NaN       NaN       NaN       NaN
(-0.35,-0.30]      0        NaN          NaN       NaN       NaN       NaN
(-0.30,-0.25]      0        NaN          NaN       NaN       NaN       NaN
(-0.25,-0.20]      0        NaN          NaN       NaN       NaN       NaN
(-0.20,-0.15]      1      0.034        0.034       NaN     0.034     0.034
(-0.15,-0.10]      6      0.066        0.048     0.055     0.155     0.012
(-0.10,-0.05]     59      0.084        0.066     0.091     0.624     0.002
(-0.05,0.00]    1824      0.051        0.026     0.070     0.824     0.000
(0.00,0.05]    22631      0.066        0.044     0.074     0.915     0.000
(0.05,0.10]     7843      0.093        0.065     0.092     1.326     0.000
(0.10,0.15]     1297      0.122        0.087     0.117     0.817     0.000
(0.15,0.20]      225      0.146        0.106     0.144     0.771     0.000
(0.20,0.25]       38      0.165        0.114     0.138     0.494     0.000
(0.25,0.30]        4      0.266        0.255     0.169     0.463     0.092
(0.30,0.35]        1      0.047        0.047       NaN     0.047     0.047
(0.35,0.40]        0        NaN          NaN       NaN       NaN       NaN
(0.40,0.45]        0        NaN          NaN       NaN       NaN       NaN
(0.45,0.50]        0        NaN          NaN       NaN       NaN       NaN
(0.50,0.55]        0        NaN          NaN       NaN       NaN       NaN
(0.55,0.60]        0        NaN          NaN       NaN       NaN       NaN
(0.60,0.65]        0        NaN          NaN       NaN       NaN       NaN
(0.65,0.70]        0        NaN          NaN       NaN       NaN       NaN
(0.70,0.75]        0        NaN          NaN       NaN       NaN       NaN
(0.75,0.80]        0        NaN          NaN       NaN       NaN       NaN
(0.80,0.85]        0        NaN          NaN       NaN       NaN       NaN
(0.85,0.90]        0        NaN          NaN       NaN       NaN       NaN
(0.90,0.95]        0        NaN          NaN       NaN       NaN       NaN
(0.95,1.00]        0        NaN          NaN       NaN       NaN       NaN

test period:20180701-20190101
(332099, 2036) (35524, 2036)

--------------------Train network--------------------

 (332099, 2036) (332099,) {'fit': {'categorical_feature': ['area', 'market', 'exchange', 'is_hs']}, 'train_indexes': (0, None)}

----------Train layer 0----------
slice(0, None, None)

Train l2_y_l
C:\Users\dell-pc\Anaconda3.6\lib\site-packages\lightgbm\basic.py:1042: UserWarning: categorical_feature in Dataset is overridden. New categorical_feature is ['area', 'exchange', 'is_hs', 'market']
  warnings.warn('categorical_feature in Dataset is overridden. New categorical_feature is {}'.format(sorted(list(categorical_feature))))
[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves
[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves
Time usage: 360.37s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=0.1, max_depth=12, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=50,
       n_jobs=-1, num_leaves=31, objective=None, random_state=0,
       reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,
       subsample_for_bin=200000, subsample_freq=0)
                                    feature  importance_raw  \
2025                                 sz_vol             114
1865                               sz50_vol             114
1705                                 sh_vol              85
567                                     amt              50
895                               hs300_vol              50
1526        p80mv_(20k_low/p20mv_20k_low-1)              36
732                                 cyb_vol              31
1466        p60mv_(20k_low/p20mv_20k_low-1)              25
454                          (high-low)/avg              23
1457        p60mv_(20k_avg/p20mv_20k_avg-1)              16
1449  p600mv_(120k_low-120k_close)/120k_avg              16
1120       p20mv_(20k_low-20k_open)/20k_avg              16
1061       p180mv_(60k_amt/p60mv_60k_amt-1)              12
1321        p40mv_(20k_avg/p20mv_20k_avg-1)              12
1350           p480mv_lower_shadow/120k_avg              11
141             (20k_high/p80mv_20k_high-1)              11
986     p120mv_(60k_close-60k_open)/60k_avg              11
1268           p360mv_lower_shadow/120k_avg              11
1450   p600mv_(120k_low-120k_open)/120k_avg              10
453                        (high-close)/avg              10

      importance_percent
2025                7.60
1865                7.60
1705                5.67
567                 3.33
895                 3.33
1526                2.40
732                 2.07
1466                1.67
454                 1.53
1457                1.07
1449                1.07
1120                1.07
1061                0.80
1321                0.80
1350                0.73
141                 0.73
986                 0.73
1268                0.73
1450                0.67
453                 0.67
Among 2036 features, 1655 features are not used in the model

--------------------Predict--------------------

----------Layer 0 predicts----------

y_l_r
               count  eval_mean  eval_median  eval_std  eval_max  eval_min
pred_range
(-1.00,-0.95]      0        NaN          NaN       NaN       NaN       NaN
(-0.95,-0.90]      0        NaN          NaN       NaN       NaN       NaN
(-0.90,-0.85]      0        NaN          NaN       NaN       NaN       NaN
(-0.85,-0.80]      0        NaN          NaN       NaN       NaN       NaN
(-0.80,-0.75]      0        NaN          NaN       NaN       NaN       NaN
(-0.75,-0.70]      0        NaN          NaN       NaN       NaN       NaN
(-0.70,-0.65]      0        NaN          NaN       NaN       NaN       NaN
(-0.65,-0.60]      0        NaN          NaN       NaN       NaN       NaN
(-0.60,-0.55]      0        NaN          NaN       NaN       NaN       NaN
(-0.55,-0.50]      0        NaN          NaN       NaN       NaN       NaN
(-0.50,-0.45]      0        NaN          NaN       NaN       NaN       NaN
(-0.45,-0.40]      0        NaN          NaN       NaN       NaN       NaN
(-0.40,-0.35]      0        NaN          NaN       NaN       NaN       NaN
(-0.35,-0.30]      0        NaN          NaN       NaN       NaN       NaN
(-0.30,-0.25]      0        NaN          NaN       NaN       NaN       NaN
(-0.25,-0.20]      0        NaN          NaN       NaN       NaN       NaN
(-0.20,-0.15]      1     -0.066       -0.066       NaN    -0.066    -0.066
(-0.15,-0.10]      5      0.008       -0.059     0.110     0.167    -0.077
(-0.10,-0.05]    133     -0.065       -0.108     0.128     0.384    -0.370
(-0.05,0.00]    4884     -0.045       -0.071     0.123     0.888    -0.562
(0.00,0.05]    22815     -0.014       -0.043     0.124     0.977    -0.643
(0.05,0.10]     5721      0.005        0.000     0.146     1.178    -0.483
(0.10,0.15]     1293      0.044        0.089     0.180     0.776    -0.420
(0.15,0.20]      561      0.044        0.086     0.191     0.573    -0.366
(0.20,0.25]      102      0.059        0.119     0.193     0.422    -0.336
(0.25,0.30]        9      0.117        0.161     0.152     0.253    -0.172
(0.30,0.35]        0        NaN          NaN       NaN       NaN       NaN
(0.35,0.40]        0        NaN          NaN       NaN       NaN       NaN
(0.40,0.45]        0        NaN          NaN       NaN       NaN       NaN
(0.45,0.50]        0        NaN          NaN       NaN       NaN       NaN
(0.50,0.55]        0        NaN          NaN       NaN       NaN       NaN
(0.55,0.60]        0        NaN          NaN       NaN       NaN       NaN
(0.60,0.65]        0        NaN          NaN       NaN       NaN       NaN
(0.65,0.70]        0        NaN          NaN       NaN       NaN       NaN
(0.70,0.75]        0        NaN          NaN       NaN       NaN       NaN
(0.75,0.80]        0        NaN          NaN       NaN       NaN       NaN
(0.80,0.85]        0        NaN          NaN       NaN       NaN       NaN
(0.85,0.90]        0        NaN          NaN       NaN       NaN       NaN
(0.90,0.95]        0        NaN          NaN       NaN       NaN       NaN
(0.95,1.00]        0        NaN          NaN       NaN       NaN       NaN

y_l
               count  eval_mean  eval_median  eval_std  eval_max  eval_min
pred_range
(-1.00,-0.95]      0        NaN          NaN       NaN       NaN       NaN
(-0.95,-0.90]      0        NaN          NaN       NaN       NaN       NaN
(-0.90,-0.85]      0        NaN          NaN       NaN       NaN       NaN
(-0.85,-0.80]      0        NaN          NaN       NaN       NaN       NaN
(-0.80,-0.75]      0        NaN          NaN       NaN       NaN       NaN
(-0.75,-0.70]      0        NaN          NaN       NaN       NaN       NaN
(-0.70,-0.65]      0        NaN          NaN       NaN       NaN       NaN
(-0.65,-0.60]      0        NaN          NaN       NaN       NaN       NaN
(-0.60,-0.55]      0        NaN          NaN       NaN       NaN       NaN
(-0.55,-0.50]      0        NaN          NaN       NaN       NaN       NaN
(-0.50,-0.45]      0        NaN          NaN       NaN       NaN       NaN
(-0.45,-0.40]      0        NaN          NaN       NaN       NaN       NaN
(-0.40,-0.35]      0        NaN          NaN       NaN       NaN       NaN
(-0.35,-0.30]      0        NaN          NaN       NaN       NaN       NaN
(-0.30,-0.25]      0        NaN          NaN       NaN       NaN       NaN
(-0.25,-0.20]      0        NaN          NaN       NaN       NaN       NaN
(-0.20,-0.15]      1     -0.079       -0.079       NaN    -0.079    -0.079
(-0.15,-0.10]      5      0.008       -0.074     0.129     0.191    -0.090
(-0.10,-0.05]    133     -0.086       -0.131     0.147     0.438    -0.407
(-0.05,0.00]    4884     -0.058       -0.091     0.142     0.983    -0.590
(0.00,0.05]    22815     -0.022       -0.063     0.144     1.062    -0.670
(0.05,0.10]     5721     -0.001       -0.059     0.172     1.328    -0.534
(0.10,0.15]     1293      0.043        0.106     0.213     0.872    -0.467
(0.15,0.20]      561      0.045        0.104     0.226     0.636    -0.409
(0.20,0.25]      102      0.071        0.148     0.229     0.483    -0.402
(0.25,0.30]        9      0.174        0.202     0.147     0.296    -0.191
(0.30,0.35]        0        NaN          NaN       NaN       NaN       NaN
(0.35,0.40]        0        NaN          NaN       NaN       NaN       NaN
(0.40,0.45]        0        NaN          NaN       NaN       NaN       NaN
(0.45,0.50]        0        NaN          NaN       NaN       NaN       NaN
(0.50,0.55]        0        NaN          NaN       NaN       NaN       NaN
(0.55,0.60]        0        NaN          NaN       NaN       NaN       NaN
(0.60,0.65]        0        NaN          NaN       NaN       NaN       NaN
(0.65,0.70]        0        NaN          NaN       NaN       NaN       NaN
(0.70,0.75]        0        NaN          NaN       NaN       NaN       NaN
(0.75,0.80]        0        NaN          NaN       NaN       NaN       NaN
(0.80,0.85]        0        NaN          NaN       NaN       NaN       NaN
(0.85,0.90]        0        NaN          NaN       NaN       NaN       NaN
(0.90,0.95]        0        NaN          NaN       NaN       NaN       NaN
(0.95,1.00]        0        NaN          NaN       NaN       NaN       NaN

y_l_avg
               count  eval_mean  eval_median  eval_std  eval_max  eval_min
pred_range
(-1.00,-0.95]      0        NaN          NaN       NaN       NaN       NaN
(-0.95,-0.90]      0        NaN          NaN       NaN       NaN       NaN
(-0.90,-0.85]      0        NaN          NaN       NaN       NaN       NaN
(-0.85,-0.80]      0        NaN          NaN       NaN       NaN       NaN
(-0.80,-0.75]      0        NaN          NaN       NaN       NaN       NaN
(-0.75,-0.70]      0        NaN          NaN       NaN       NaN       NaN
(-0.70,-0.65]      0        NaN          NaN       NaN       NaN       NaN
(-0.65,-0.60]      0        NaN          NaN       NaN       NaN       NaN
(-0.60,-0.55]      0        NaN          NaN       NaN       NaN       NaN
(-0.55,-0.50]      0        NaN          NaN       NaN       NaN       NaN
(-0.50,-0.45]      0        NaN          NaN       NaN       NaN       NaN
(-0.45,-0.40]      0        NaN          NaN       NaN       NaN       NaN
(-0.40,-0.35]      0        NaN          NaN       NaN       NaN       NaN
(-0.35,-0.30]      0        NaN          NaN       NaN       NaN       NaN
(-0.30,-0.25]      0        NaN          NaN       NaN       NaN       NaN
(-0.25,-0.20]      0        NaN          NaN       NaN       NaN       NaN
(-0.20,-0.15]      1     -0.030       -0.030       NaN    -0.030    -0.030
(-0.15,-0.10]      5      0.008       -0.016     0.053     0.093    -0.039
(-0.10,-0.05]    133     -0.034       -0.037     0.063     0.223    -0.256
(-0.05,0.00]    4884     -0.022       -0.019     0.066     0.602    -0.481
(0.00,0.05]    22815     -0.006       -0.006     0.066     0.721    -0.564
(0.05,0.10]     5721      0.005        0.000     0.076     0.730    -0.329
(0.10,0.15]     1293      0.024        0.021     0.093     0.486    -0.278
(0.15,0.20]      561      0.022        0.014     0.097     0.384    -0.277
(0.20,0.25]      102      0.031        0.024     0.090     0.240    -0.176
(0.25,0.30]        9      0.048        0.052     0.079     0.138    -0.112
(0.30,0.35]        0        NaN          NaN       NaN       NaN       NaN
(0.35,0.40]        0        NaN          NaN       NaN       NaN       NaN
(0.40,0.45]        0        NaN          NaN       NaN       NaN       NaN
(0.45,0.50]        0        NaN          NaN       NaN       NaN       NaN
(0.50,0.55]        0        NaN          NaN       NaN       NaN       NaN
(0.55,0.60]        0        NaN          NaN       NaN       NaN       NaN
(0.60,0.65]        0        NaN          NaN       NaN       NaN       NaN
(0.65,0.70]        0        NaN          NaN       NaN       NaN       NaN
(0.70,0.75]        0        NaN          NaN       NaN       NaN       NaN
(0.75,0.80]        0        NaN          NaN       NaN       NaN       NaN
(0.80,0.85]        0        NaN          NaN       NaN       NaN       NaN
(0.85,0.90]        0        NaN          NaN       NaN       NaN       NaN
(0.90,0.95]        0        NaN          NaN       NaN       NaN       NaN
(0.95,1.00]        0        NaN          NaN       NaN       NaN       NaN

y_l_rise
               count  eval_mean  eval_median  eval_std  eval_max  eval_min
pred_range
(-1.00,-0.95]      0        NaN          NaN       NaN       NaN       NaN
(-0.95,-0.90]      0        NaN          NaN       NaN       NaN       NaN
(-0.90,-0.85]      0        NaN          NaN       NaN       NaN       NaN
(-0.85,-0.80]      0        NaN          NaN       NaN       NaN       NaN
(-0.80,-0.75]      0        NaN          NaN       NaN       NaN       NaN
(-0.75,-0.70]      0        NaN          NaN       NaN       NaN       NaN
(-0.70,-0.65]      0        NaN          NaN       NaN       NaN       NaN
(-0.65,-0.60]      0        NaN          NaN       NaN       NaN       NaN
(-0.60,-0.55]      0        NaN          NaN       NaN       NaN       NaN
(-0.55,-0.50]      0        NaN          NaN       NaN       NaN       NaN
(-0.50,-0.45]      0        NaN          NaN       NaN       NaN       NaN
(-0.45,-0.40]      0        NaN          NaN       NaN       NaN       NaN
(-0.40,-0.35]      0        NaN          NaN       NaN       NaN       NaN
(-0.35,-0.30]      0        NaN          NaN       NaN       NaN       NaN
(-0.30,-0.25]      0        NaN          NaN       NaN       NaN       NaN
(-0.25,-0.20]      0        NaN          NaN       NaN       NaN       NaN
(-0.20,-0.15]      1      0.035        0.035       NaN     0.035     0.035
(-0.15,-0.10]      5      0.078        0.044     0.069     0.191     0.026
(-0.10,-0.05]    133      0.061        0.045     0.070     0.438     0.000
(-0.05,0.00]    4884      0.059        0.040     0.067     0.983     0.000
(0.00,0.05]    22815      0.071        0.051     0.073     1.062     0.000
(0.05,0.10]     5721      0.097        0.075     0.091     1.328     0.000
(0.10,0.15]     1293      0.142        0.115     0.116     0.872     0.000
(0.15,0.20]      561      0.151        0.121     0.126     0.636     0.000
(0.20,0.25]      102      0.171        0.153     0.112     0.483     0.007
(0.25,0.30]        9      0.200        0.202     0.080     0.296     0.040
(0.30,0.35]        0        NaN          NaN       NaN       NaN       NaN
(0.35,0.40]        0        NaN          NaN       NaN       NaN       NaN
(0.40,0.45]        0        NaN          NaN       NaN       NaN       NaN
(0.45,0.50]        0        NaN          NaN       NaN       NaN       NaN
(0.50,0.55]        0        NaN          NaN       NaN       NaN       NaN
(0.55,0.60]        0        NaN          NaN       NaN       NaN       NaN
(0.60,0.65]        0        NaN          NaN       NaN       NaN       NaN
(0.65,0.70]        0        NaN          NaN       NaN       NaN       NaN
(0.70,0.75]        0        NaN          NaN       NaN       NaN       NaN
(0.75,0.80]        0        NaN          NaN       NaN       NaN       NaN
(0.80,0.85]        0        NaN          NaN       NaN       NaN       NaN
(0.85,0.90]        0        NaN          NaN       NaN       NaN       NaN
(0.90,0.95]        0        NaN          NaN       NaN       NaN       NaN
(0.95,1.00]        0        NaN          NaN       NaN       NaN       NaN

Process finished with exit code -1















fit y_l
3 layers
C:\Users\dell-pc\Anaconda3.6\python.exe C:/Users/dell-pc/Quant/Quant/ml_model.py
2013-01-01 2018-12-31
Time slice keys in hdf5: 2013/0101-0101,2014/0101-0101,2015/0101-0101,2016/0101-0101,2017/0101-0101,2018/0101-0101

Current key: 2013/0101-0101
Current slice size(length): 278061
Current subsample size(length): 27806

Current key: 2014/0101-0101
Current slice size(length): 291574
Current subsample size(length): 29157

Current key: 2015/0101-0101
Current slice size(length): 304680
Current subsample size(length): 30468

Current key: 2016/0101-0101
Current slice size(length): 313767
Current subsample size(length): 31376

Current key: 2017/0101-0101
Current slice size(length): 333371
Current subsample size(length): 33337

Current key: 2018/0101-0101
Current slice size(length): 347712
Current subsample size(length): 34771

Total concatenating size: 186915
Result dataset size: 186915
<class 'pandas.core.frame.DataFrame'>
Int64Index: 186915 entries, 20130607 to 20180925
Columns: 2037 entries, (10MA/20MA-1) to vol0
dtypes: float16(1987), float64(44), int64(1), uint8(5)
memory usage: 774.9 MB
None
(95, 8)
          y_l_rise  y_l_decline  y_l_avg  y_s_rise  y_s_decline  y_s_avg  y_l  \
date
20161202       0.0          0.0      NaN       0.0          0.0      NaN  0.0
20161216       0.0          0.0      NaN       0.0          0.0      NaN  0.0
20161208       0.0          0.0      NaN       0.0          0.0      NaN  0.0
20161205       0.0          0.0      NaN       0.0          0.0      NaN  0.0
20161025       0.0          0.0      NaN       0.0          0.0      NaN  0.0
20161026       0.0          0.0      NaN       0.0          0.0      NaN  0.0
20161010       0.0          0.0      NaN       0.0          0.0      NaN  0.0
20161027       0.0          0.0      NaN       0.0          0.0      NaN  0.0
20161117       0.0          0.0      NaN       0.0          0.0      NaN  0.0
20161102       0.0          0.0      NaN       0.0          0.0      NaN  0.0
20160927       0.0          0.0      NaN       0.0          0.0      NaN  0.0
20161214       0.0          0.0      NaN       0.0          0.0      NaN  0.0
20161014       0.0          0.0      NaN       0.0          0.0      NaN  0.0
20161226       0.0          0.0      NaN       0.0          0.0      NaN  0.0
20161020       0.0          0.0      NaN       0.0          0.0      NaN  0.0
20170324       0.0          0.0      NaN       0.0          0.0      NaN  0.0
20170707       0.0          0.0      NaN       0.0          0.0      NaN  0.0
20170926       0.0          0.0      NaN       0.0          0.0      NaN  0.0
20170926       0.0          0.0      NaN       0.0          0.0      NaN  0.0
20170405       0.0          0.0      NaN       0.0          0.0      NaN  0.0

          y_l_r
date
20161202    NaN
20161216    NaN
20161208    NaN
20161205    NaN
20161025    NaN
20161026    NaN
20161010    NaN
20161027    NaN
20161117    NaN
20161102    NaN
20160927    NaN
20161214    NaN
20161014    NaN
20161226    NaN
20161020    NaN
20170324    NaN
20170707    NaN
20170926    NaN
20170926    NaN
20170405    NaN

test period:20160701-20170101
(100028, 2036) (16121, 2036)

--------------------Train network--------------------

 (100028, 2036) (100028,) {'train_indexes': (0, 33342), 'fit': {'categorical_feature': ['area', 'market', 'exchange', 'is_hs']}}

----------Train layer 0----------
slice(0, 33342, None)

Train custom_revenue_y_s_rise
C:\Users\dell-pc\Anaconda3.6\lib\site-packages\lightgbm\basic.py:1042: UserWarning: categorical_feature in Dataset is overridden. New categorical_feature is ['area', 'exchange', 'is_hs', 'market']
  warnings.warn('categorical_feature in Dataset is overridden. New categorical_feature is {}'.format(sorted(list(categorical_feature))))
[LightGBM] [Warning] Using self-defined objective function
[LightGBM] [Warning] Using self-defined objective function
Time usage: 13.10s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=2, max_depth=8, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=10,
       n_jobs=-1, num_leaves=15,
       objective=<function custom_revenue_obj at 0x000001E7431D5EA0>,
       random_state=0, reg_alpha=0.0, reg_lambda=0.0, silent=True,
       subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
                                      feature  importance_raw  \
1705                                   sh_vol              20
2025                                   sz_vol              16
895                                 hs300_vol              16
1160      p240mv_(60k_high-60k_close)/60k_avg              10
357                 (60k_low/p60mv_60k_low-1)              10
1466          p60mv_(20k_low/p20mv_20k_low-1)               9
979     p120mv_(120k_low-120k_close)/120k_avg               9
1526          p80mv_(20k_low/p20mv_20k_low-1)               6
915   p1000mv_(250k_high-250k_close)/250k_avg               6
937        p100mv_(20k_open/p20mv_20k_open-1)               6
908                                    market               5
1009   p1250mv_(250k_low-250k_close)/250k_avg               3
992        p120mv_(60k_low-60k_close)/60k_avg               2
1077                p1mv_(120MA/p1mv_120MA-1)               2
1865                                 sz50_vol               2
466                      (high/p20min_high-1)               2
187           (250k_high/p1250mv_250k_high-1)               2
934        p100mv_(20k_low-20k_close)/20k_avg               2
1151    p240mv_(120k_low-120k_close)/120k_avg               2
194             (250k_low/p1250mv_250k_low-1)               2

      importance_percent
1705               14.29
2025               11.43
895                11.43
1160                7.14
357                 7.14
1466                6.43
979                 6.43
1526                4.29
915                 4.29
937                 4.29
908                 3.57
1009                2.14
992                 1.43
1077                1.43
1865                1.43
466                 1.43
187                 1.43
934                 1.43
1151                1.43
194                 1.43
Among 2036 features, 2010 features are not used in the model

Train custom_revenue2_y_l_rise
[LightGBM] [Warning] Using self-defined objective function
[LightGBM] [Warning] Using self-defined objective function
Time usage: 13.44s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=2, max_depth=8, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=10,
       n_jobs=-1, num_leaves=15,
       objective=<function custom_revenue2_obj at 0x000001E7431E10D0>,
       random_state=0, reg_alpha=0.0, reg_lambda=0.0, silent=True,
       subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
                                    feature  importance_raw  \
567                                     amt              10
1705                                 sh_vol               8
1526        p80mv_(20k_low/p20mv_20k_low-1)               6
1865                               sz50_vol               6
357               (60k_low/p60mv_60k_low-1)               5
1466        p60mv_(20k_low/p20mv_20k_low-1)               5
1160    p240mv_(60k_high-60k_close)/60k_avg               4
568                                    area               4
1014          p1250mv_lower_shadow/250k_avg               4
2025                                 sz_vol               3
936        p100mv_(20k_low/p20mv_20k_low-1)               3
148               (20k_low/p60mv_20k_low-1)               3
1071       p180mv_(60k_low/p60mv_60k_low-1)               3
906                    lower_shadow/60k_avg               2
979   p120mv_(120k_low-120k_close)/120k_avg               2
937      p100mv_(20k_open/p20mv_20k_open-1)               2
1170            p240mv_lower_shadow/60k_avg               2
925           p1000mv_upper_shadow/250k_avg               2
1457        p60mv_(20k_avg/p20mv_20k_avg-1)               2
1108        p20mv_(10k_low/p10mv_10k_low-1)               2

      importance_percent
567                 7.14
1705                5.71
1526                4.29
1865                4.29
357                 3.57
1466                3.57
1160                2.86
568                 2.86
1014                2.86
2025                2.14
936                 2.14
148                 2.14
1071                2.14
906                 1.43
979                 1.43
937                 1.43
1170                1.43
925                 1.43
1457                1.43
1108                1.43
Among 2036 features, 1956 features are not used in the model

Train custom_revenue2_y_l_avg
[LightGBM] [Warning] Using self-defined objective function
[LightGBM] [Warning] Using self-defined objective function
Time usage: 13.51s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=2, max_depth=8, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=10,
       n_jobs=-1, num_leaves=15,
       objective=<function custom_revenue2_obj at 0x000001E7431E10D0>,
       random_state=0, reg_alpha=0.0, reg_lambda=0.0, silent=True,
       subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
                                    feature  importance_raw  \
567                                     amt              10
1705                                 sh_vol               8
1526        p80mv_(20k_low/p20mv_20k_low-1)               6
1865                               sz50_vol               6
357               (60k_low/p60mv_60k_low-1)               5
1466        p60mv_(20k_low/p20mv_20k_low-1)               5
1160    p240mv_(60k_high-60k_close)/60k_avg               4
568                                    area               4
1014          p1250mv_lower_shadow/250k_avg               4
2025                                 sz_vol               3
936        p100mv_(20k_low/p20mv_20k_low-1)               3
148               (20k_low/p60mv_20k_low-1)               3
1071       p180mv_(60k_low/p60mv_60k_low-1)               3
906                    lower_shadow/60k_avg               2
979   p120mv_(120k_low-120k_close)/120k_avg               2
937      p100mv_(20k_open/p20mv_20k_open-1)               2
1170            p240mv_lower_shadow/60k_avg               2
925           p1000mv_upper_shadow/250k_avg               2
1457        p60mv_(20k_avg/p20mv_20k_avg-1)               2
1108        p20mv_(10k_low/p10mv_10k_low-1)               2

      importance_percent
567                 7.14
1705                5.71
1526                4.29
1865                4.29
357                 3.57
1466                3.57
1160                2.86
568                 2.86
1014                2.86
2025                2.14
936                 2.14
148                 2.14
1071                2.14
906                 1.43
979                 1.43
937                 1.43
1170                1.43
925                 1.43
1457                1.43
1108                1.43
Among 2036 features, 1956 features are not used in the model

Train custom_revenue2_y_s_rise
[LightGBM] [Warning] Using self-defined objective function
[LightGBM] [Warning] Using self-defined objective function
Time usage: 13.55s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=2, max_depth=8, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=10,
       n_jobs=-1, num_leaves=15,
       objective=<function custom_revenue2_obj at 0x000001E7431E10D0>,
       random_state=0, reg_alpha=0.0, reg_lambda=0.0, silent=True,
       subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
                                    feature  importance_raw  \
567                                     amt              10
1705                                 sh_vol               8
1526        p80mv_(20k_low/p20mv_20k_low-1)               6
1865                               sz50_vol               6
357               (60k_low/p60mv_60k_low-1)               5
1466        p60mv_(20k_low/p20mv_20k_low-1)               5
1160    p240mv_(60k_high-60k_close)/60k_avg               4
568                                    area               4
1014          p1250mv_lower_shadow/250k_avg               4
2025                                 sz_vol               3
936        p100mv_(20k_low/p20mv_20k_low-1)               3
148               (20k_low/p60mv_20k_low-1)               3
1071       p180mv_(60k_low/p60mv_60k_low-1)               3
906                    lower_shadow/60k_avg               2
979   p120mv_(120k_low-120k_close)/120k_avg               2
937      p100mv_(20k_open/p20mv_20k_open-1)               2
1170            p240mv_lower_shadow/60k_avg               2
925           p1000mv_upper_shadow/250k_avg               2
1457        p60mv_(20k_avg/p20mv_20k_avg-1)               2
1108        p20mv_(10k_low/p10mv_10k_low-1)               2

      importance_percent
567                 7.14
1705                5.71
1526                4.29
1865                4.29
357                 3.57
1466                3.57
1160                2.86
568                 2.86
1014                2.86
2025                2.14
936                 2.14
148                 2.14
1071                2.14
906                 1.43
979                 1.43
937                 1.43
1170                1.43
925                 1.43
1457                1.43
1108                1.43
Among 2036 features, 1956 features are not used in the model

Train custom_revenue_y_l_rise
[LightGBM] [Warning] Using self-defined objective function
[LightGBM] [Warning] Using self-defined objective function
Time usage: 13.85s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=2, max_depth=8, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=10,
       n_jobs=-1, num_leaves=15,
       objective=<function custom_revenue_obj at 0x000001E7431D5EA0>,
       random_state=0, reg_alpha=0.0, reg_lambda=0.0, silent=True,
       subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
                                      feature  importance_raw  \
1705                                   sh_vol              20
2025                                   sz_vol              16
895                                 hs300_vol              16
1160      p240mv_(60k_high-60k_close)/60k_avg              10
357                 (60k_low/p60mv_60k_low-1)              10
1466          p60mv_(20k_low/p20mv_20k_low-1)               9
979     p120mv_(120k_low-120k_close)/120k_avg               9
1526          p80mv_(20k_low/p20mv_20k_low-1)               6
915   p1000mv_(250k_high-250k_close)/250k_avg               6
937        p100mv_(20k_open/p20mv_20k_open-1)               6
908                                    market               5
1009   p1250mv_(250k_low-250k_close)/250k_avg               3
992        p120mv_(60k_low-60k_close)/60k_avg               2
1077                p1mv_(120MA/p1mv_120MA-1)               2
1865                                 sz50_vol               2
466                      (high/p20min_high-1)               2
187           (250k_high/p1250mv_250k_high-1)               2
934        p100mv_(20k_low-20k_close)/20k_avg               2
1151    p240mv_(120k_low-120k_close)/120k_avg               2
194             (250k_low/p1250mv_250k_low-1)               2

      importance_percent
1705               14.29
2025               11.43
895                11.43
1160                7.14
357                 7.14
1466                6.43
979                 6.43
1526                4.29
915                 4.29
937                 4.29
908                 3.57
1009                2.14
992                 1.43
1077                1.43
1865                1.43
466                 1.43
187                 1.43
934                 1.43
1151                1.43
194                 1.43
Among 2036 features, 2010 features are not used in the model

Train custom_revenue2_y_s_decline
[LightGBM] [Warning] Using self-defined objective function
[LightGBM] [Warning] Using self-defined objective function
Time usage: 13.70s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=2, max_depth=8, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=10,
       n_jobs=-1, num_leaves=15,
       objective=<function custom_revenue2_obj at 0x000001E7431E10D0>,
       random_state=0, reg_alpha=0.0, reg_lambda=0.0, silent=True,
       subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
                                    feature  importance_raw  \
567                                     amt              10
1705                                 sh_vol               8
1526        p80mv_(20k_low/p20mv_20k_low-1)               6
1865                               sz50_vol               6
357               (60k_low/p60mv_60k_low-1)               5
1466        p60mv_(20k_low/p20mv_20k_low-1)               5
1160    p240mv_(60k_high-60k_close)/60k_avg               4
568                                    area               4
1014          p1250mv_lower_shadow/250k_avg               4
2025                                 sz_vol               3
936        p100mv_(20k_low/p20mv_20k_low-1)               3
148               (20k_low/p60mv_20k_low-1)               3
1071       p180mv_(60k_low/p60mv_60k_low-1)               3
906                    lower_shadow/60k_avg               2
979   p120mv_(120k_low-120k_close)/120k_avg               2
937      p100mv_(20k_open/p20mv_20k_open-1)               2
1170            p240mv_lower_shadow/60k_avg               2
925           p1000mv_upper_shadow/250k_avg               2
1457        p60mv_(20k_avg/p20mv_20k_avg-1)               2
1108        p20mv_(10k_low/p10mv_10k_low-1)               2

      importance_percent
567                 7.14
1705                5.71
1526                4.29
1865                4.29
357                 3.57
1466                3.57
1160                2.86
568                 2.86
1014                2.86
2025                2.14
936                 2.14
148                 2.14
1071                2.14
906                 1.43
979                 1.43
937                 1.43
1170                1.43
925                 1.43
1457                1.43
1108                1.43
Among 2036 features, 1956 features are not used in the model

Train custom_revenue_y_s_avg
[LightGBM] [Warning] Using self-defined objective function
[LightGBM] [Warning] Using self-defined objective function
Time usage: 13.73s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=2, max_depth=8, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=10,
       n_jobs=-1, num_leaves=15,
       objective=<function custom_revenue_obj at 0x000001E7431D5EA0>,
       random_state=0, reg_alpha=0.0, reg_lambda=0.0, silent=True,
       subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
                                      feature  importance_raw  \
1705                                   sh_vol              20
2025                                   sz_vol              16
895                                 hs300_vol              16
1160      p240mv_(60k_high-60k_close)/60k_avg              10
357                 (60k_low/p60mv_60k_low-1)              10
1466          p60mv_(20k_low/p20mv_20k_low-1)               9
979     p120mv_(120k_low-120k_close)/120k_avg               9
1526          p80mv_(20k_low/p20mv_20k_low-1)               6
915   p1000mv_(250k_high-250k_close)/250k_avg               6
937        p100mv_(20k_open/p20mv_20k_open-1)               6
908                                    market               5
1009   p1250mv_(250k_low-250k_close)/250k_avg               3
992        p120mv_(60k_low-60k_close)/60k_avg               2
1077                p1mv_(120MA/p1mv_120MA-1)               2
1865                                 sz50_vol               2
466                      (high/p20min_high-1)               2
187           (250k_high/p1250mv_250k_high-1)               2
934        p100mv_(20k_low-20k_close)/20k_avg               2
1151    p240mv_(120k_low-120k_close)/120k_avg               2
194             (250k_low/p1250mv_250k_low-1)               2

      importance_percent
1705               14.29
2025               11.43
895                11.43
1160                7.14
357                 7.14
1466                6.43
979                 6.43
1526                4.29
915                 4.29
937                 4.29
908                 3.57
1009                2.14
992                 1.43
1077                1.43
1865                1.43
466                 1.43
187                 1.43
934                 1.43
1151                1.43
194                 1.43
Among 2036 features, 2010 features are not used in the model

Train custom_revenue_y_s_decline
[LightGBM] [Warning] Using self-defined objective function
[LightGBM] [Warning] Using self-defined objective function
Time usage: 14.00s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=2, max_depth=8, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=10,
       n_jobs=-1, num_leaves=15,
       objective=<function custom_revenue_obj at 0x000001E7431D5EA0>,
       random_state=0, reg_alpha=0.0, reg_lambda=0.0, silent=True,
       subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
                                      feature  importance_raw  \
1705                                   sh_vol              20
2025                                   sz_vol              16
895                                 hs300_vol              16
1160      p240mv_(60k_high-60k_close)/60k_avg              10
357                 (60k_low/p60mv_60k_low-1)              10
1466          p60mv_(20k_low/p20mv_20k_low-1)               9
979     p120mv_(120k_low-120k_close)/120k_avg               9
1526          p80mv_(20k_low/p20mv_20k_low-1)               6
915   p1000mv_(250k_high-250k_close)/250k_avg               6
937        p100mv_(20k_open/p20mv_20k_open-1)               6
908                                    market               5
1009   p1250mv_(250k_low-250k_close)/250k_avg               3
992        p120mv_(60k_low-60k_close)/60k_avg               2
1077                p1mv_(120MA/p1mv_120MA-1)               2
1865                                 sz50_vol               2
466                      (high/p20min_high-1)               2
187           (250k_high/p1250mv_250k_high-1)               2
934        p100mv_(20k_low-20k_close)/20k_avg               2
1151    p240mv_(120k_low-120k_close)/120k_avg               2
194             (250k_low/p1250mv_250k_low-1)               2

      importance_percent
1705               14.29
2025               11.43
895                11.43
1160                7.14
357                 7.14
1466                6.43
979                 6.43
1526                4.29
915                 4.29
937                 4.29
908                 3.57
1009                2.14
992                 1.43
1077                1.43
1865                1.43
466                 1.43
187                 1.43
934                 1.43
1151                1.43
194                 1.43
Among 2036 features, 2010 features are not used in the model

Train custom_revenue2_y_s_avg
[LightGBM] [Warning] Using self-defined objective function
[LightGBM] [Warning] Using self-defined objective function
Time usage: 13.91s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=2, max_depth=8, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=10,
       n_jobs=-1, num_leaves=15,
       objective=<function custom_revenue2_obj at 0x000001E7431E10D0>,
       random_state=0, reg_alpha=0.0, reg_lambda=0.0, silent=True,
       subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
                                    feature  importance_raw  \
567                                     amt              10
1705                                 sh_vol               8
1526        p80mv_(20k_low/p20mv_20k_low-1)               6
1865                               sz50_vol               6
357               (60k_low/p60mv_60k_low-1)               5
1466        p60mv_(20k_low/p20mv_20k_low-1)               5
1160    p240mv_(60k_high-60k_close)/60k_avg               4
568                                    area               4
1014          p1250mv_lower_shadow/250k_avg               4
2025                                 sz_vol               3
936        p100mv_(20k_low/p20mv_20k_low-1)               3
148               (20k_low/p60mv_20k_low-1)               3
1071       p180mv_(60k_low/p60mv_60k_low-1)               3
906                    lower_shadow/60k_avg               2
979   p120mv_(120k_low-120k_close)/120k_avg               2
937      p100mv_(20k_open/p20mv_20k_open-1)               2
1170            p240mv_lower_shadow/60k_avg               2
925           p1000mv_upper_shadow/250k_avg               2
1457        p60mv_(20k_avg/p20mv_20k_avg-1)               2
1108        p20mv_(10k_low/p10mv_10k_low-1)               2

      importance_percent
567                 7.14
1705                5.71
1526                4.29
1865                4.29
357                 3.57
1466                3.57
1160                2.86
568                 2.86
1014                2.86
2025                2.14
936                 2.14
148                 2.14
1071                2.14
906                 1.43
979                 1.43
937                 1.43
1170                1.43
925                 1.43
1457                1.43
1108                1.43
Among 2036 features, 1956 features are not used in the model

Train custom_revenue_y_l_avg
[LightGBM] [Warning] Using self-defined objective function
[LightGBM] [Warning] Using self-defined objective function
Time usage: 14.02s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=2, max_depth=8, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=10,
       n_jobs=-1, num_leaves=15,
       objective=<function custom_revenue_obj at 0x000001E7431D5EA0>,
       random_state=0, reg_alpha=0.0, reg_lambda=0.0, silent=True,
       subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
                                      feature  importance_raw  \
1705                                   sh_vol              20
2025                                   sz_vol              16
895                                 hs300_vol              16
1160      p240mv_(60k_high-60k_close)/60k_avg              10
357                 (60k_low/p60mv_60k_low-1)              10
1466          p60mv_(20k_low/p20mv_20k_low-1)               9
979     p120mv_(120k_low-120k_close)/120k_avg               9
1526          p80mv_(20k_low/p20mv_20k_low-1)               6
915   p1000mv_(250k_high-250k_close)/250k_avg               6
937        p100mv_(20k_open/p20mv_20k_open-1)               6
908                                    market               5
1009   p1250mv_(250k_low-250k_close)/250k_avg               3
992        p120mv_(60k_low-60k_close)/60k_avg               2
1077                p1mv_(120MA/p1mv_120MA-1)               2
1865                                 sz50_vol               2
466                      (high/p20min_high-1)               2
187           (250k_high/p1250mv_250k_high-1)               2
934        p100mv_(20k_low-20k_close)/20k_avg               2
1151    p240mv_(120k_low-120k_close)/120k_avg               2
194             (250k_low/p1250mv_250k_low-1)               2

      importance_percent
1705               14.29
2025               11.43
895                11.43
1160                7.14
357                 7.14
1466                6.43
979                 6.43
1526                4.29
915                 4.29
937                 4.29
908                 3.57
1009                2.14
992                 1.43
1077                1.43
1865                1.43
466                 1.43
187                 1.43
934                 1.43
1151                1.43
194                 1.43
Among 2036 features, 2010 features are not used in the model

Train custom_revenue2_y_l_decline
[LightGBM] [Warning] Using self-defined objective function
[LightGBM] [Warning] Using self-defined objective function
Time usage: 14.01s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=2, max_depth=8, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=10,
       n_jobs=-1, num_leaves=15,
       objective=<function custom_revenue2_obj at 0x000001E7431E10D0>,
       random_state=0, reg_alpha=0.0, reg_lambda=0.0, silent=True,
       subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
                                    feature  importance_raw  \
567                                     amt              10
1705                                 sh_vol               8
1526        p80mv_(20k_low/p20mv_20k_low-1)               6
1865                               sz50_vol               6
357               (60k_low/p60mv_60k_low-1)               5
1466        p60mv_(20k_low/p20mv_20k_low-1)               5
1160    p240mv_(60k_high-60k_close)/60k_avg               4
568                                    area               4
1014          p1250mv_lower_shadow/250k_avg               4
2025                                 sz_vol               3
936        p100mv_(20k_low/p20mv_20k_low-1)               3
148               (20k_low/p60mv_20k_low-1)               3
1071       p180mv_(60k_low/p60mv_60k_low-1)               3
906                    lower_shadow/60k_avg               2
979   p120mv_(120k_low-120k_close)/120k_avg               2
937      p100mv_(20k_open/p20mv_20k_open-1)               2
1170            p240mv_lower_shadow/60k_avg               2
925           p1000mv_upper_shadow/250k_avg               2
1457        p60mv_(20k_avg/p20mv_20k_avg-1)               2
1108        p20mv_(10k_low/p10mv_10k_low-1)               2

      importance_percent
567                 7.14
1705                5.71
1526                4.29
1865                4.29
357                 3.57
1466                3.57
1160                2.86
568                 2.86
1014                2.86
2025                2.14
936                 2.14
148                 2.14
1071                2.14
906                 1.43
979                 1.43
937                 1.43
1170                1.43
925                 1.43
1457                1.43
1108                1.43
Among 2036 features, 1956 features are not used in the model

Train custom_revenue_y_l_decline
[LightGBM] [Warning] Using self-defined objective function
[LightGBM] [Warning] Using self-defined objective function
Time usage: 14.12s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=2, max_depth=8, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=10,
       n_jobs=-1, num_leaves=15,
       objective=<function custom_revenue_obj at 0x000001E7431D5EA0>,
       random_state=0, reg_alpha=0.0, reg_lambda=0.0, silent=True,
       subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
                                      feature  importance_raw  \
1705                                   sh_vol              20
2025                                   sz_vol              16
895                                 hs300_vol              16
1160      p240mv_(60k_high-60k_close)/60k_avg              10
357                 (60k_low/p60mv_60k_low-1)              10
1466          p60mv_(20k_low/p20mv_20k_low-1)               9
979     p120mv_(120k_low-120k_close)/120k_avg               9
1526          p80mv_(20k_low/p20mv_20k_low-1)               6
915   p1000mv_(250k_high-250k_close)/250k_avg               6
937        p100mv_(20k_open/p20mv_20k_open-1)               6
908                                    market               5
1009   p1250mv_(250k_low-250k_close)/250k_avg               3
992        p120mv_(60k_low-60k_close)/60k_avg               2
1077                p1mv_(120MA/p1mv_120MA-1)               2
1865                                 sz50_vol               2
466                      (high/p20min_high-1)               2
187           (250k_high/p1250mv_250k_high-1)               2
934        p100mv_(20k_low-20k_close)/20k_avg               2
1151    p240mv_(120k_low-120k_close)/120k_avg               2
194             (250k_low/p1250mv_250k_low-1)               2

      importance_percent
1705               14.29
2025               11.43
895                11.43
1160                7.14
357                 7.14
1466                6.43
979                 6.43
1526                4.29
915                 4.29
937                 4.29
908                 3.57
1009                2.14
992                 1.43
1077                1.43
1865                1.43
466                 1.43
187                 1.43
934                 1.43
1151                1.43
194                 1.43
Among 2036 features, 2010 features are not used in the model

----------Layer 0 predicts----------

 (100028, 2180) (100028,) {'train_indexes': (33342, 66684), 'fit': {'categorical_feature': ['area', 'market', 'exchange', 'is_hs']}}

----------Train layer 1----------
slice(33342, 66684, None)

Train l2_y_l_rise
[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves
[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves
Time usage: 21.03s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=0.2, max_depth=12, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=25,
       n_jobs=-1, num_leaves=31, objective=None, random_state=0,
       reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,
       subsample_for_bin=200000, subsample_freq=0)
                                      feature  importance_raw  \
568                                      area              33
2025                                   sz_vol              25
1865                                 sz50_vol              18
895                                 hs300_vol              14
1235         p300mv_(60k_low/p60mv_60k_low-1)              10
1511      p750mv_(250k_low/p250mv_250k_low-1)               8
1505   p750mv_(250k_high-250k_close)/250k_avg               7
1705                                   sh_vol               7
1241          p30mv_(10k_avg/p10mv_10k_avg-1)               7
567                                       amt               7
2035                                     vol0               6
1238              p300mv_lower_shadow/60k_avg               6
454                            (high-low)/avg               6
915   p1000mv_(250k_high-250k_close)/250k_avg               5
1250          p30mv_(10k_low/p10mv_10k_low-1)               5
2048     layer0_custom_revenue2_y_l_rise_pred               5
1166         p240mv_(60k_low/p60mv_60k_low-1)               5
2034                                      vol               5
154               (20k_open/p60mv_20k_open-1)               5
1116         p20mv_(20k_high-20k_low)/20k_avg               4

      importance_percent
568                 4.40
2025                3.33
1865                2.40
895                 1.87
1235                1.33
1511                1.07
1505                0.93
1705                0.93
1241                0.93
567                 0.93
2035                0.80
1238                0.80
454                 0.80
915                 0.67
1250                0.67
2048                0.67
1166                0.67
2034                0.67
154                 0.67
1116                0.53
Among 2180 features, 1755 features are not used in the model

Train l2_y_s_avg
[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves
[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves
Time usage: 21.24s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=0.2, max_depth=12, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=25,
       n_jobs=-1, num_leaves=31, objective=None, random_state=0,
       reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,
       subsample_for_bin=200000, subsample_freq=0)
                                      feature  importance_raw  \
568                                      area              33
2025                                   sz_vol              25
1865                                 sz50_vol              18
895                                 hs300_vol              14
1235         p300mv_(60k_low/p60mv_60k_low-1)              10
1511      p750mv_(250k_low/p250mv_250k_low-1)               8
1505   p750mv_(250k_high-250k_close)/250k_avg               7
1705                                   sh_vol               7
1241          p30mv_(10k_avg/p10mv_10k_avg-1)               7
567                                       amt               7
2035                                     vol0               6
1238              p300mv_lower_shadow/60k_avg               6
454                            (high-low)/avg               6
915   p1000mv_(250k_high-250k_close)/250k_avg               5
1250          p30mv_(10k_low/p10mv_10k_low-1)               5
2048     layer0_custom_revenue2_y_l_rise_pred               5
1166         p240mv_(60k_low/p60mv_60k_low-1)               5
2034                                      vol               5
154               (20k_open/p60mv_20k_open-1)               5
1116         p20mv_(20k_high-20k_low)/20k_avg               4

      importance_percent
568                 4.40
2025                3.33
1865                2.40
895                 1.87
1235                1.33
1511                1.07
1505                0.93
1705                0.93
1241                0.93
567                 0.93
2035                0.80
1238                0.80
454                 0.80
915                 0.67
1250                0.67
2048                0.67
1166                0.67
2034                0.67
154                 0.67
1116                0.53
Among 2180 features, 1755 features are not used in the model

Train l2_y_s_rise
[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves
[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves
Time usage: 21.49s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=0.2, max_depth=12, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=25,
       n_jobs=-1, num_leaves=31, objective=None, random_state=0,
       reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,
       subsample_for_bin=200000, subsample_freq=0)
                                      feature  importance_raw  \
568                                      area              33
2025                                   sz_vol              25
1865                                 sz50_vol              18
895                                 hs300_vol              14
1235         p300mv_(60k_low/p60mv_60k_low-1)              10
1511      p750mv_(250k_low/p250mv_250k_low-1)               8
1505   p750mv_(250k_high-250k_close)/250k_avg               7
1705                                   sh_vol               7
1241          p30mv_(10k_avg/p10mv_10k_avg-1)               7
567                                       amt               7
2035                                     vol0               6
1238              p300mv_lower_shadow/60k_avg               6
454                            (high-low)/avg               6
915   p1000mv_(250k_high-250k_close)/250k_avg               5
1250          p30mv_(10k_low/p10mv_10k_low-1)               5
2048     layer0_custom_revenue2_y_l_rise_pred               5
1166         p240mv_(60k_low/p60mv_60k_low-1)               5
2034                                      vol               5
154               (20k_open/p60mv_20k_open-1)               5
1116         p20mv_(20k_high-20k_low)/20k_avg               4

      importance_percent
568                 4.40
2025                3.33
1865                2.40
895                 1.87
1235                1.33
1511                1.07
1505                0.93
1705                0.93
1241                0.93
567                 0.93
2035                0.80
1238                0.80
454                 0.80
915                 0.67
1250                0.67
2048                0.67
1166                0.67
2034                0.67
154                 0.67
1116                0.53
Among 2180 features, 1755 features are not used in the model

Train l2_y_l_decline
[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves
[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves
Time usage: 21.55s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=0.2, max_depth=12, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=25,
       n_jobs=-1, num_leaves=31, objective=None, random_state=0,
       reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,
       subsample_for_bin=200000, subsample_freq=0)
                                      feature  importance_raw  \
568                                      area              33
2025                                   sz_vol              25
1865                                 sz50_vol              18
895                                 hs300_vol              14
1235         p300mv_(60k_low/p60mv_60k_low-1)              10
1511      p750mv_(250k_low/p250mv_250k_low-1)               8
1505   p750mv_(250k_high-250k_close)/250k_avg               7
1705                                   sh_vol               7
1241          p30mv_(10k_avg/p10mv_10k_avg-1)               7
567                                       amt               7
2035                                     vol0               6
1238              p300mv_lower_shadow/60k_avg               6
454                            (high-low)/avg               6
915   p1000mv_(250k_high-250k_close)/250k_avg               5
1250          p30mv_(10k_low/p10mv_10k_low-1)               5
2048     layer0_custom_revenue2_y_l_rise_pred               5
1166         p240mv_(60k_low/p60mv_60k_low-1)               5
2034                                      vol               5
154               (20k_open/p60mv_20k_open-1)               5
1116         p20mv_(20k_high-20k_low)/20k_avg               4

      importance_percent
568                 4.40
2025                3.33
1865                2.40
895                 1.87
1235                1.33
1511                1.07
1505                0.93
1705                0.93
1241                0.93
567                 0.93
2035                0.80
1238                0.80
454                 0.80
915                 0.67
1250                0.67
2048                0.67
1166                0.67
2034                0.67
154                 0.67
1116                0.53
Among 2180 features, 1755 features are not used in the model

Train l2_y_l_avg
[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves
[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves
Time usage: 22.14s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=0.2, max_depth=12, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=25,
       n_jobs=-1, num_leaves=31, objective=None, random_state=0,
       reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,
       subsample_for_bin=200000, subsample_freq=0)
                                      feature  importance_raw  \
568                                      area              33
2025                                   sz_vol              25
1865                                 sz50_vol              18
895                                 hs300_vol              14
1235         p300mv_(60k_low/p60mv_60k_low-1)              10
1511      p750mv_(250k_low/p250mv_250k_low-1)               8
1505   p750mv_(250k_high-250k_close)/250k_avg               7
1705                                   sh_vol               7
1241          p30mv_(10k_avg/p10mv_10k_avg-1)               7
567                                       amt               7
2035                                     vol0               6
1238              p300mv_lower_shadow/60k_avg               6
454                            (high-low)/avg               6
915   p1000mv_(250k_high-250k_close)/250k_avg               5
1250          p30mv_(10k_low/p10mv_10k_low-1)               5
2048     layer0_custom_revenue2_y_l_rise_pred               5
1166         p240mv_(60k_low/p60mv_60k_low-1)               5
2034                                      vol               5
154               (20k_open/p60mv_20k_open-1)               5
1116         p20mv_(20k_high-20k_low)/20k_avg               4

      importance_percent
568                 4.40
2025                3.33
1865                2.40
895                 1.87
1235                1.33
1511                1.07
1505                0.93
1705                0.93
1241                0.93
567                 0.93
2035                0.80
1238                0.80
454                 0.80
915                 0.67
1250                0.67
2048                0.67
1166                0.67
2034                0.67
154                 0.67
1116                0.53
Among 2180 features, 1755 features are not used in the model

Train l2_y_s_decline
[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves
[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves
Time usage: 21.35s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=0.2, max_depth=12, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=25,
       n_jobs=-1, num_leaves=31, objective=None, random_state=0,
       reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,
       subsample_for_bin=200000, subsample_freq=0)
                                      feature  importance_raw  \
568                                      area              33
2025                                   sz_vol              25
1865                                 sz50_vol              18
895                                 hs300_vol              14
1235         p300mv_(60k_low/p60mv_60k_low-1)              10
1511      p750mv_(250k_low/p250mv_250k_low-1)               8
1505   p750mv_(250k_high-250k_close)/250k_avg               7
1705                                   sh_vol               7
1241          p30mv_(10k_avg/p10mv_10k_avg-1)               7
567                                       amt               7
2035                                     vol0               6
1238              p300mv_lower_shadow/60k_avg               6
454                            (high-low)/avg               6
915   p1000mv_(250k_high-250k_close)/250k_avg               5
1250          p30mv_(10k_low/p10mv_10k_low-1)               5
2048     layer0_custom_revenue2_y_l_rise_pred               5
1166         p240mv_(60k_low/p60mv_60k_low-1)               5
2034                                      vol               5
154               (20k_open/p60mv_20k_open-1)               5
1116         p20mv_(20k_high-20k_low)/20k_avg               4

      importance_percent
568                 4.40
2025                3.33
1865                2.40
895                 1.87
1235                1.33
1511                1.07
1505                0.93
1705                0.93
1241                0.93
567                 0.93
2035                0.80
1238                0.80
454                 0.80
915                 0.67
1250                0.67
2048                0.67
1166                0.67
2034                0.67
154                 0.67
1116                0.53
Among 2180 features, 1755 features are not used in the model

----------Layer 1 predicts----------

 (100028, 2336) (100028,) {'train_indexes': (66684, None), 'fit': {'categorical_feature': ['area', 'market', 'exchange', 'is_hs']}}

----------Train layer 2----------
slice(66684, None, None)

Train l2_y_l_r
[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves
[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves
Time usage: 33.30s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=0.1, max_depth=12, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=50,
       n_jobs=-1, num_leaves=31, objective=None, random_state=0,
       reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,
       subsample_for_bin=200000, subsample_freq=0)
                                         feature  importance_raw  \
2025                                      sz_vol              72
1865                                    sz50_vol              65
1705                                      sh_vol              53
895                                    hs300_vol              48
567                                          amt              36
732                                      cyb_vol              23
568                                         area              18
1449       p600mv_(120k_low-120k_close)/120k_avg              15
1350                p480mv_lower_shadow/120k_avg              13
1241             p30mv_(10k_avg/p10mv_10k_avg-1)              12
1321             p40mv_(20k_avg/p20mv_20k_avg-1)              11
2053  layer0_custom_revenue2_y_l_rise_tree3_leaf              11
1062            p180mv_(60k_avg/p60mv_60k_avg-1)              11
2180                     layer1_l2_y_l_rise_pred              11
454                               (high-low)/avg              11
1000                 p120mv_upper_shadow/60k_avg              11
1264        p360mv_(120k_low-120k_open)/120k_avg              10
1237            p300mv_(60k_vol/p60mv_60k_vol-1)               9
430                      (close/p120max_close-1)               9
927             p100mv_(20k_avg/p20mv_20k_avg-1)               9

      importance_percent
2025                4.80
1865                4.33
1705                3.53
895                 3.20
567                 2.40
732                 1.53
568                 1.20
1449                1.00
1350                0.87
1241                0.80
1321                0.73
2053                0.73
1062                0.73
2180                0.73
454                 0.73
1000                0.73
1264                0.67
1237                0.60
430                 0.60
927                 0.60
Among 2336 features, 1794 features are not used in the model

--------------------Predict--------------------

----------Layer 0 predicts----------

----------Layer 1 predicts----------

----------Layer 2 predicts----------

y_l_r
               count  eval_mean  eval_median  eval_std  eval_max  eval_min
pred_range
(-1.00,-0.95]      0        NaN          NaN       NaN       NaN       NaN
(-0.95,-0.90]      0        NaN          NaN       NaN       NaN       NaN
(-0.90,-0.85]      0        NaN          NaN       NaN       NaN       NaN
(-0.85,-0.80]      0        NaN          NaN       NaN       NaN       NaN
(-0.80,-0.75]      0        NaN          NaN       NaN       NaN       NaN
(-0.75,-0.70]      0        NaN          NaN       NaN       NaN       NaN
(-0.70,-0.65]      0        NaN          NaN       NaN       NaN       NaN
(-0.65,-0.60]      0        NaN          NaN       NaN       NaN       NaN
(-0.60,-0.55]      0        NaN          NaN       NaN       NaN       NaN
(-0.55,-0.50]      0        NaN          NaN       NaN       NaN       NaN
(-0.50,-0.45]      0        NaN          NaN       NaN       NaN       NaN
(-0.45,-0.40]      0        NaN          NaN       NaN       NaN       NaN
(-0.40,-0.35]      0        NaN          NaN       NaN       NaN       NaN
(-0.35,-0.30]      0        NaN          NaN       NaN       NaN       NaN
(-0.30,-0.25]      0        NaN          NaN       NaN       NaN       NaN
(-0.25,-0.20]      7      0.023        0.112     0.137     0.149    -0.189
(-0.20,-0.15]     39      0.003        0.041     0.134     0.246    -0.222
(-0.15,-0.10]    255     -0.010       -0.068     0.125     0.599    -0.231
(-0.10,-0.05]    931     -0.008       -0.047     0.109     0.449    -0.253
(-0.05,0.00]    3606      0.010        0.000     0.102     0.683    -0.293
(0.00,0.05]     5880      0.016        0.000     0.099     1.027    -0.331
(0.05,0.10]     3872      0.014        0.031     0.104     0.819    -0.320
(0.10,0.15]     1276      0.002        0.000     0.117     0.995    -0.269
(0.15,0.20]      205      0.009        0.028     0.136     0.568    -0.256
(0.20,0.25]       39     -0.008       -0.052     0.155     0.417    -0.275
(0.25,0.30]       10     -0.036       -0.109     0.172     0.278    -0.193
(0.30,0.35]        0        NaN          NaN       NaN       NaN       NaN
(0.35,0.40]        1     -0.139       -0.139       NaN    -0.139    -0.139
(0.40,0.45]        0        NaN          NaN       NaN       NaN       NaN
(0.45,0.50]        0        NaN          NaN       NaN       NaN       NaN
(0.50,0.55]        0        NaN          NaN       NaN       NaN       NaN
(0.55,0.60]        0        NaN          NaN       NaN       NaN       NaN
(0.60,0.65]        0        NaN          NaN       NaN       NaN       NaN
(0.65,0.70]        0        NaN          NaN       NaN       NaN       NaN
(0.70,0.75]        0        NaN          NaN       NaN       NaN       NaN
(0.75,0.80]        0        NaN          NaN       NaN       NaN       NaN
(0.80,0.85]        0        NaN          NaN       NaN       NaN       NaN
(0.85,0.90]        0        NaN          NaN       NaN       NaN       NaN
(0.90,0.95]        0        NaN          NaN       NaN       NaN       NaN
(0.95,1.00]        0        NaN          NaN       NaN       NaN       NaN

y_l
               count  eval_mean  eval_median  eval_std  eval_max  eval_min
pred_range
(-1.00,-0.95]      0        NaN          NaN       NaN       NaN       NaN
(-0.95,-0.90]      0        NaN          NaN       NaN       NaN       NaN
(-0.90,-0.85]      0        NaN          NaN       NaN       NaN       NaN
(-0.85,-0.80]      0        NaN          NaN       NaN       NaN       NaN
(-0.80,-0.75]      0        NaN          NaN       NaN       NaN       NaN
(-0.75,-0.70]      0        NaN          NaN       NaN       NaN       NaN
(-0.70,-0.65]      0        NaN          NaN       NaN       NaN       NaN
(-0.65,-0.60]      0        NaN          NaN       NaN       NaN       NaN
(-0.60,-0.55]      0        NaN          NaN       NaN       NaN       NaN
(-0.55,-0.50]      0        NaN          NaN       NaN       NaN       NaN
(-0.50,-0.45]      0        NaN          NaN       NaN       NaN       NaN
(-0.45,-0.40]      0        NaN          NaN       NaN       NaN       NaN
(-0.40,-0.35]      0        NaN          NaN       NaN       NaN       NaN
(-0.35,-0.30]      0        NaN          NaN       NaN       NaN       NaN
(-0.30,-0.25]      0        NaN          NaN       NaN       NaN       NaN
(-0.25,-0.20]      7      0.026        0.128     0.159     0.174    -0.214
(-0.20,-0.15]     39     -0.009       -0.073     0.159     0.286    -0.251
(-0.15,-0.10]    255     -0.015       -0.083     0.148     0.689    -0.262
(-0.10,-0.05]    931     -0.013       -0.064     0.129     0.526    -0.296
(-0.05,0.00]    3606      0.010        0.000     0.120     0.775    -0.333
(0.00,0.05]     5880      0.018        0.000     0.116     1.231    -0.364
(0.05,0.10]     3872      0.013        0.033     0.123     0.910    -0.363
(0.10,0.15]     1276     -0.004       -0.047     0.139     1.168    -0.319
(0.15,0.20]      205      0.007       -0.049     0.162     0.644    -0.302
(0.20,0.25]       39     -0.007       -0.065     0.186     0.505    -0.316
(0.25,0.30]       10     -0.043       -0.129     0.206     0.324    -0.239
(0.30,0.35]        0        NaN          NaN       NaN       NaN       NaN
(0.35,0.40]        1     -0.159       -0.159       NaN    -0.159    -0.159
(0.40,0.45]        0        NaN          NaN       NaN       NaN       NaN
(0.45,0.50]        0        NaN          NaN       NaN       NaN       NaN
(0.50,0.55]        0        NaN          NaN       NaN       NaN       NaN
(0.55,0.60]        0        NaN          NaN       NaN       NaN       NaN
(0.60,0.65]        0        NaN          NaN       NaN       NaN       NaN
(0.65,0.70]        0        NaN          NaN       NaN       NaN       NaN
(0.70,0.75]        0        NaN          NaN       NaN       NaN       NaN
(0.75,0.80]        0        NaN          NaN       NaN       NaN       NaN
(0.80,0.85]        0        NaN          NaN       NaN       NaN       NaN
(0.85,0.90]        0        NaN          NaN       NaN       NaN       NaN
(0.90,0.95]        0        NaN          NaN       NaN       NaN       NaN
(0.95,1.00]        0        NaN          NaN       NaN       NaN       NaN

y_l_avg
               count  eval_mean  eval_median  eval_std  eval_max  eval_min
pred_range
(-1.00,-0.95]      0        NaN          NaN       NaN       NaN       NaN
(-0.95,-0.90]      0        NaN          NaN       NaN       NaN       NaN
(-0.90,-0.85]      0        NaN          NaN       NaN       NaN       NaN
(-0.85,-0.80]      0        NaN          NaN       NaN       NaN       NaN
(-0.80,-0.75]      0        NaN          NaN       NaN       NaN       NaN
(-0.75,-0.70]      0        NaN          NaN       NaN       NaN       NaN
(-0.70,-0.65]      0        NaN          NaN       NaN       NaN       NaN
(-0.65,-0.60]      0        NaN          NaN       NaN       NaN       NaN
(-0.60,-0.55]      0        NaN          NaN       NaN       NaN       NaN
(-0.55,-0.50]      0        NaN          NaN       NaN       NaN       NaN
(-0.50,-0.45]      0        NaN          NaN       NaN       NaN       NaN
(-0.45,-0.40]      0        NaN          NaN       NaN       NaN       NaN
(-0.40,-0.35]      0        NaN          NaN       NaN       NaN       NaN
(-0.35,-0.30]      0        NaN          NaN       NaN       NaN       NaN
(-0.30,-0.25]      0        NaN          NaN       NaN       NaN       NaN
(-0.25,-0.20]      7      0.013        0.050     0.070     0.074    -0.114
(-0.20,-0.15]     39     -0.002        0.004     0.065     0.137    -0.135
(-0.15,-0.10]    255     -0.004       -0.015     0.060     0.329    -0.139
(-0.10,-0.05]    931     -0.003       -0.008     0.053     0.266    -0.148
(-0.05,0.00]    3606      0.005        0.000     0.051     0.470    -0.174
(0.00,0.05]     5880      0.008        0.000     0.051     0.566    -0.230
(0.05,0.10]     3872      0.008        0.004     0.053     0.544    -0.195
(0.10,0.15]     1276      0.004        0.000     0.057     0.474    -0.173
(0.15,0.20]      205      0.008        0.002     0.066     0.337    -0.176
(0.20,0.25]       39     -0.005       -0.005     0.069     0.155    -0.151
(0.25,0.30]       10     -0.014       -0.032     0.075     0.141    -0.090
(0.30,0.35]        0        NaN          NaN       NaN       NaN       NaN
(0.35,0.40]        1     -0.077       -0.077       NaN    -0.077    -0.077
(0.40,0.45]        0        NaN          NaN       NaN       NaN       NaN
(0.45,0.50]        0        NaN          NaN       NaN       NaN       NaN
(0.50,0.55]        0        NaN          NaN       NaN       NaN       NaN
(0.55,0.60]        0        NaN          NaN       NaN       NaN       NaN
(0.60,0.65]        0        NaN          NaN       NaN       NaN       NaN
(0.65,0.70]        0        NaN          NaN       NaN       NaN       NaN
(0.70,0.75]        0        NaN          NaN       NaN       NaN       NaN
(0.75,0.80]        0        NaN          NaN       NaN       NaN       NaN
(0.80,0.85]        0        NaN          NaN       NaN       NaN       NaN
(0.85,0.90]        0        NaN          NaN       NaN       NaN       NaN
(0.90,0.95]        0        NaN          NaN       NaN       NaN       NaN
(0.95,1.00]        0        NaN          NaN       NaN       NaN       NaN

y_l_rise
               count  eval_mean  eval_median  eval_std  eval_max  eval_min
pred_range
(-1.00,-0.95]      0        NaN          NaN       NaN       NaN       NaN
(-0.95,-0.90]      0        NaN          NaN       NaN       NaN       NaN
(-0.90,-0.85]      0        NaN          NaN       NaN       NaN       NaN
(-0.85,-0.80]      0        NaN          NaN       NaN       NaN       NaN
(-0.80,-0.75]      0        NaN          NaN       NaN       NaN       NaN
(-0.75,-0.70]      0        NaN          NaN       NaN       NaN       NaN
(-0.70,-0.65]      0        NaN          NaN       NaN       NaN       NaN
(-0.65,-0.60]      0        NaN          NaN       NaN       NaN       NaN
(-0.60,-0.55]      0        NaN          NaN       NaN       NaN       NaN
(-0.55,-0.50]      0        NaN          NaN       NaN       NaN       NaN
(-0.50,-0.45]      0        NaN          NaN       NaN       NaN       NaN
(-0.45,-0.40]      0        NaN          NaN       NaN       NaN       NaN
(-0.40,-0.35]      0        NaN          NaN       NaN       NaN       NaN
(-0.35,-0.30]      0        NaN          NaN       NaN       NaN       NaN
(-0.30,-0.25]      0        NaN          NaN       NaN       NaN       NaN
(-0.25,-0.20]      7      0.102        0.128     0.064     0.174     0.014
(-0.20,-0.15]     39      0.086        0.053     0.078     0.286     0.005
(-0.15,-0.10]    255      0.077        0.050     0.081     0.689     0.000
(-0.10,-0.05]    931      0.067        0.045     0.073     0.526     0.000
(-0.05,0.00]    3606      0.065        0.042     0.077     0.775     0.000
(0.00,0.05]     5880      0.065        0.043     0.077     1.231     0.000
(0.05,0.10]     3872      0.071        0.052     0.073     0.910     0.000
(0.10,0.15]     1276      0.075        0.056     0.080     1.168     0.000
(0.15,0.20]      205      0.096        0.071     0.087     0.644     0.000
(0.20,0.25]       39      0.096        0.053     0.101     0.505     0.010
(0.25,0.30]       10      0.100        0.069     0.099     0.324     0.016
(0.30,0.35]        0        NaN          NaN       NaN       NaN       NaN
(0.35,0.40]        1      0.000        0.000       NaN     0.000     0.000
(0.40,0.45]        0        NaN          NaN       NaN       NaN       NaN
(0.45,0.50]        0        NaN          NaN       NaN       NaN       NaN
(0.50,0.55]        0        NaN          NaN       NaN       NaN       NaN
(0.55,0.60]        0        NaN          NaN       NaN       NaN       NaN
(0.60,0.65]        0        NaN          NaN       NaN       NaN       NaN
(0.65,0.70]        0        NaN          NaN       NaN       NaN       NaN
(0.70,0.75]        0        NaN          NaN       NaN       NaN       NaN
(0.75,0.80]        0        NaN          NaN       NaN       NaN       NaN
(0.80,0.85]        0        NaN          NaN       NaN       NaN       NaN
(0.85,0.90]        0        NaN          NaN       NaN       NaN       NaN
(0.90,0.95]        0        NaN          NaN       NaN       NaN       NaN
(0.95,1.00]        0        NaN          NaN       NaN       NaN       NaN

test period:20170101-20170701
(115939, 2036) (15914, 2036)

--------------------Train network--------------------

 (115939, 2036) (115939,) {'train_indexes': (0, 38646), 'fit': {'categorical_feature': ['area', 'market', 'exchange', 'is_hs']}}

----------Train layer 0----------
slice(0, 38646, None)

Train custom_revenue_y_s_rise
C:\Users\dell-pc\Anaconda3.6\lib\site-packages\lightgbm\basic.py:1042: UserWarning: categorical_feature in Dataset is overridden. New categorical_feature is ['area', 'exchange', 'is_hs', 'market']
  warnings.warn('categorical_feature in Dataset is overridden. New categorical_feature is {}'.format(sorted(list(categorical_feature))))
[LightGBM] [Warning] Using self-defined objective function
[LightGBM] [Warning] Using self-defined objective function
Time usage: 16.53s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=2, max_depth=8, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=10,
       n_jobs=-1, num_leaves=15,
       objective=<function custom_revenue_obj at 0x000001E7431D5EA0>,
       random_state=0, reg_alpha=0.0, reg_lambda=0.0, silent=True,
       subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
                                    feature  importance_raw  \
1705                                 sh_vol              29
1151  p240mv_(120k_low-120k_close)/120k_avg              20
992      p120mv_(60k_low-60k_close)/60k_avg              10
1526        p80mv_(20k_low/p20mv_20k_low-1)              10
357               (60k_low/p60mv_60k_low-1)              10
920   p1000mv_(250k_low-250k_open)/250k_avg              10
1865                               sz50_vol              10
187         (250k_high/p1250mv_250k_high-1)              10
1331      p40mv_(20k_open/p20mv_20k_open-1)              10
2025                                 sz_vol              10
454                          (high-low)/avg               9
401                      (avg/p10min_avg-1)               1
515                    (open/p10min_open-1)               1

      importance_percent
1705               20.71
1151               14.29
992                 7.14
1526                7.14
357                 7.14
920                 7.14
1865                7.14
187                 7.14
1331                7.14
2025                7.14
454                 6.43
401                 0.71
515                 0.71
Among 2036 features, 2023 features are not used in the model

Train custom_revenue2_y_l_rise
[LightGBM] [Warning] Using self-defined objective function
[LightGBM] [Warning] Using self-defined objective function
Time usage: 16.68s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=2, max_depth=8, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=10,
       n_jobs=-1, num_leaves=15,
       objective=<function custom_revenue2_obj at 0x000001E7431E10D0>,
       random_state=0, reg_alpha=0.0, reg_lambda=0.0, silent=True,
       subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
                                    feature  importance_raw  \
1705                                 sh_vol               9
567                                     amt               7
1466        p60mv_(20k_low/p20mv_20k_low-1)               7
1526        p80mv_(20k_low/p20mv_20k_low-1)               7
357               (60k_low/p60mv_60k_low-1)               6
1865                               sz50_vol               4
454                          (high-low)/avg               3
1151  p240mv_(120k_low-120k_close)/120k_avg               3
1457        p60mv_(20k_avg/p20mv_20k_avg-1)               3
951         p10mv_(10k_low/p10mv_10k_low-1)               3
936        p100mv_(20k_low/p20mv_20k_low-1)               3
288                 (5k_high-5k_low)/5k_avg               3
1062       p180mv_(60k_avg/p60mv_60k_avg-1)               2
1387           p500mv_lower_shadow/250k_avg               2
2025                                 sz_vol               2
1006  p1250mv_(250k_high-250k_low)/250k_avg               2
1238            p300mv_lower_shadow/60k_avg               2
96                  (120k_open/250k_open-1)               2
924           p1000mv_lower_shadow/250k_avg               2
937      p100mv_(20k_open/p20mv_20k_open-1)               2

      importance_percent
1705                6.43
567                 5.00
1466                5.00
1526                5.00
357                 4.29
1865                2.86
454                 2.14
1151                2.14
1457                2.14
951                 2.14
936                 2.14
288                 2.14
1062                1.43
1387                1.43
2025                1.43
1006                1.43
1238                1.43
96                  1.43
924                 1.43
937                 1.43
Among 2036 features, 1956 features are not used in the model

Train custom_revenue2_y_l_avg
[LightGBM] [Warning] Using self-defined objective function
[LightGBM] [Warning] Using self-defined objective function
Time usage: 16.52s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=2, max_depth=8, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=10,
       n_jobs=-1, num_leaves=15,
       objective=<function custom_revenue2_obj at 0x000001E7431E10D0>,
       random_state=0, reg_alpha=0.0, reg_lambda=0.0, silent=True,
       subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
                                    feature  importance_raw  \
1705                                 sh_vol               9
567                                     amt               7
1466        p60mv_(20k_low/p20mv_20k_low-1)               7
1526        p80mv_(20k_low/p20mv_20k_low-1)               7
357               (60k_low/p60mv_60k_low-1)               6
1865                               sz50_vol               4
454                          (high-low)/avg               3
1151  p240mv_(120k_low-120k_close)/120k_avg               3
1457        p60mv_(20k_avg/p20mv_20k_avg-1)               3
951         p10mv_(10k_low/p10mv_10k_low-1)               3
936        p100mv_(20k_low/p20mv_20k_low-1)               3
288                 (5k_high-5k_low)/5k_avg               3
1062       p180mv_(60k_avg/p60mv_60k_avg-1)               2
1387           p500mv_lower_shadow/250k_avg               2
2025                                 sz_vol               2
1006  p1250mv_(250k_high-250k_low)/250k_avg               2
1238            p300mv_lower_shadow/60k_avg               2
96                  (120k_open/250k_open-1)               2
924           p1000mv_lower_shadow/250k_avg               2
937      p100mv_(20k_open/p20mv_20k_open-1)               2

      importance_percent
1705                6.43
567                 5.00
1466                5.00
1526                5.00
357                 4.29
1865                2.86
454                 2.14
1151                2.14
1457                2.14
951                 2.14
936                 2.14
288                 2.14
1062                1.43
1387                1.43
2025                1.43
1006                1.43
1238                1.43
96                  1.43
924                 1.43
937                 1.43
Among 2036 features, 1956 features are not used in the model

Train custom_revenue2_y_s_rise
[LightGBM] [Warning] Using self-defined objective function
[LightGBM] [Warning] Using self-defined objective function
Time usage: 16.42s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=2, max_depth=8, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=10,
       n_jobs=-1, num_leaves=15,
       objective=<function custom_revenue2_obj at 0x000001E7431E10D0>,
       random_state=0, reg_alpha=0.0, reg_lambda=0.0, silent=True,
       subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
                                    feature  importance_raw  \
1705                                 sh_vol               9
567                                     amt               7
1466        p60mv_(20k_low/p20mv_20k_low-1)               7
1526        p80mv_(20k_low/p20mv_20k_low-1)               7
357               (60k_low/p60mv_60k_low-1)               6
1865                               sz50_vol               4
454                          (high-low)/avg               3
1151  p240mv_(120k_low-120k_close)/120k_avg               3
1457        p60mv_(20k_avg/p20mv_20k_avg-1)               3
951         p10mv_(10k_low/p10mv_10k_low-1)               3
936        p100mv_(20k_low/p20mv_20k_low-1)               3
288                 (5k_high-5k_low)/5k_avg               3
1062       p180mv_(60k_avg/p60mv_60k_avg-1)               2
1387           p500mv_lower_shadow/250k_avg               2
2025                                 sz_vol               2
1006  p1250mv_(250k_high-250k_low)/250k_avg               2
1238            p300mv_lower_shadow/60k_avg               2
96                  (120k_open/250k_open-1)               2
924           p1000mv_lower_shadow/250k_avg               2
937      p100mv_(20k_open/p20mv_20k_open-1)               2

      importance_percent
1705                6.43
567                 5.00
1466                5.00
1526                5.00
357                 4.29
1865                2.86
454                 2.14
1151                2.14
1457                2.14
951                 2.14
936                 2.14
288                 2.14
1062                1.43
1387                1.43
2025                1.43
1006                1.43
1238                1.43
96                  1.43
924                 1.43
937                 1.43
Among 2036 features, 1956 features are not used in the model

Train custom_revenue_y_l_rise
[LightGBM] [Warning] Using self-defined objective function
[LightGBM] [Warning] Using self-defined objective function
Time usage: 16.85s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=2, max_depth=8, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=10,
       n_jobs=-1, num_leaves=15,
       objective=<function custom_revenue_obj at 0x000001E7431D5EA0>,
       random_state=0, reg_alpha=0.0, reg_lambda=0.0, silent=True,
       subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
                                    feature  importance_raw  \
1705                                 sh_vol              29
1151  p240mv_(120k_low-120k_close)/120k_avg              20
992      p120mv_(60k_low-60k_close)/60k_avg              10
1526        p80mv_(20k_low/p20mv_20k_low-1)              10
357               (60k_low/p60mv_60k_low-1)              10
920   p1000mv_(250k_low-250k_open)/250k_avg              10
1865                               sz50_vol              10
187         (250k_high/p1250mv_250k_high-1)              10
1331      p40mv_(20k_open/p20mv_20k_open-1)              10
2025                                 sz_vol              10
454                          (high-low)/avg               9
401                      (avg/p10min_avg-1)               1
515                    (open/p10min_open-1)               1

      importance_percent
1705               20.71
1151               14.29
992                 7.14
1526                7.14
357                 7.14
920                 7.14
1865                7.14
187                 7.14
1331                7.14
2025                7.14
454                 6.43
401                 0.71
515                 0.71
Among 2036 features, 2023 features are not used in the model

Train custom_revenue2_y_s_decline
[LightGBM] [Warning] Using self-defined objective function
[LightGBM] [Warning] Using self-defined objective function
Time usage: 16.61s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=2, max_depth=8, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=10,
       n_jobs=-1, num_leaves=15,
       objective=<function custom_revenue2_obj at 0x000001E7431E10D0>,
       random_state=0, reg_alpha=0.0, reg_lambda=0.0, silent=True,
       subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
                                    feature  importance_raw  \
1705                                 sh_vol               9
567                                     amt               7
1466        p60mv_(20k_low/p20mv_20k_low-1)               7
1526        p80mv_(20k_low/p20mv_20k_low-1)               7
357               (60k_low/p60mv_60k_low-1)               6
1865                               sz50_vol               4
454                          (high-low)/avg               3
1151  p240mv_(120k_low-120k_close)/120k_avg               3
1457        p60mv_(20k_avg/p20mv_20k_avg-1)               3
951         p10mv_(10k_low/p10mv_10k_low-1)               3
936        p100mv_(20k_low/p20mv_20k_low-1)               3
288                 (5k_high-5k_low)/5k_avg               3
1062       p180mv_(60k_avg/p60mv_60k_avg-1)               2
1387           p500mv_lower_shadow/250k_avg               2
2025                                 sz_vol               2
1006  p1250mv_(250k_high-250k_low)/250k_avg               2
1238            p300mv_lower_shadow/60k_avg               2
96                  (120k_open/250k_open-1)               2
924           p1000mv_lower_shadow/250k_avg               2
937      p100mv_(20k_open/p20mv_20k_open-1)               2

      importance_percent
1705                6.43
567                 5.00
1466                5.00
1526                5.00
357                 4.29
1865                2.86
454                 2.14
1151                2.14
1457                2.14
951                 2.14
936                 2.14
288                 2.14
1062                1.43
1387                1.43
2025                1.43
1006                1.43
1238                1.43
96                  1.43
924                 1.43
937                 1.43
Among 2036 features, 1956 features are not used in the model

Train custom_revenue_y_s_avg
[LightGBM] [Warning] Using self-defined objective function
[LightGBM] [Warning] Using self-defined objective function
Time usage: 16.85s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=2, max_depth=8, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=10,
       n_jobs=-1, num_leaves=15,
       objective=<function custom_revenue_obj at 0x000001E7431D5EA0>,
       random_state=0, reg_alpha=0.0, reg_lambda=0.0, silent=True,
       subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
                                    feature  importance_raw  \
1705                                 sh_vol              29
1151  p240mv_(120k_low-120k_close)/120k_avg              20
992      p120mv_(60k_low-60k_close)/60k_avg              10
1526        p80mv_(20k_low/p20mv_20k_low-1)              10
357               (60k_low/p60mv_60k_low-1)              10
920   p1000mv_(250k_low-250k_open)/250k_avg              10
1865                               sz50_vol              10
187         (250k_high/p1250mv_250k_high-1)              10
1331      p40mv_(20k_open/p20mv_20k_open-1)              10
2025                                 sz_vol              10
454                          (high-low)/avg               9
401                      (avg/p10min_avg-1)               1
515                    (open/p10min_open-1)               1

      importance_percent
1705               20.71
1151               14.29
992                 7.14
1526                7.14
357                 7.14
920                 7.14
1865                7.14
187                 7.14
1331                7.14
2025                7.14
454                 6.43
401                 0.71
515                 0.71
Among 2036 features, 2023 features are not used in the model

Train custom_revenue_y_s_decline
[LightGBM] [Warning] Using self-defined objective function
[LightGBM] [Warning] Using self-defined objective function
Time usage: 16.99s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=2, max_depth=8, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=10,
       n_jobs=-1, num_leaves=15,
       objective=<function custom_revenue_obj at 0x000001E7431D5EA0>,
       random_state=0, reg_alpha=0.0, reg_lambda=0.0, silent=True,
       subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
                                    feature  importance_raw  \
1705                                 sh_vol              29
1151  p240mv_(120k_low-120k_close)/120k_avg              20
992      p120mv_(60k_low-60k_close)/60k_avg              10
1526        p80mv_(20k_low/p20mv_20k_low-1)              10
357               (60k_low/p60mv_60k_low-1)              10
920   p1000mv_(250k_low-250k_open)/250k_avg              10
1865                               sz50_vol              10
187         (250k_high/p1250mv_250k_high-1)              10
1331      p40mv_(20k_open/p20mv_20k_open-1)              10
2025                                 sz_vol              10
454                          (high-low)/avg               9
401                      (avg/p10min_avg-1)               1
515                    (open/p10min_open-1)               1

      importance_percent
1705               20.71
1151               14.29
992                 7.14
1526                7.14
357                 7.14
920                 7.14
1865                7.14
187                 7.14
1331                7.14
2025                7.14
454                 6.43
401                 0.71
515                 0.71
Among 2036 features, 2023 features are not used in the model

Train custom_revenue2_y_s_avg
[LightGBM] [Warning] Using self-defined objective function
[LightGBM] [Warning] Using self-defined objective function
Time usage: 16.88s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=2, max_depth=8, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=10,
       n_jobs=-1, num_leaves=15,
       objective=<function custom_revenue2_obj at 0x000001E7431E10D0>,
       random_state=0, reg_alpha=0.0, reg_lambda=0.0, silent=True,
       subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
                                    feature  importance_raw  \
1705                                 sh_vol               9
567                                     amt               7
1466        p60mv_(20k_low/p20mv_20k_low-1)               7
1526        p80mv_(20k_low/p20mv_20k_low-1)               7
357               (60k_low/p60mv_60k_low-1)               6
1865                               sz50_vol               4
454                          (high-low)/avg               3
1151  p240mv_(120k_low-120k_close)/120k_avg               3
1457        p60mv_(20k_avg/p20mv_20k_avg-1)               3
951         p10mv_(10k_low/p10mv_10k_low-1)               3
936        p100mv_(20k_low/p20mv_20k_low-1)               3
288                 (5k_high-5k_low)/5k_avg               3
1062       p180mv_(60k_avg/p60mv_60k_avg-1)               2
1387           p500mv_lower_shadow/250k_avg               2
2025                                 sz_vol               2
1006  p1250mv_(250k_high-250k_low)/250k_avg               2
1238            p300mv_lower_shadow/60k_avg               2
96                  (120k_open/250k_open-1)               2
924           p1000mv_lower_shadow/250k_avg               2
937      p100mv_(20k_open/p20mv_20k_open-1)               2

      importance_percent
1705                6.43
567                 5.00
1466                5.00
1526                5.00
357                 4.29
1865                2.86
454                 2.14
1151                2.14
1457                2.14
951                 2.14
936                 2.14
288                 2.14
1062                1.43
1387                1.43
2025                1.43
1006                1.43
1238                1.43
96                  1.43
924                 1.43
937                 1.43
Among 2036 features, 1956 features are not used in the model

Train custom_revenue_y_l_avg
[LightGBM] [Warning] Using self-defined objective function
[LightGBM] [Warning] Using self-defined objective function
Time usage: 17.16s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=2, max_depth=8, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=10,
       n_jobs=-1, num_leaves=15,
       objective=<function custom_revenue_obj at 0x000001E7431D5EA0>,
       random_state=0, reg_alpha=0.0, reg_lambda=0.0, silent=True,
       subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
                                    feature  importance_raw  \
1705                                 sh_vol              29
1151  p240mv_(120k_low-120k_close)/120k_avg              20
992      p120mv_(60k_low-60k_close)/60k_avg              10
1526        p80mv_(20k_low/p20mv_20k_low-1)              10
357               (60k_low/p60mv_60k_low-1)              10
920   p1000mv_(250k_low-250k_open)/250k_avg              10
1865                               sz50_vol              10
187         (250k_high/p1250mv_250k_high-1)              10
1331      p40mv_(20k_open/p20mv_20k_open-1)              10
2025                                 sz_vol              10
454                          (high-low)/avg               9
401                      (avg/p10min_avg-1)               1
515                    (open/p10min_open-1)               1

      importance_percent
1705               20.71
1151               14.29
992                 7.14
1526                7.14
357                 7.14
920                 7.14
1865                7.14
187                 7.14
1331                7.14
2025                7.14
454                 6.43
401                 0.71
515                 0.71
Among 2036 features, 2023 features are not used in the model

Train custom_revenue2_y_l_decline
[LightGBM] [Warning] Using self-defined objective function
[LightGBM] [Warning] Using self-defined objective function
Time usage: 17.17s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=2, max_depth=8, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=10,
       n_jobs=-1, num_leaves=15,
       objective=<function custom_revenue2_obj at 0x000001E7431E10D0>,
       random_state=0, reg_alpha=0.0, reg_lambda=0.0, silent=True,
       subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
                                    feature  importance_raw  \
1705                                 sh_vol               9
567                                     amt               7
1466        p60mv_(20k_low/p20mv_20k_low-1)               7
1526        p80mv_(20k_low/p20mv_20k_low-1)               7
357               (60k_low/p60mv_60k_low-1)               6
1865                               sz50_vol               4
454                          (high-low)/avg               3
1151  p240mv_(120k_low-120k_close)/120k_avg               3
1457        p60mv_(20k_avg/p20mv_20k_avg-1)               3
951         p10mv_(10k_low/p10mv_10k_low-1)               3
936        p100mv_(20k_low/p20mv_20k_low-1)               3
288                 (5k_high-5k_low)/5k_avg               3
1062       p180mv_(60k_avg/p60mv_60k_avg-1)               2
1387           p500mv_lower_shadow/250k_avg               2
2025                                 sz_vol               2
1006  p1250mv_(250k_high-250k_low)/250k_avg               2
1238            p300mv_lower_shadow/60k_avg               2
96                  (120k_open/250k_open-1)               2
924           p1000mv_lower_shadow/250k_avg               2
937      p100mv_(20k_open/p20mv_20k_open-1)               2

      importance_percent
1705                6.43
567                 5.00
1466                5.00
1526                5.00
357                 4.29
1865                2.86
454                 2.14
1151                2.14
1457                2.14
951                 2.14
936                 2.14
288                 2.14
1062                1.43
1387                1.43
2025                1.43
1006                1.43
1238                1.43
96                  1.43
924                 1.43
937                 1.43
Among 2036 features, 1956 features are not used in the model

Train custom_revenue_y_l_decline
[LightGBM] [Warning] Using self-defined objective function
[LightGBM] [Warning] Using self-defined objective function
Time usage: 17.11s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=2, max_depth=8, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=10,
       n_jobs=-1, num_leaves=15,
       objective=<function custom_revenue_obj at 0x000001E7431D5EA0>,
       random_state=0, reg_alpha=0.0, reg_lambda=0.0, silent=True,
       subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
                                    feature  importance_raw  \
1705                                 sh_vol              29
1151  p240mv_(120k_low-120k_close)/120k_avg              20
992      p120mv_(60k_low-60k_close)/60k_avg              10
1526        p80mv_(20k_low/p20mv_20k_low-1)              10
357               (60k_low/p60mv_60k_low-1)              10
920   p1000mv_(250k_low-250k_open)/250k_avg              10
1865                               sz50_vol              10
187         (250k_high/p1250mv_250k_high-1)              10
1331      p40mv_(20k_open/p20mv_20k_open-1)              10
2025                                 sz_vol              10
454                          (high-low)/avg               9
401                      (avg/p10min_avg-1)               1
515                    (open/p10min_open-1)               1

      importance_percent
1705               20.71
1151               14.29
992                 7.14
1526                7.14
357                 7.14
920                 7.14
1865                7.14
187                 7.14
1331                7.14
2025                7.14
454                 6.43
401                 0.71
515                 0.71
Among 2036 features, 2023 features are not used in the model

----------Layer 0 predicts----------

 (115939, 2180) (115939,) {'train_indexes': (38646, 77292), 'fit': {'categorical_feature': ['area', 'market', 'exchange', 'is_hs']}}

----------Train layer 1----------
slice(38646, 77292, None)

Train l2_y_l_rise
[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves
[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves
Time usage: 25.14s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=0.2, max_depth=12, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=25,
       n_jobs=-1, num_leaves=31, objective=None, random_state=0,
       reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,
       subsample_for_bin=200000, subsample_freq=0)
                                   feature  importance_raw  importance_percent
2025                                sz_vol              52                6.93
1865                              sz50_vol              34                4.53
895                              hs300_vol              18                2.40
568                                   area              15                2.00
567                                    amt              15                2.00
1705                                sh_vol              15                2.00
2034                                   vol               8                1.07
732                                cyb_vol               7                0.93
1182  p250mv_(250k_low-250k_open)/250k_avg               6                0.80
2048  layer0_custom_revenue2_y_l_rise_pred               6                0.80
1112       p20mv_(20k_avg/p20mv_20k_avg-1)               6                0.80
1268          p360mv_lower_shadow/120k_avg               6                0.80
288                (5k_high-5k_low)/5k_avg               6                0.80
2035                                  vol0               5                0.67
1347   p480mv_(120k_low/p120mv_120k_low-1)               5                0.67
1235      p300mv_(60k_low/p60mv_60k_low-1)               5                0.67
899                                   low0               5                0.67
22           (10k_close/p30mv_10k_close-1)               5                0.67
1350          p480mv_lower_shadow/120k_avg               5                0.67
1061      p180mv_(60k_amt/p60mv_60k_amt-1)               5                0.67
Among 2180 features, 1804 features are not used in the model

Train l2_y_s_avg
[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves
[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves
Time usage: 25.03s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=0.2, max_depth=12, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=25,
       n_jobs=-1, num_leaves=31, objective=None, random_state=0,
       reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,
       subsample_for_bin=200000, subsample_freq=0)
                                   feature  importance_raw  importance_percent
2025                                sz_vol              52                6.93
1865                              sz50_vol              34                4.53
895                              hs300_vol              18                2.40
568                                   area              15                2.00
567                                    amt              15                2.00
1705                                sh_vol              15                2.00
2034                                   vol               8                1.07
732                                cyb_vol               7                0.93
1182  p250mv_(250k_low-250k_open)/250k_avg               6                0.80
2048  layer0_custom_revenue2_y_l_rise_pred               6                0.80
1112       p20mv_(20k_avg/p20mv_20k_avg-1)               6                0.80
1268          p360mv_lower_shadow/120k_avg               6                0.80
288                (5k_high-5k_low)/5k_avg               6                0.80
2035                                  vol0               5                0.67
1347   p480mv_(120k_low/p120mv_120k_low-1)               5                0.67
1235      p300mv_(60k_low/p60mv_60k_low-1)               5                0.67
899                                   low0               5                0.67
22           (10k_close/p30mv_10k_close-1)               5                0.67
1350          p480mv_lower_shadow/120k_avg               5                0.67
1061      p180mv_(60k_amt/p60mv_60k_amt-1)               5                0.67
Among 2180 features, 1804 features are not used in the model

Train l2_y_s_rise
[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves
[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves
Time usage: 25.14s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=0.2, max_depth=12, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=25,
       n_jobs=-1, num_leaves=31, objective=None, random_state=0,
       reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,
       subsample_for_bin=200000, subsample_freq=0)
                                   feature  importance_raw  importance_percent
2025                                sz_vol              52                6.93
1865                              sz50_vol              34                4.53
895                              hs300_vol              18                2.40
568                                   area              15                2.00
567                                    amt              15                2.00
1705                                sh_vol              15                2.00
2034                                   vol               8                1.07
732                                cyb_vol               7                0.93
1182  p250mv_(250k_low-250k_open)/250k_avg               6                0.80
2048  layer0_custom_revenue2_y_l_rise_pred               6                0.80
1112       p20mv_(20k_avg/p20mv_20k_avg-1)               6                0.80
1268          p360mv_lower_shadow/120k_avg               6                0.80
288                (5k_high-5k_low)/5k_avg               6                0.80
2035                                  vol0               5                0.67
1347   p480mv_(120k_low/p120mv_120k_low-1)               5                0.67
1235      p300mv_(60k_low/p60mv_60k_low-1)               5                0.67
899                                   low0               5                0.67
22           (10k_close/p30mv_10k_close-1)               5                0.67
1350          p480mv_lower_shadow/120k_avg               5                0.67
1061      p180mv_(60k_amt/p60mv_60k_amt-1)               5                0.67
Among 2180 features, 1804 features are not used in the model

Train l2_y_l_decline
[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves
[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves
Time usage: 25.19s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=0.2, max_depth=12, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=25,
       n_jobs=-1, num_leaves=31, objective=None, random_state=0,
       reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,
       subsample_for_bin=200000, subsample_freq=0)
                                   feature  importance_raw  importance_percent
2025                                sz_vol              52                6.93
1865                              sz50_vol              34                4.53
895                              hs300_vol              18                2.40
568                                   area              15                2.00
567                                    amt              15                2.00
1705                                sh_vol              15                2.00
2034                                   vol               8                1.07
732                                cyb_vol               7                0.93
1182  p250mv_(250k_low-250k_open)/250k_avg               6                0.80
2048  layer0_custom_revenue2_y_l_rise_pred               6                0.80
1112       p20mv_(20k_avg/p20mv_20k_avg-1)               6                0.80
1268          p360mv_lower_shadow/120k_avg               6                0.80
288                (5k_high-5k_low)/5k_avg               6                0.80
2035                                  vol0               5                0.67
1347   p480mv_(120k_low/p120mv_120k_low-1)               5                0.67
1235      p300mv_(60k_low/p60mv_60k_low-1)               5                0.67
899                                   low0               5                0.67
22           (10k_close/p30mv_10k_close-1)               5                0.67
1350          p480mv_lower_shadow/120k_avg               5                0.67
1061      p180mv_(60k_amt/p60mv_60k_amt-1)               5                0.67
Among 2180 features, 1804 features are not used in the model

Train l2_y_l_avg
[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves
[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves
Time usage: 25.29s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=0.2, max_depth=12, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=25,
       n_jobs=-1, num_leaves=31, objective=None, random_state=0,
       reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,
       subsample_for_bin=200000, subsample_freq=0)
                                   feature  importance_raw  importance_percent
2025                                sz_vol              52                6.93
1865                              sz50_vol              34                4.53
895                              hs300_vol              18                2.40
568                                   area              15                2.00
567                                    amt              15                2.00
1705                                sh_vol              15                2.00
2034                                   vol               8                1.07
732                                cyb_vol               7                0.93
1182  p250mv_(250k_low-250k_open)/250k_avg               6                0.80
2048  layer0_custom_revenue2_y_l_rise_pred               6                0.80
1112       p20mv_(20k_avg/p20mv_20k_avg-1)               6                0.80
1268          p360mv_lower_shadow/120k_avg               6                0.80
288                (5k_high-5k_low)/5k_avg               6                0.80
2035                                  vol0               5                0.67
1347   p480mv_(120k_low/p120mv_120k_low-1)               5                0.67
1235      p300mv_(60k_low/p60mv_60k_low-1)               5                0.67
899                                   low0               5                0.67
22           (10k_close/p30mv_10k_close-1)               5                0.67
1350          p480mv_lower_shadow/120k_avg               5                0.67
1061      p180mv_(60k_amt/p60mv_60k_amt-1)               5                0.67
Among 2180 features, 1804 features are not used in the model

Train l2_y_s_decline
[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves
[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves
Time usage: 25.20s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=0.2, max_depth=12, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=25,
       n_jobs=-1, num_leaves=31, objective=None, random_state=0,
       reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,
       subsample_for_bin=200000, subsample_freq=0)
                                   feature  importance_raw  importance_percent
2025                                sz_vol              52                6.93
1865                              sz50_vol              34                4.53
895                              hs300_vol              18                2.40
568                                   area              15                2.00
567                                    amt              15                2.00
1705                                sh_vol              15                2.00
2034                                   vol               8                1.07
732                                cyb_vol               7                0.93
1182  p250mv_(250k_low-250k_open)/250k_avg               6                0.80
2048  layer0_custom_revenue2_y_l_rise_pred               6                0.80
1112       p20mv_(20k_avg/p20mv_20k_avg-1)               6                0.80
1268          p360mv_lower_shadow/120k_avg               6                0.80
288                (5k_high-5k_low)/5k_avg               6                0.80
2035                                  vol0               5                0.67
1347   p480mv_(120k_low/p120mv_120k_low-1)               5                0.67
1235      p300mv_(60k_low/p60mv_60k_low-1)               5                0.67
899                                   low0               5                0.67
22           (10k_close/p30mv_10k_close-1)               5                0.67
1350          p480mv_lower_shadow/120k_avg               5                0.67
1061      p180mv_(60k_amt/p60mv_60k_amt-1)               5                0.67
Among 2180 features, 1804 features are not used in the model

----------Layer 1 predicts----------

 (115939, 2336) (115939,) {'train_indexes': (77292, None), 'fit': {'categorical_feature': ['area', 'market', 'exchange', 'is_hs']}}

----------Train layer 2----------
slice(77292, None, None)

Train l2_y_l_r
[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves
[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves
Time usage: 37.29s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=0.1, max_depth=12, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=50,
       n_jobs=-1, num_leaves=31, objective=None, random_state=0,
       reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,
       subsample_for_bin=200000, subsample_freq=0)
                                  feature  importance_raw  importance_percent
2025                               sz_vol              33                2.20
567                                   amt              30                2.00
568                                  area              29                1.93
1865                             sz50_vol              22                1.47
454                        (high-low)/avg              18                1.20
1241      p30mv_(10k_avg/p10mv_10k_avg-1)              18                1.20
1457      p60mv_(20k_avg/p20mv_20k_avg-1)              15                1.00
895                             hs300_vol              15                1.00
1705                               sh_vol              13                0.87
453                      (high-close)/avg              12                0.80
927      p100mv_(20k_avg/p20mv_20k_avg-1)              12                0.80
1049        p15mv_(5k_high-5k_low)/5k_avg              12                0.80
234               (3k_high-3k_low)/3k_avg              11                0.73
1000          p120mv_upper_shadow/60k_avg              11                0.73
1112      p20mv_(20k_avg/p20mv_20k_avg-1)              10                0.67
430               (close/p120max_close-1)              10                0.67
124             (20k_avg/p60mv_20k_avg-1)              10                0.67
1265  p360mv_(120k_low/p120mv_120k_low-1)              10                0.67
486                    (low/p10max_low-1)               9                0.60
1225     p300mv_(60k_amt/p60mv_60k_amt-1)               9                0.60
Among 2336 features, 1750 features are not used in the model

--------------------Predict--------------------

----------Layer 0 predicts----------

----------Layer 1 predicts----------

----------Layer 2 predicts----------

y_l_r
               count  eval_mean  eval_median  eval_std  eval_max  eval_min
pred_range
(-1.00,-0.95]      0        NaN          NaN       NaN       NaN       NaN
(-0.95,-0.90]      0        NaN          NaN       NaN       NaN       NaN
(-0.90,-0.85]      0        NaN          NaN       NaN       NaN       NaN
(-0.85,-0.80]      0        NaN          NaN       NaN       NaN       NaN
(-0.80,-0.75]      0        NaN          NaN       NaN       NaN       NaN
(-0.75,-0.70]      0        NaN          NaN       NaN       NaN       NaN
(-0.70,-0.65]      0        NaN          NaN       NaN       NaN       NaN
(-0.65,-0.60]      0        NaN          NaN       NaN       NaN       NaN
(-0.60,-0.55]      0        NaN          NaN       NaN       NaN       NaN
(-0.55,-0.50]      0        NaN          NaN       NaN       NaN       NaN
(-0.50,-0.45]      0        NaN          NaN       NaN       NaN       NaN
(-0.45,-0.40]      0        NaN          NaN       NaN       NaN       NaN
(-0.40,-0.35]      0        NaN          NaN       NaN       NaN       NaN
(-0.35,-0.30]      0        NaN          NaN       NaN       NaN       NaN
(-0.30,-0.25]      0        NaN          NaN       NaN       NaN       NaN
(-0.25,-0.20]      0        NaN          NaN       NaN       NaN       NaN
(-0.20,-0.15]      0        NaN          NaN       NaN       NaN       NaN
(-0.15,-0.10]      1     -0.337       -0.337       NaN    -0.337    -0.337
(-0.10,-0.05]     76     -0.059       -0.114     0.168     0.534    -0.398
(-0.05,0.00]     973     -0.033       -0.056     0.135     0.931    -0.384
(0.00,0.05]     6308      0.001        0.000     0.110     1.219    -0.426
(0.05,0.10]     6713      0.020        0.040     0.110     1.063    -0.454
(0.10,0.15]     1571      0.043        0.062     0.123     0.780    -0.324
(0.15,0.20]      223      0.042        0.070     0.142     0.572    -0.249
(0.20,0.25]       41      0.090        0.106     0.178     0.531    -0.188
(0.25,0.30]        4     -0.136       -0.138     0.036    -0.098    -0.171
(0.30,0.35]        3     -0.045       -0.092     0.108     0.078    -0.123
(0.35,0.40]        1     -0.133       -0.133       NaN    -0.133    -0.133
(0.40,0.45]        0        NaN          NaN       NaN       NaN       NaN
(0.45,0.50]        0        NaN          NaN       NaN       NaN       NaN
(0.50,0.55]        0        NaN          NaN       NaN       NaN       NaN
(0.55,0.60]        0        NaN          NaN       NaN       NaN       NaN
(0.60,0.65]        0        NaN          NaN       NaN       NaN       NaN
(0.65,0.70]        0        NaN          NaN       NaN       NaN       NaN
(0.70,0.75]        0        NaN          NaN       NaN       NaN       NaN
(0.75,0.80]        0        NaN          NaN       NaN       NaN       NaN
(0.80,0.85]        0        NaN          NaN       NaN       NaN       NaN
(0.85,0.90]        0        NaN          NaN       NaN       NaN       NaN
(0.90,0.95]        0        NaN          NaN       NaN       NaN       NaN
(0.95,1.00]        0        NaN          NaN       NaN       NaN       NaN

y_l
               count  eval_mean  eval_median  eval_std  eval_max  eval_min
pred_range
(-1.00,-0.95]      0        NaN          NaN       NaN       NaN       NaN
(-0.95,-0.90]      0        NaN          NaN       NaN       NaN       NaN
(-0.90,-0.85]      0        NaN          NaN       NaN       NaN       NaN
(-0.85,-0.80]      0        NaN          NaN       NaN       NaN       NaN
(-0.80,-0.75]      0        NaN          NaN       NaN       NaN       NaN
(-0.75,-0.70]      0        NaN          NaN       NaN       NaN       NaN
(-0.70,-0.65]      0        NaN          NaN       NaN       NaN       NaN
(-0.65,-0.60]      0        NaN          NaN       NaN       NaN       NaN
(-0.60,-0.55]      0        NaN          NaN       NaN       NaN       NaN
(-0.55,-0.50]      0        NaN          NaN       NaN       NaN       NaN
(-0.50,-0.45]      0        NaN          NaN       NaN       NaN       NaN
(-0.45,-0.40]      0        NaN          NaN       NaN       NaN       NaN
(-0.40,-0.35]      0        NaN          NaN       NaN       NaN       NaN
(-0.35,-0.30]      0        NaN          NaN       NaN       NaN       NaN
(-0.30,-0.25]      0        NaN          NaN       NaN       NaN       NaN
(-0.25,-0.20]      0        NaN          NaN       NaN       NaN       NaN
(-0.20,-0.15]      0        NaN          NaN       NaN       NaN       NaN
(-0.15,-0.10]      1     -0.408       -0.408       NaN    -0.408    -0.408
(-0.10,-0.05]     76     -0.074       -0.138     0.197     0.640    -0.458
(-0.05,0.00]     973     -0.042       -0.074     0.157     1.105    -0.444
(0.00,0.05]     6308     -0.003        0.000     0.129     1.303    -0.471
(0.05,0.10]     6713      0.018        0.045     0.130     1.191    -0.491
(0.10,0.15]     1571      0.043        0.073     0.146     0.882    -0.365
(0.15,0.20]      223      0.034        0.068     0.169     0.625    -0.288
(0.20,0.25]       41      0.100        0.128     0.207     0.600    -0.229
(0.25,0.30]        4     -0.162       -0.162     0.046    -0.109    -0.216
(0.30,0.35]        3     -0.132       -0.134     0.012    -0.119    -0.143
(0.35,0.40]        1     -0.166       -0.166       NaN    -0.166    -0.166
(0.40,0.45]        0        NaN          NaN       NaN       NaN       NaN
(0.45,0.50]        0        NaN          NaN       NaN       NaN       NaN
(0.50,0.55]        0        NaN          NaN       NaN       NaN       NaN
(0.55,0.60]        0        NaN          NaN       NaN       NaN       NaN
(0.60,0.65]        0        NaN          NaN       NaN       NaN       NaN
(0.65,0.70]        0        NaN          NaN       NaN       NaN       NaN
(0.70,0.75]        0        NaN          NaN       NaN       NaN       NaN
(0.75,0.80]        0        NaN          NaN       NaN       NaN       NaN
(0.80,0.85]        0        NaN          NaN       NaN       NaN       NaN
(0.85,0.90]        0        NaN          NaN       NaN       NaN       NaN
(0.90,0.95]        0        NaN          NaN       NaN       NaN       NaN
(0.95,1.00]        0        NaN          NaN       NaN       NaN       NaN

y_l_avg
               count  eval_mean  eval_median  eval_std  eval_max  eval_min
pred_range
(-1.00,-0.95]      0        NaN          NaN       NaN       NaN       NaN
(-0.95,-0.90]      0        NaN          NaN       NaN       NaN       NaN
(-0.90,-0.85]      0        NaN          NaN       NaN       NaN       NaN
(-0.85,-0.80]      0        NaN          NaN       NaN       NaN       NaN
(-0.80,-0.75]      0        NaN          NaN       NaN       NaN       NaN
(-0.75,-0.70]      0        NaN          NaN       NaN       NaN       NaN
(-0.70,-0.65]      0        NaN          NaN       NaN       NaN       NaN
(-0.65,-0.60]      0        NaN          NaN       NaN       NaN       NaN
(-0.60,-0.55]      0        NaN          NaN       NaN       NaN       NaN
(-0.55,-0.50]      0        NaN          NaN       NaN       NaN       NaN
(-0.50,-0.45]      0        NaN          NaN       NaN       NaN       NaN
(-0.45,-0.40]      0        NaN          NaN       NaN       NaN       NaN
(-0.40,-0.35]      0        NaN          NaN       NaN       NaN       NaN
(-0.35,-0.30]      0        NaN          NaN       NaN       NaN       NaN
(-0.30,-0.25]      0        NaN          NaN       NaN       NaN       NaN
(-0.25,-0.20]      0        NaN          NaN       NaN       NaN       NaN
(-0.20,-0.15]      0        NaN          NaN       NaN       NaN       NaN
(-0.15,-0.10]      1     -0.122       -0.122       NaN    -0.122    -0.122
(-0.10,-0.05]     76     -0.028       -0.036     0.081     0.214    -0.219
(-0.05,0.00]     973     -0.015       -0.013     0.071     0.533    -0.246
(0.00,0.05]     6308      0.001        0.000     0.058     0.968    -0.292
(0.05,0.10]     6713      0.012        0.009     0.058     0.693    -0.381
(0.10,0.15]     1571      0.025        0.021     0.065     0.475    -0.203
(0.15,0.20]      223      0.028        0.014     0.077     0.414    -0.133
(0.20,0.25]       41      0.055        0.045     0.099     0.324    -0.100
(0.25,0.30]        4     -0.058       -0.051     0.039    -0.021    -0.109
(0.30,0.35]        3     -0.023       -0.010     0.034     0.003    -0.062
(0.35,0.40]        1     -0.034       -0.034       NaN    -0.034    -0.034
(0.40,0.45]        0        NaN          NaN       NaN       NaN       NaN
(0.45,0.50]        0        NaN          NaN       NaN       NaN       NaN
(0.50,0.55]        0        NaN          NaN       NaN       NaN       NaN
(0.55,0.60]        0        NaN          NaN       NaN       NaN       NaN
(0.60,0.65]        0        NaN          NaN       NaN       NaN       NaN
(0.65,0.70]        0        NaN          NaN       NaN       NaN       NaN
(0.70,0.75]        0        NaN          NaN       NaN       NaN       NaN
(0.75,0.80]        0        NaN          NaN       NaN       NaN       NaN
(0.80,0.85]        0        NaN          NaN       NaN       NaN       NaN
(0.85,0.90]        0        NaN          NaN       NaN       NaN       NaN
(0.90,0.95]        0        NaN          NaN       NaN       NaN       NaN
(0.95,1.00]        0        NaN          NaN       NaN       NaN       NaN

y_l_rise
               count  eval_mean  eval_median  eval_std  eval_max  eval_min
pred_range
(-1.00,-0.95]      0        NaN          NaN       NaN       NaN       NaN
(-0.95,-0.90]      0        NaN          NaN       NaN       NaN       NaN
(-0.90,-0.85]      0        NaN          NaN       NaN       NaN       NaN
(-0.85,-0.80]      0        NaN          NaN       NaN       NaN       NaN
(-0.80,-0.75]      0        NaN          NaN       NaN       NaN       NaN
(-0.75,-0.70]      0        NaN          NaN       NaN       NaN       NaN
(-0.70,-0.65]      0        NaN          NaN       NaN       NaN       NaN
(-0.65,-0.60]      0        NaN          NaN       NaN       NaN       NaN
(-0.60,-0.55]      0        NaN          NaN       NaN       NaN       NaN
(-0.55,-0.50]      0        NaN          NaN       NaN       NaN       NaN
(-0.50,-0.45]      0        NaN          NaN       NaN       NaN       NaN
(-0.45,-0.40]      0        NaN          NaN       NaN       NaN       NaN
(-0.40,-0.35]      0        NaN          NaN       NaN       NaN       NaN
(-0.35,-0.30]      0        NaN          NaN       NaN       NaN       NaN
(-0.30,-0.25]      0        NaN          NaN       NaN       NaN       NaN
(-0.25,-0.20]      0        NaN          NaN       NaN       NaN       NaN
(-0.20,-0.15]      0        NaN          NaN       NaN       NaN       NaN
(-0.15,-0.10]      1      0.044        0.044       NaN     0.044     0.044
(-0.10,-0.05]     76      0.083        0.048     0.099     0.640     0.000
(-0.05,0.00]     973      0.061        0.033     0.092     1.105     0.000
(0.00,0.05]     6308      0.060        0.037     0.081     1.303     0.000
(0.05,0.10]     6713      0.077        0.058     0.078     1.191     0.000
(0.10,0.15]     1571      0.101        0.080     0.089     0.882     0.000
(0.15,0.20]      223      0.115        0.090     0.099     0.625     0.000
(0.20,0.25]       41      0.166        0.132     0.133     0.600     0.004
(0.25,0.30]        4      0.030        0.025     0.033     0.068     0.000
(0.30,0.35]        3      0.056        0.049     0.044     0.103     0.017
(0.35,0.40]        1      0.063        0.063       NaN     0.063     0.063
(0.40,0.45]        0        NaN          NaN       NaN       NaN       NaN
(0.45,0.50]        0        NaN          NaN       NaN       NaN       NaN
(0.50,0.55]        0        NaN          NaN       NaN       NaN       NaN
(0.55,0.60]        0        NaN          NaN       NaN       NaN       NaN
(0.60,0.65]        0        NaN          NaN       NaN       NaN       NaN
(0.65,0.70]        0        NaN          NaN       NaN       NaN       NaN
(0.70,0.75]        0        NaN          NaN       NaN       NaN       NaN
(0.75,0.80]        0        NaN          NaN       NaN       NaN       NaN
(0.80,0.85]        0        NaN          NaN       NaN       NaN       NaN
(0.85,0.90]        0        NaN          NaN       NaN       NaN       NaN
(0.90,0.95]        0        NaN          NaN       NaN       NaN       NaN
(0.95,1.00]        0        NaN          NaN       NaN       NaN       NaN

test period:20170701-20180101
(131874, 2036) (17387, 2036)

C:\Users\dell-pc\Anaconda3.6\lib\site-packages\lightgbm\basic.py:1042: UserWarning: categorical_feature in Dataset is overridden. New categorical_feature is ['area', 'exchange', 'is_hs', 'market']
--------------------Train network--------------------

  warnings.warn('categorical_feature in Dataset is overridden. New categorical_feature is {}'.format(sorted(list(categorical_feature))))
 (131874, 2036) (131874,) {'train_indexes': (0, 43958), 'fit': {'categorical_feature': ['area', 'market', 'exchange', 'is_hs']}}

----------Train layer 0----------
slice(0, 43958, None)

Train custom_revenue_y_s_rise
[LightGBM] [Warning] Using self-defined objective function
[LightGBM] [Warning] Using self-defined objective function
Time usage: 20.17s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=2, max_depth=8, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=10,
       n_jobs=-1, num_leaves=15,
       objective=<function custom_revenue_obj at 0x000001E7431D5EA0>,
       random_state=0, reg_alpha=0.0, reg_lambda=0.0, silent=True,
       subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
                                    feature  importance_raw  \
1705                                 sh_vol              30
921    p1000mv_(250k_low/p250mv_250k_low-1)              10
937      p100mv_(20k_open/p20mv_20k_open-1)              10
1233     p300mv_(60k_low-60k_close)/60k_avg              10
1160    p240mv_(60k_high-60k_close)/60k_avg              10
454                          (high-low)/avg              10
1268           p360mv_lower_shadow/120k_avg              10
357               (60k_low/p60mv_60k_low-1)              10
1014          p1250mv_lower_shadow/250k_avg              10
895                               hs300_vol              10
1238            p300mv_lower_shadow/60k_avg              10
1181  p250mv_(250k_low-250k_close)/250k_avg              10

      importance_percent
1705               21.43
921                 7.14
937                 7.14
1233                7.14
1160                7.14
454                 7.14
1268                7.14
357                 7.14
1014                7.14
895                 7.14
1238                7.14
1181                7.14
Among 2036 features, 2024 features are not used in the model

Train custom_revenue2_y_l_rise
[LightGBM] [Warning] Using self-defined objective function
[LightGBM] [Warning] Using self-defined objective function
Time usage: 20.49s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=2, max_depth=8, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=10,
       n_jobs=-1, num_leaves=15,
       objective=<function custom_revenue2_obj at 0x000001E7431E10D0>,
       random_state=0, reg_alpha=0.0, reg_lambda=0.0, silent=True,
       subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
                                      feature  importance_raw  \
567                                       amt              10
1705                                   sh_vol              10
1526          p80mv_(20k_low/p20mv_20k_low-1)               9
1014            p1250mv_lower_shadow/250k_avg               6
1466          p60mv_(20k_low/p20mv_20k_low-1)               6
1005  p1250mv_(250k_high-250k_close)/250k_avg               4
1865                                 sz50_vol               4
1235         p300mv_(60k_low/p60mv_60k_low-1)               4
1238              p300mv_lower_shadow/60k_avg               4
895                                 hs300_vol               3
1147   p240mv_(120k_high-120k_close)/120k_avg               3
2025                                   sz_vol               3
1457          p60mv_(20k_avg/p20mv_20k_avg-1)               3
454                            (high-low)/avg               3
937        p100mv_(20k_open/p20mv_20k_open-1)               3
342                (60k_high-60k_low)/60k_avg               2
351                (60k_low-60k_open)/60k_avg               2
357                 (60k_low/p60mv_60k_low-1)               2
1268             p360mv_lower_shadow/120k_avg               2
1160      p240mv_(60k_high-60k_close)/60k_avg               2

      importance_percent
567                 7.14
1705                7.14
1526                6.43
1014                4.29
1466                4.29
1005                2.86
1865                2.86
1235                2.86
1238                2.86
895                 2.14
1147                2.14
2025                2.14
1457                2.14
454                 2.14
937                 2.14
342                 1.43
351                 1.43
357                 1.43
1268                1.43
1160                1.43
Among 2036 features, 1964 features are not used in the model

Train custom_revenue2_y_l_avg
[LightGBM] [Warning] Using self-defined objective function
[LightGBM] [Warning] Using self-defined objective function
Time usage: 20.76s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=2, max_depth=8, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=10,
       n_jobs=-1, num_leaves=15,
       objective=<function custom_revenue2_obj at 0x000001E7431E10D0>,
       random_state=0, reg_alpha=0.0, reg_lambda=0.0, silent=True,
       subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
                                      feature  importance_raw  \
567                                       amt              10
1705                                   sh_vol              10
1526          p80mv_(20k_low/p20mv_20k_low-1)               9
1014            p1250mv_lower_shadow/250k_avg               6
1466          p60mv_(20k_low/p20mv_20k_low-1)               6
1005  p1250mv_(250k_high-250k_close)/250k_avg               4
1865                                 sz50_vol               4
1235         p300mv_(60k_low/p60mv_60k_low-1)               4
1238              p300mv_lower_shadow/60k_avg               4
895                                 hs300_vol               3
1147   p240mv_(120k_high-120k_close)/120k_avg               3
2025                                   sz_vol               3
1457          p60mv_(20k_avg/p20mv_20k_avg-1)               3
454                            (high-low)/avg               3
937        p100mv_(20k_open/p20mv_20k_open-1)               3
342                (60k_high-60k_low)/60k_avg               2
351                (60k_low-60k_open)/60k_avg               2
357                 (60k_low/p60mv_60k_low-1)               2
1268             p360mv_lower_shadow/120k_avg               2
1160      p240mv_(60k_high-60k_close)/60k_avg               2

      importance_percent
567                 7.14
1705                7.14
1526                6.43
1014                4.29
1466                4.29
1005                2.86
1865                2.86
1235                2.86
1238                2.86
895                 2.14
1147                2.14
2025                2.14
1457                2.14
454                 2.14
937                 2.14
342                 1.43
351                 1.43
357                 1.43
1268                1.43
1160                1.43
Among 2036 features, 1964 features are not used in the model

Train custom_revenue2_y_s_rise
[LightGBM] [Warning] Using self-defined objective function
[LightGBM] [Warning] Using self-defined objective function
Time usage: 20.62s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=2, max_depth=8, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=10,
       n_jobs=-1, num_leaves=15,
       objective=<function custom_revenue2_obj at 0x000001E7431E10D0>,
       random_state=0, reg_alpha=0.0, reg_lambda=0.0, silent=True,
       subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
                                      feature  importance_raw  \
567                                       amt              10
1705                                   sh_vol              10
1526          p80mv_(20k_low/p20mv_20k_low-1)               9
1014            p1250mv_lower_shadow/250k_avg               6
1466          p60mv_(20k_low/p20mv_20k_low-1)               6
1005  p1250mv_(250k_high-250k_close)/250k_avg               4
1865                                 sz50_vol               4
1235         p300mv_(60k_low/p60mv_60k_low-1)               4
1238              p300mv_lower_shadow/60k_avg               4
895                                 hs300_vol               3
1147   p240mv_(120k_high-120k_close)/120k_avg               3
2025                                   sz_vol               3
1457          p60mv_(20k_avg/p20mv_20k_avg-1)               3
454                            (high-low)/avg               3
937        p100mv_(20k_open/p20mv_20k_open-1)               3
342                (60k_high-60k_low)/60k_avg               2
351                (60k_low-60k_open)/60k_avg               2
357                 (60k_low/p60mv_60k_low-1)               2
1268             p360mv_lower_shadow/120k_avg               2
1160      p240mv_(60k_high-60k_close)/60k_avg               2

      importance_percent
567                 7.14
1705                7.14
1526                6.43
1014                4.29
1466                4.29
1005                2.86
1865                2.86
1235                2.86
1238                2.86
895                 2.14
1147                2.14
2025                2.14
1457                2.14
454                 2.14
937                 2.14
342                 1.43
351                 1.43
357                 1.43
1268                1.43
1160                1.43
Among 2036 features, 1964 features are not used in the model

Train custom_revenue_y_l_rise
[LightGBM] [Warning] Using self-defined objective function
[LightGBM] [Warning] Using self-defined objective function
Time usage: 20.67s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=2, max_depth=8, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=10,
       n_jobs=-1, num_leaves=15,
       objective=<function custom_revenue_obj at 0x000001E7431D5EA0>,
       random_state=0, reg_alpha=0.0, reg_lambda=0.0, silent=True,
       subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
                                    feature  importance_raw  \
1705                                 sh_vol              30
921    p1000mv_(250k_low/p250mv_250k_low-1)              10
937      p100mv_(20k_open/p20mv_20k_open-1)              10
1233     p300mv_(60k_low-60k_close)/60k_avg              10
1160    p240mv_(60k_high-60k_close)/60k_avg              10
454                          (high-low)/avg              10
1268           p360mv_lower_shadow/120k_avg              10
357               (60k_low/p60mv_60k_low-1)              10
1014          p1250mv_lower_shadow/250k_avg              10
895                               hs300_vol              10
1238            p300mv_lower_shadow/60k_avg              10
1181  p250mv_(250k_low-250k_close)/250k_avg              10

      importance_percent
1705               21.43
921                 7.14
937                 7.14
1233                7.14
1160                7.14
454                 7.14
1268                7.14
357                 7.14
1014                7.14
895                 7.14
1238                7.14
1181                7.14
Among 2036 features, 2024 features are not used in the model

Train custom_revenue2_y_s_decline
[LightGBM] [Warning] Using self-defined objective function
[LightGBM] [Warning] Using self-defined objective function
Time usage: 20.75s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=2, max_depth=8, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=10,
       n_jobs=-1, num_leaves=15,
       objective=<function custom_revenue2_obj at 0x000001E7431E10D0>,
       random_state=0, reg_alpha=0.0, reg_lambda=0.0, silent=True,
       subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
                                      feature  importance_raw  \
567                                       amt              10
1705                                   sh_vol              10
1526          p80mv_(20k_low/p20mv_20k_low-1)               9
1014            p1250mv_lower_shadow/250k_avg               6
1466          p60mv_(20k_low/p20mv_20k_low-1)               6
1005  p1250mv_(250k_high-250k_close)/250k_avg               4
1865                                 sz50_vol               4
1235         p300mv_(60k_low/p60mv_60k_low-1)               4
1238              p300mv_lower_shadow/60k_avg               4
895                                 hs300_vol               3
1147   p240mv_(120k_high-120k_close)/120k_avg               3
2025                                   sz_vol               3
1457          p60mv_(20k_avg/p20mv_20k_avg-1)               3
454                            (high-low)/avg               3
937        p100mv_(20k_open/p20mv_20k_open-1)               3
342                (60k_high-60k_low)/60k_avg               2
351                (60k_low-60k_open)/60k_avg               2
357                 (60k_low/p60mv_60k_low-1)               2
1268             p360mv_lower_shadow/120k_avg               2
1160      p240mv_(60k_high-60k_close)/60k_avg               2

      importance_percent
567                 7.14
1705                7.14
1526                6.43
1014                4.29
1466                4.29
1005                2.86
1865                2.86
1235                2.86
1238                2.86
895                 2.14
1147                2.14
2025                2.14
1457                2.14
454                 2.14
937                 2.14
342                 1.43
351                 1.43
357                 1.43
1268                1.43
1160                1.43
Among 2036 features, 1964 features are not used in the model

Train custom_revenue_y_s_avg
[LightGBM] [Warning] Using self-defined objective function
[LightGBM] [Warning] Using self-defined objective function
Time usage: 20.89s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=2, max_depth=8, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=10,
       n_jobs=-1, num_leaves=15,
       objective=<function custom_revenue_obj at 0x000001E7431D5EA0>,
       random_state=0, reg_alpha=0.0, reg_lambda=0.0, silent=True,
       subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
                                    feature  importance_raw  \
1705                                 sh_vol              30
921    p1000mv_(250k_low/p250mv_250k_low-1)              10
937      p100mv_(20k_open/p20mv_20k_open-1)              10
1233     p300mv_(60k_low-60k_close)/60k_avg              10
1160    p240mv_(60k_high-60k_close)/60k_avg              10
454                          (high-low)/avg              10
1268           p360mv_lower_shadow/120k_avg              10
357               (60k_low/p60mv_60k_low-1)              10
1014          p1250mv_lower_shadow/250k_avg              10
895                               hs300_vol              10
1238            p300mv_lower_shadow/60k_avg              10
1181  p250mv_(250k_low-250k_close)/250k_avg              10

      importance_percent
1705               21.43
921                 7.14
937                 7.14
1233                7.14
1160                7.14
454                 7.14
1268                7.14
357                 7.14
1014                7.14
895                 7.14
1238                7.14
1181                7.14
Among 2036 features, 2024 features are not used in the model

Train custom_revenue_y_s_decline
[LightGBM] [Warning] Using self-defined objective function
[LightGBM] [Warning] Using self-defined objective function
Time usage: 20.84s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=2, max_depth=8, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=10,
       n_jobs=-1, num_leaves=15,
       objective=<function custom_revenue_obj at 0x000001E7431D5EA0>,
       random_state=0, reg_alpha=0.0, reg_lambda=0.0, silent=True,
       subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
                                    feature  importance_raw  \
1705                                 sh_vol              30
921    p1000mv_(250k_low/p250mv_250k_low-1)              10
937      p100mv_(20k_open/p20mv_20k_open-1)              10
1233     p300mv_(60k_low-60k_close)/60k_avg              10
1160    p240mv_(60k_high-60k_close)/60k_avg              10
454                          (high-low)/avg              10
1268           p360mv_lower_shadow/120k_avg              10
357               (60k_low/p60mv_60k_low-1)              10
1014          p1250mv_lower_shadow/250k_avg              10
895                               hs300_vol              10
1238            p300mv_lower_shadow/60k_avg              10
1181  p250mv_(250k_low-250k_close)/250k_avg              10

      importance_percent
1705               21.43
921                 7.14
937                 7.14
1233                7.14
1160                7.14
454                 7.14
1268                7.14
357                 7.14
1014                7.14
895                 7.14
1238                7.14
1181                7.14
Among 2036 features, 2024 features are not used in the model

Train custom_revenue2_y_s_avg
[LightGBM] [Warning] Using self-defined objective function
[LightGBM] [Warning] Using self-defined objective function
Time usage: 21.06s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=2, max_depth=8, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=10,
       n_jobs=-1, num_leaves=15,
       objective=<function custom_revenue2_obj at 0x000001E7431E10D0>,
       random_state=0, reg_alpha=0.0, reg_lambda=0.0, silent=True,
       subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
                                      feature  importance_raw  \
567                                       amt              10
1705                                   sh_vol              10
1526          p80mv_(20k_low/p20mv_20k_low-1)               9
1014            p1250mv_lower_shadow/250k_avg               6
1466          p60mv_(20k_low/p20mv_20k_low-1)               6
1005  p1250mv_(250k_high-250k_close)/250k_avg               4
1865                                 sz50_vol               4
1235         p300mv_(60k_low/p60mv_60k_low-1)               4
1238              p300mv_lower_shadow/60k_avg               4
895                                 hs300_vol               3
1147   p240mv_(120k_high-120k_close)/120k_avg               3
2025                                   sz_vol               3
1457          p60mv_(20k_avg/p20mv_20k_avg-1)               3
454                            (high-low)/avg               3
937        p100mv_(20k_open/p20mv_20k_open-1)               3
342                (60k_high-60k_low)/60k_avg               2
351                (60k_low-60k_open)/60k_avg               2
357                 (60k_low/p60mv_60k_low-1)               2
1268             p360mv_lower_shadow/120k_avg               2
1160      p240mv_(60k_high-60k_close)/60k_avg               2

      importance_percent
567                 7.14
1705                7.14
1526                6.43
1014                4.29
1466                4.29
1005                2.86
1865                2.86
1235                2.86
1238                2.86
895                 2.14
1147                2.14
2025                2.14
1457                2.14
454                 2.14
937                 2.14
342                 1.43
351                 1.43
357                 1.43
1268                1.43
1160                1.43
Among 2036 features, 1964 features are not used in the model

Train custom_revenue_y_l_avg
[LightGBM] [Warning] Using self-defined objective function
[LightGBM] [Warning] Using self-defined objective function
Time usage: 20.99s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=2, max_depth=8, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=10,
       n_jobs=-1, num_leaves=15,
       objective=<function custom_revenue_obj at 0x000001E7431D5EA0>,
       random_state=0, reg_alpha=0.0, reg_lambda=0.0, silent=True,
       subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
                                    feature  importance_raw  \
1705                                 sh_vol              30
921    p1000mv_(250k_low/p250mv_250k_low-1)              10
937      p100mv_(20k_open/p20mv_20k_open-1)              10
1233     p300mv_(60k_low-60k_close)/60k_avg              10
1160    p240mv_(60k_high-60k_close)/60k_avg              10
454                          (high-low)/avg              10
1268           p360mv_lower_shadow/120k_avg              10
357               (60k_low/p60mv_60k_low-1)              10
1014          p1250mv_lower_shadow/250k_avg              10
895                               hs300_vol              10
1238            p300mv_lower_shadow/60k_avg              10
1181  p250mv_(250k_low-250k_close)/250k_avg              10

      importance_percent
1705               21.43
921                 7.14
937                 7.14
1233                7.14
1160                7.14
454                 7.14
1268                7.14
357                 7.14
1014                7.14
895                 7.14
1238                7.14
1181                7.14
Among 2036 features, 2024 features are not used in the model

Train custom_revenue2_y_l_decline
[LightGBM] [Warning] Using self-defined objective function
[LightGBM] [Warning] Using self-defined objective function
Time usage: 21.04s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=2, max_depth=8, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=10,
       n_jobs=-1, num_leaves=15,
       objective=<function custom_revenue2_obj at 0x000001E7431E10D0>,
       random_state=0, reg_alpha=0.0, reg_lambda=0.0, silent=True,
       subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
                                      feature  importance_raw  \
567                                       amt              10
1705                                   sh_vol              10
1526          p80mv_(20k_low/p20mv_20k_low-1)               9
1014            p1250mv_lower_shadow/250k_avg               6
1466          p60mv_(20k_low/p20mv_20k_low-1)               6
1005  p1250mv_(250k_high-250k_close)/250k_avg               4
1865                                 sz50_vol               4
1235         p300mv_(60k_low/p60mv_60k_low-1)               4
1238              p300mv_lower_shadow/60k_avg               4
895                                 hs300_vol               3
1147   p240mv_(120k_high-120k_close)/120k_avg               3
2025                                   sz_vol               3
1457          p60mv_(20k_avg/p20mv_20k_avg-1)               3
454                            (high-low)/avg               3
937        p100mv_(20k_open/p20mv_20k_open-1)               3
342                (60k_high-60k_low)/60k_avg               2
351                (60k_low-60k_open)/60k_avg               2
357                 (60k_low/p60mv_60k_low-1)               2
1268             p360mv_lower_shadow/120k_avg               2
1160      p240mv_(60k_high-60k_close)/60k_avg               2

      importance_percent
567                 7.14
1705                7.14
1526                6.43
1014                4.29
1466                4.29
1005                2.86
1865                2.86
1235                2.86
1238                2.86
895                 2.14
1147                2.14
2025                2.14
1457                2.14
454                 2.14
937                 2.14
342                 1.43
351                 1.43
357                 1.43
1268                1.43
1160                1.43
Among 2036 features, 1964 features are not used in the model

Train custom_revenue_y_l_decline
[LightGBM] [Warning] Using self-defined objective function
[LightGBM] [Warning] Using self-defined objective function
Time usage: 21.43s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=2, max_depth=8, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=10,
       n_jobs=-1, num_leaves=15,
       objective=<function custom_revenue_obj at 0x000001E7431D5EA0>,
       random_state=0, reg_alpha=0.0, reg_lambda=0.0, silent=True,
       subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
                                    feature  importance_raw  \
1705                                 sh_vol              30
921    p1000mv_(250k_low/p250mv_250k_low-1)              10
937      p100mv_(20k_open/p20mv_20k_open-1)              10
1233     p300mv_(60k_low-60k_close)/60k_avg              10
1160    p240mv_(60k_high-60k_close)/60k_avg              10
454                          (high-low)/avg              10
1268           p360mv_lower_shadow/120k_avg              10
357               (60k_low/p60mv_60k_low-1)              10
1014          p1250mv_lower_shadow/250k_avg              10
895                               hs300_vol              10
1238            p300mv_lower_shadow/60k_avg              10
1181  p250mv_(250k_low-250k_close)/250k_avg              10

      importance_percent
1705               21.43
921                 7.14
937                 7.14
1233                7.14
1160                7.14
454                 7.14
1268                7.14
357                 7.14
1014                7.14
895                 7.14
1238                7.14
1181                7.14
Among 2036 features, 2024 features are not used in the model

----------Layer 0 predicts----------

 (131874, 2180) (131874,) {'train_indexes': (43958, 87916), 'fit': {'categorical_feature': ['area', 'market', 'exchange', 'is_hs']}}

----------Train layer 1----------
slice(43958, 87916, None)

Train l2_y_l_rise
[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves
[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves
Time usage: 30.23s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=0.2, max_depth=12, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=25,
       n_jobs=-1, num_leaves=31, objective=None, random_state=0,
       reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,
       subsample_for_bin=200000, subsample_freq=0)
                                         feature  importance_raw  \
2025                                      sz_vol              49
1865                                    sz50_vol              37
1705                                      sh_vol              21
567                                          amt              19
895                                    hs300_vol              13
1350                p480mv_lower_shadow/120k_avg              12
568                                         area              10
1525            p80mv_(20k_low-20k_open)/20k_avg               9
1120            p20mv_(20k_low-20k_open)/20k_avg               9
1466             p60mv_(20k_low/p20mv_20k_low-1)               8
2054  layer0_custom_revenue2_y_l_rise_tree4_leaf               8
154                  (20k_open/p60mv_20k_open-1)               8
732                                      cyb_vol               8
1449       p600mv_(120k_low-120k_close)/120k_avg               7
1268                p360mv_lower_shadow/120k_avg               7
1347         p480mv_(120k_low/p120mv_120k_low-1)               7
124                    (20k_avg/p60mv_20k_avg-1)               6
141                  (20k_high/p80mv_20k_high-1)               6
1526             p80mv_(20k_low/p20mv_20k_low-1)               6
2048        layer0_custom_revenue2_y_l_rise_pred               6

      importance_percent
2025                6.53
1865                4.93
1705                2.80
567                 2.53
895                 1.73
1350                1.60
568                 1.33
1525                1.20
1120                1.20
1466                1.07
2054                1.07
154                 1.07
732                 1.07
1449                0.93
1268                0.93
1347                0.93
124                 0.80
141                 0.80
1526                0.80
2048                0.80
Among 2180 features, 1836 features are not used in the model

Train l2_y_s_avg
[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves
[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves
Time usage: 29.86s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=0.2, max_depth=12, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=25,
       n_jobs=-1, num_leaves=31, objective=None, random_state=0,
       reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,
       subsample_for_bin=200000, subsample_freq=0)
                                         feature  importance_raw  \
2025                                      sz_vol              49
1865                                    sz50_vol              37
1705                                      sh_vol              21
567                                          amt              19
895                                    hs300_vol              13
1350                p480mv_lower_shadow/120k_avg              12
568                                         area              10
1525            p80mv_(20k_low-20k_open)/20k_avg               9
1120            p20mv_(20k_low-20k_open)/20k_avg               9
1466             p60mv_(20k_low/p20mv_20k_low-1)               8
2054  layer0_custom_revenue2_y_l_rise_tree4_leaf               8
154                  (20k_open/p60mv_20k_open-1)               8
732                                      cyb_vol               8
1449       p600mv_(120k_low-120k_close)/120k_avg               7
1268                p360mv_lower_shadow/120k_avg               7
1347         p480mv_(120k_low/p120mv_120k_low-1)               7
124                    (20k_avg/p60mv_20k_avg-1)               6
141                  (20k_high/p80mv_20k_high-1)               6
1526             p80mv_(20k_low/p20mv_20k_low-1)               6
2048        layer0_custom_revenue2_y_l_rise_pred               6

      importance_percent
2025                6.53
1865                4.93
1705                2.80
567                 2.53
895                 1.73
1350                1.60
568                 1.33
1525                1.20
1120                1.20
1466                1.07
2054                1.07
154                 1.07
732                 1.07
1449                0.93
1268                0.93
1347                0.93
124                 0.80
141                 0.80
1526                0.80
2048                0.80
Among 2180 features, 1836 features are not used in the model

Train l2_y_s_rise
[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves
[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves
Time usage: 30.08s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=0.2, max_depth=12, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=25,
       n_jobs=-1, num_leaves=31, objective=None, random_state=0,
       reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,
       subsample_for_bin=200000, subsample_freq=0)
                                         feature  importance_raw  \
2025                                      sz_vol              49
1865                                    sz50_vol              37
1705                                      sh_vol              21
567                                          amt              19
895                                    hs300_vol              13
1350                p480mv_lower_shadow/120k_avg              12
568                                         area              10
1525            p80mv_(20k_low-20k_open)/20k_avg               9
1120            p20mv_(20k_low-20k_open)/20k_avg               9
1466             p60mv_(20k_low/p20mv_20k_low-1)               8
2054  layer0_custom_revenue2_y_l_rise_tree4_leaf               8
154                  (20k_open/p60mv_20k_open-1)               8
732                                      cyb_vol               8
1449       p600mv_(120k_low-120k_close)/120k_avg               7
1268                p360mv_lower_shadow/120k_avg               7
1347         p480mv_(120k_low/p120mv_120k_low-1)               7
124                    (20k_avg/p60mv_20k_avg-1)               6
141                  (20k_high/p80mv_20k_high-1)               6
1526             p80mv_(20k_low/p20mv_20k_low-1)               6
2048        layer0_custom_revenue2_y_l_rise_pred               6

      importance_percent
2025                6.53
1865                4.93
1705                2.80
567                 2.53
895                 1.73
1350                1.60
568                 1.33
1525                1.20
1120                1.20
1466                1.07
2054                1.07
154                 1.07
732                 1.07
1449                0.93
1268                0.93
1347                0.93
124                 0.80
141                 0.80
1526                0.80
2048                0.80
Among 2180 features, 1836 features are not used in the model

Train l2_y_l_decline
[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves
[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves
Time usage: 30.15s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=0.2, max_depth=12, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=25,
       n_jobs=-1, num_leaves=31, objective=None, random_state=0,
       reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,
       subsample_for_bin=200000, subsample_freq=0)
                                         feature  importance_raw  \
2025                                      sz_vol              49
1865                                    sz50_vol              37
1705                                      sh_vol              21
567                                          amt              19
895                                    hs300_vol              13
1350                p480mv_lower_shadow/120k_avg              12
568                                         area              10
1525            p80mv_(20k_low-20k_open)/20k_avg               9
1120            p20mv_(20k_low-20k_open)/20k_avg               9
1466             p60mv_(20k_low/p20mv_20k_low-1)               8
2054  layer0_custom_revenue2_y_l_rise_tree4_leaf               8
154                  (20k_open/p60mv_20k_open-1)               8
732                                      cyb_vol               8
1449       p600mv_(120k_low-120k_close)/120k_avg               7
1268                p360mv_lower_shadow/120k_avg               7
1347         p480mv_(120k_low/p120mv_120k_low-1)               7
124                    (20k_avg/p60mv_20k_avg-1)               6
141                  (20k_high/p80mv_20k_high-1)               6
1526             p80mv_(20k_low/p20mv_20k_low-1)               6
2048        layer0_custom_revenue2_y_l_rise_pred               6

      importance_percent
2025                6.53
1865                4.93
1705                2.80
567                 2.53
895                 1.73
1350                1.60
568                 1.33
1525                1.20
1120                1.20
1466                1.07
2054                1.07
154                 1.07
732                 1.07
1449                0.93
1268                0.93
1347                0.93
124                 0.80
141                 0.80
1526                0.80
2048                0.80
Among 2180 features, 1836 features are not used in the model

Train l2_y_l_avg
[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves
[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves
Time usage: 30.23s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=0.2, max_depth=12, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=25,
       n_jobs=-1, num_leaves=31, objective=None, random_state=0,
       reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,
       subsample_for_bin=200000, subsample_freq=0)
                                         feature  importance_raw  \
2025                                      sz_vol              49
1865                                    sz50_vol              37
1705                                      sh_vol              21
567                                          amt              19
895                                    hs300_vol              13
1350                p480mv_lower_shadow/120k_avg              12
568                                         area              10
1525            p80mv_(20k_low-20k_open)/20k_avg               9
1120            p20mv_(20k_low-20k_open)/20k_avg               9
1466             p60mv_(20k_low/p20mv_20k_low-1)               8
2054  layer0_custom_revenue2_y_l_rise_tree4_leaf               8
154                  (20k_open/p60mv_20k_open-1)               8
732                                      cyb_vol               8
1449       p600mv_(120k_low-120k_close)/120k_avg               7
1268                p360mv_lower_shadow/120k_avg               7
1347         p480mv_(120k_low/p120mv_120k_low-1)               7
124                    (20k_avg/p60mv_20k_avg-1)               6
141                  (20k_high/p80mv_20k_high-1)               6
1526             p80mv_(20k_low/p20mv_20k_low-1)               6
2048        layer0_custom_revenue2_y_l_rise_pred               6

      importance_percent
2025                6.53
1865                4.93
1705                2.80
567                 2.53
895                 1.73
1350                1.60
568                 1.33
1525                1.20
1120                1.20
1466                1.07
2054                1.07
154                 1.07
732                 1.07
1449                0.93
1268                0.93
1347                0.93
124                 0.80
141                 0.80
1526                0.80
2048                0.80
Among 2180 features, 1836 features are not used in the model

Train l2_y_s_decline
[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves
[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves
Time usage: 30.38s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=0.2, max_depth=12, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=25,
       n_jobs=-1, num_leaves=31, objective=None, random_state=0,
       reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,
       subsample_for_bin=200000, subsample_freq=0)
                                         feature  importance_raw  \
2025                                      sz_vol              49
1865                                    sz50_vol              37
1705                                      sh_vol              21
567                                          amt              19
895                                    hs300_vol              13
1350                p480mv_lower_shadow/120k_avg              12
568                                         area              10
1525            p80mv_(20k_low-20k_open)/20k_avg               9
1120            p20mv_(20k_low-20k_open)/20k_avg               9
1466             p60mv_(20k_low/p20mv_20k_low-1)               8
2054  layer0_custom_revenue2_y_l_rise_tree4_leaf               8
154                  (20k_open/p60mv_20k_open-1)               8
732                                      cyb_vol               8
1449       p600mv_(120k_low-120k_close)/120k_avg               7
1268                p360mv_lower_shadow/120k_avg               7
1347         p480mv_(120k_low/p120mv_120k_low-1)               7
124                    (20k_avg/p60mv_20k_avg-1)               6
141                  (20k_high/p80mv_20k_high-1)               6
1526             p80mv_(20k_low/p20mv_20k_low-1)               6
2048        layer0_custom_revenue2_y_l_rise_pred               6

      importance_percent
2025                6.53
1865                4.93
1705                2.80
567                 2.53
895                 1.73
1350                1.60
568                 1.33
1525                1.20
1120                1.20
1466                1.07
2054                1.07
154                 1.07
732                 1.07
1449                0.93
1268                0.93
1347                0.93
124                 0.80
141                 0.80
1526                0.80
2048                0.80
Among 2180 features, 1836 features are not used in the model

----------Layer 1 predicts----------

 (131874, 2336) (131874,) {'train_indexes': (87916, None), 'fit': {'categorical_feature': ['area', 'market', 'exchange', 'is_hs']}}

----------Train layer 2----------
slice(87916, None, None)

Train l2_y_l_r
[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves
[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves
Time usage: 41.54s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=0.1, max_depth=12, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=50,
       n_jobs=-1, num_leaves=31, objective=None, random_state=0,
       reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,
       subsample_for_bin=200000, subsample_freq=0)
                                   feature  importance_raw  importance_percent
568                                   area              57                3.80
2025                                sz_vol              32                2.13
895                              hs300_vol              28                1.87
567                                    amt              20                1.33
1705                                sh_vol              19                1.27
1865                              sz50_vol              16                1.07
1108       p20mv_(10k_low/p10mv_10k_low-1)              16                1.07
454                         (high-low)/avg              14                0.93
1112       p20mv_(20k_avg/p20mv_20k_avg-1)              14                0.93
1121       p20mv_(20k_low/p20mv_20k_low-1)              11                0.73
192          (250k_low-250k_open)/250k_avg              10                0.67
453                       (high-close)/avg               9                0.60
1229   p300mv_(60k_high-60k_close)/60k_avg               9                0.60
1074           p180mv_lower_shadow/60k_avg               9                0.60
493                     (low/p20max_low-1)               9                0.60
936       p100mv_(20k_low/p20mv_20k_low-1)               8                0.53
1466       p60mv_(20k_low/p20mv_20k_low-1)               8                0.53
1260  p360mv_(120k_high-120k_low)/120k_avg               8                0.53
2180               layer1_l2_y_l_rise_pred               8                0.53
1483            p60mv_lower_shadow/60k_avg               8                0.53
Among 2336 features, 1681 features are not used in the model

--------------------Predict--------------------

----------Layer 0 predicts----------

----------Layer 1 predicts----------

----------Layer 2 predicts----------

y_l_r
               count  eval_mean  eval_median  eval_std  eval_max  eval_min
pred_range
(-1.00,-0.95]      0        NaN          NaN       NaN       NaN       NaN
(-0.95,-0.90]      0        NaN          NaN       NaN       NaN       NaN
(-0.90,-0.85]      0        NaN          NaN       NaN       NaN       NaN
(-0.85,-0.80]      0        NaN          NaN       NaN       NaN       NaN
(-0.80,-0.75]      0        NaN          NaN       NaN       NaN       NaN
(-0.75,-0.70]      0        NaN          NaN       NaN       NaN       NaN
(-0.70,-0.65]      0        NaN          NaN       NaN       NaN       NaN
(-0.65,-0.60]      0        NaN          NaN       NaN       NaN       NaN
(-0.60,-0.55]      0        NaN          NaN       NaN       NaN       NaN
(-0.55,-0.50]      0        NaN          NaN       NaN       NaN       NaN
(-0.50,-0.45]      0        NaN          NaN       NaN       NaN       NaN
(-0.45,-0.40]      0        NaN          NaN       NaN       NaN       NaN
(-0.40,-0.35]      0        NaN          NaN       NaN       NaN       NaN
(-0.35,-0.30]      0        NaN          NaN       NaN       NaN       NaN
(-0.30,-0.25]      0        NaN          NaN       NaN       NaN       NaN
(-0.25,-0.20]      0        NaN          NaN       NaN       NaN       NaN
(-0.20,-0.15]      0        NaN          NaN       NaN       NaN       NaN
(-0.15,-0.10]     33      0.095        0.095     0.174     0.516    -0.171
(-0.10,-0.05]   1275      0.039        0.047     0.137     0.758    -0.375
(-0.05,0.00]    6993      0.020        0.000     0.113     0.812    -0.356
(0.00,0.05]     7705      0.016        0.000     0.111     0.854    -0.331
(0.05,0.10]     1246      0.022        0.033     0.139     1.730    -0.277
(0.10,0.15]      122      0.060        0.068     0.195     1.448    -0.236
(0.15,0.20]       12      0.067       -0.016     0.227     0.484    -0.189
(0.20,0.25]        1      0.267        0.267       NaN     0.267     0.267
(0.25,0.30]        0        NaN          NaN       NaN       NaN       NaN
(0.30,0.35]        0        NaN          NaN       NaN       NaN       NaN
(0.35,0.40]        0        NaN          NaN       NaN       NaN       NaN
(0.40,0.45]        0        NaN          NaN       NaN       NaN       NaN
(0.45,0.50]        0        NaN          NaN       NaN       NaN       NaN
(0.50,0.55]        0        NaN          NaN       NaN       NaN       NaN
(0.55,0.60]        0        NaN          NaN       NaN       NaN       NaN
(0.60,0.65]        0        NaN          NaN       NaN       NaN       NaN
(0.65,0.70]        0        NaN          NaN       NaN       NaN       NaN
(0.70,0.75]        0        NaN          NaN       NaN       NaN       NaN
(0.75,0.80]        0        NaN          NaN       NaN       NaN       NaN
(0.80,0.85]        0        NaN          NaN       NaN       NaN       NaN
(0.85,0.90]        0        NaN          NaN       NaN       NaN       NaN
(0.90,0.95]        0        NaN          NaN       NaN       NaN       NaN
(0.95,1.00]        0        NaN          NaN       NaN       NaN       NaN

y_l
               count  eval_mean  eval_median  eval_std  eval_max  eval_min
pred_range
(-1.00,-0.95]      0        NaN          NaN       NaN       NaN       NaN
(-0.95,-0.90]      0        NaN          NaN       NaN       NaN       NaN
(-0.90,-0.85]      0        NaN          NaN       NaN       NaN       NaN
(-0.85,-0.80]      0        NaN          NaN       NaN       NaN       NaN
(-0.80,-0.75]      0        NaN          NaN       NaN       NaN       NaN
(-0.75,-0.70]      0        NaN          NaN       NaN       NaN       NaN
(-0.70,-0.65]      0        NaN          NaN       NaN       NaN       NaN
(-0.65,-0.60]      0        NaN          NaN       NaN       NaN       NaN
(-0.60,-0.55]      0        NaN          NaN       NaN       NaN       NaN
(-0.55,-0.50]      0        NaN          NaN       NaN       NaN       NaN
(-0.50,-0.45]      0        NaN          NaN       NaN       NaN       NaN
(-0.45,-0.40]      0        NaN          NaN       NaN       NaN       NaN
(-0.40,-0.35]      0        NaN          NaN       NaN       NaN       NaN
(-0.35,-0.30]      0        NaN          NaN       NaN       NaN       NaN
(-0.30,-0.25]      0        NaN          NaN       NaN       NaN       NaN
(-0.25,-0.20]      0        NaN          NaN       NaN       NaN       NaN
(-0.20,-0.15]      0        NaN          NaN       NaN       NaN       NaN
(-0.15,-0.10]     33      0.105        0.102     0.210     0.604    -0.197
(-0.10,-0.05]   1275      0.045        0.059     0.160     0.836    -0.431
(-0.05,0.00]    6993      0.023        0.000     0.133     0.975    -0.397
(0.00,0.05]     7705      0.016        0.000     0.130     0.988    -0.379
(0.05,0.10]     1246      0.026        0.046     0.163     2.043    -0.329
(0.10,0.15]      122      0.065        0.079     0.231     1.711    -0.260
(0.15,0.20]       12      0.070       -0.024     0.265     0.558    -0.234
(0.20,0.25]        1      0.311        0.311       NaN     0.311     0.311
(0.25,0.30]        0        NaN          NaN       NaN       NaN       NaN
(0.30,0.35]        0        NaN          NaN       NaN       NaN       NaN
(0.35,0.40]        0        NaN          NaN       NaN       NaN       NaN
(0.40,0.45]        0        NaN          NaN       NaN       NaN       NaN
(0.45,0.50]        0        NaN          NaN       NaN       NaN       NaN
(0.50,0.55]        0        NaN          NaN       NaN       NaN       NaN
(0.55,0.60]        0        NaN          NaN       NaN       NaN       NaN
(0.60,0.65]        0        NaN          NaN       NaN       NaN       NaN
(0.65,0.70]        0        NaN          NaN       NaN       NaN       NaN
(0.70,0.75]        0        NaN          NaN       NaN       NaN       NaN
(0.75,0.80]        0        NaN          NaN       NaN       NaN       NaN
(0.80,0.85]        0        NaN          NaN       NaN       NaN       NaN
(0.85,0.90]        0        NaN          NaN       NaN       NaN       NaN
(0.90,0.95]        0        NaN          NaN       NaN       NaN       NaN
(0.95,1.00]        0        NaN          NaN       NaN       NaN       NaN

y_l_avg
               count  eval_mean  eval_median  eval_std  eval_max  eval_min
pred_range
(-1.00,-0.95]      0        NaN          NaN       NaN       NaN       NaN
(-0.95,-0.90]      0        NaN          NaN       NaN       NaN       NaN
(-0.90,-0.85]      0        NaN          NaN       NaN       NaN       NaN
(-0.85,-0.80]      0        NaN          NaN       NaN       NaN       NaN
(-0.80,-0.75]      0        NaN          NaN       NaN       NaN       NaN
(-0.75,-0.70]      0        NaN          NaN       NaN       NaN       NaN
(-0.70,-0.65]      0        NaN          NaN       NaN       NaN       NaN
(-0.65,-0.60]      0        NaN          NaN       NaN       NaN       NaN
(-0.60,-0.55]      0        NaN          NaN       NaN       NaN       NaN
(-0.55,-0.50]      0        NaN          NaN       NaN       NaN       NaN
(-0.50,-0.45]      0        NaN          NaN       NaN       NaN       NaN
(-0.45,-0.40]      0        NaN          NaN       NaN       NaN       NaN
(-0.40,-0.35]      0        NaN          NaN       NaN       NaN       NaN
(-0.35,-0.30]      0        NaN          NaN       NaN       NaN       NaN
(-0.30,-0.25]      0        NaN          NaN       NaN       NaN       NaN
(-0.25,-0.20]      0        NaN          NaN       NaN       NaN       NaN
(-0.20,-0.15]      0        NaN          NaN       NaN       NaN       NaN
(-0.15,-0.10]     33      0.041        0.024     0.083     0.252    -0.093
(-0.10,-0.05]   1275      0.021        0.011     0.074     0.525    -0.208
(-0.05,0.00]    6993      0.010        0.000     0.059     0.452    -0.261
(0.00,0.05]     7705      0.008        0.000     0.058     0.487    -0.226
(0.05,0.10]     1246      0.012        0.002     0.071     0.793    -0.187
(0.10,0.15]      122      0.030        0.014     0.098     0.659    -0.162
(0.15,0.20]       12      0.058        0.005     0.115     0.262    -0.076
(0.20,0.25]        1      0.135        0.135       NaN     0.135     0.135
(0.25,0.30]        0        NaN          NaN       NaN       NaN       NaN
(0.30,0.35]        0        NaN          NaN       NaN       NaN       NaN
(0.35,0.40]        0        NaN          NaN       NaN       NaN       NaN
(0.40,0.45]        0        NaN          NaN       NaN       NaN       NaN
(0.45,0.50]        0        NaN          NaN       NaN       NaN       NaN
(0.50,0.55]        0        NaN          NaN       NaN       NaN       NaN
(0.55,0.60]        0        NaN          NaN       NaN       NaN       NaN
(0.60,0.65]        0        NaN          NaN       NaN       NaN       NaN
(0.65,0.70]        0        NaN          NaN       NaN       NaN       NaN
(0.70,0.75]        0        NaN          NaN       NaN       NaN       NaN
(0.75,0.80]        0        NaN          NaN       NaN       NaN       NaN
(0.80,0.85]        0        NaN          NaN       NaN       NaN       NaN
(0.85,0.90]        0        NaN          NaN       NaN       NaN       NaN
(0.90,0.95]        0        NaN          NaN       NaN       NaN       NaN
(0.95,1.00]        0        NaN          NaN       NaN       NaN       NaN

y_l_rise
               count  eval_mean  eval_median  eval_std  eval_max  eval_min
pred_range
(-1.00,-0.95]      0        NaN          NaN       NaN       NaN       NaN
(-0.95,-0.90]      0        NaN          NaN       NaN       NaN       NaN
(-0.90,-0.85]      0        NaN          NaN       NaN       NaN       NaN
(-0.85,-0.80]      0        NaN          NaN       NaN       NaN       NaN
(-0.80,-0.75]      0        NaN          NaN       NaN       NaN       NaN
(-0.75,-0.70]      0        NaN          NaN       NaN       NaN       NaN
(-0.70,-0.65]      0        NaN          NaN       NaN       NaN       NaN
(-0.65,-0.60]      0        NaN          NaN       NaN       NaN       NaN
(-0.60,-0.55]      0        NaN          NaN       NaN       NaN       NaN
(-0.55,-0.50]      0        NaN          NaN       NaN       NaN       NaN
(-0.50,-0.45]      0        NaN          NaN       NaN       NaN       NaN
(-0.45,-0.40]      0        NaN          NaN       NaN       NaN       NaN
(-0.40,-0.35]      0        NaN          NaN       NaN       NaN       NaN
(-0.35,-0.30]      0        NaN          NaN       NaN       NaN       NaN
(-0.30,-0.25]      0        NaN          NaN       NaN       NaN       NaN
(-0.25,-0.20]      0        NaN          NaN       NaN       NaN       NaN
(-0.20,-0.15]      0        NaN          NaN       NaN       NaN       NaN
(-0.15,-0.10]     33      0.169        0.118     0.149     0.604     0.003
(-0.10,-0.05]   1275      0.102        0.068     0.107     0.836     0.000
(-0.05,0.00]    6993      0.077        0.051     0.086     0.975     0.000
(0.00,0.05]     7705      0.075        0.050     0.082     0.988     0.000
(0.05,0.10]     1246      0.093        0.064     0.112     2.043     0.000
(0.10,0.15]      122      0.134        0.087     0.181     1.711     0.000
(0.15,0.20]       12      0.186        0.096     0.164     0.558     0.060
(0.20,0.25]        1      0.311        0.311       NaN     0.311     0.311
(0.25,0.30]        0        NaN          NaN       NaN       NaN       NaN
(0.30,0.35]        0        NaN          NaN       NaN       NaN       NaN
(0.35,0.40]        0        NaN          NaN       NaN       NaN       NaN
(0.40,0.45]        0        NaN          NaN       NaN       NaN       NaN
(0.45,0.50]        0        NaN          NaN       NaN       NaN       NaN
(0.50,0.55]        0        NaN          NaN       NaN       NaN       NaN
(0.55,0.60]        0        NaN          NaN       NaN       NaN       NaN
(0.60,0.65]        0        NaN          NaN       NaN       NaN       NaN
(0.65,0.70]        0        NaN          NaN       NaN       NaN       NaN
(0.70,0.75]        0        NaN          NaN       NaN       NaN       NaN
(0.75,0.80]        0        NaN          NaN       NaN       NaN       NaN
(0.80,0.85]        0        NaN          NaN       NaN       NaN       NaN
(0.85,0.90]        0        NaN          NaN       NaN       NaN       NaN
(0.90,0.95]        0        NaN          NaN       NaN       NaN       NaN
(0.95,1.00]        0        NaN          NaN       NaN       NaN       NaN

test period:20180101-20180701
(149126, 2036) (16917, 2036)

--------------------Train network--------------------

 (149126, 2036) (149126,) {'train_indexes': (0, 49708), 'fit': {'categorical_feature': ['area', 'market', 'exchange', 'is_hs']}}

----------Train layer 0----------
slice(0, 49708, None)

Train custom_revenue_y_s_rise
C:\Users\dell-pc\Anaconda3.6\lib\site-packages\lightgbm\basic.py:1042: UserWarning: categorical_feature in Dataset is overridden. New categorical_feature is ['area', 'exchange', 'is_hs', 'market']
  warnings.warn('categorical_feature in Dataset is overridden. New categorical_feature is {}'.format(sorted(list(categorical_feature))))
[LightGBM] [Warning] Using self-defined objective function
[LightGBM] [Warning] Using self-defined objective function
Time usage: 23.70s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=2, max_depth=8, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=10,
       n_jobs=-1, num_leaves=15,
       objective=<function custom_revenue_obj at 0x000001E7431D5EA0>,
       random_state=0, reg_alpha=0.0, reg_lambda=0.0, silent=True,
       subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
                                       feature  importance_raw  \
1705                                    sh_vol              17
1466           p60mv_(20k_low/p20mv_20k_low-1)              10
1524         p80mv_(20k_low-20k_close)/20k_avg              10
1181     p250mv_(250k_low-250k_close)/250k_avg              10
1235          p300mv_(60k_low/p60mv_60k_low-1)              10
1005   p1250mv_(250k_high-250k_close)/250k_avg              10
1526           p80mv_(20k_low/p20mv_20k_low-1)              10
1147    p240mv_(120k_high-120k_close)/120k_avg              10
2025                                    sz_vol              10
1004  p1250mv_(250k_close/p250mv_250k_close-1)               7
454                             (high-low)/avg               7
1170               p240mv_lower_shadow/60k_avg               6
979      p120mv_(120k_low-120k_close)/120k_avg               5
1165         p240mv_(60k_low-60k_open)/60k_avg               4
238                  (3k_high/p15mv_3k_high-1)               3
567                                        amt               3
916      p1000mv_(250k_high-250k_low)/250k_avg               3
343                (60k_high-60k_open)/60k_avg               2
24               (10k_close/p50mv_10k_close-1)               2
1157          p240mv_(60k_avg/p60mv_60k_avg-1)               1

      importance_percent
1705               12.14
1466                7.14
1524                7.14
1181                7.14
1235                7.14
1005                7.14
1526                7.14
1147                7.14
2025                7.14
1004                5.00
454                 5.00
1170                4.29
979                 3.57
1165                2.86
238                 2.14
567                 2.14
916                 2.14
343                 1.43
24                  1.43
1157                0.71
Among 2036 features, 2016 features are not used in the model

Train custom_revenue2_y_l_rise
[LightGBM] [Warning] Using self-defined objective function
[LightGBM] [Warning] Using self-defined objective function
Time usage: 23.78s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=2, max_depth=8, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=10,
       n_jobs=-1, num_leaves=15,
       objective=<function custom_revenue2_obj at 0x000001E7431E10D0>,
       random_state=0, reg_alpha=0.0, reg_lambda=0.0, silent=True,
       subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
                                      feature  importance_raw  \
1705                                   sh_vol              14
567                                       amt              10
1526          p80mv_(20k_low/p20mv_20k_low-1)               7
1466          p60mv_(20k_low/p20mv_20k_low-1)               7
1014            p1250mv_lower_shadow/250k_avg               6
1479          p60mv_(60k_low/p60mv_60k_low-1)               4
1235         p300mv_(60k_low/p60mv_60k_low-1)               3
2025                                   sz_vol               3
1005  p1250mv_(250k_high-250k_close)/250k_avg               3
936          p100mv_(20k_low/p20mv_20k_low-1)               3
1160      p240mv_(60k_high-60k_close)/60k_avg               3
1268             p360mv_lower_shadow/120k_avg               2
1265      p360mv_(120k_low/p120mv_120k_low-1)               2
1350             p480mv_lower_shadow/120k_avg               2
357                 (60k_low/p60mv_60k_low-1)               2
937        p100mv_(20k_open/p20mv_20k_open-1)               2
1238              p300mv_lower_shadow/60k_avg               2
979     p120mv_(120k_low-120k_close)/120k_avg               2
895                                 hs300_vol               2
1165        p240mv_(60k_low-60k_open)/60k_avg               2

      importance_percent
1705               10.00
567                 7.14
1526                5.00
1466                5.00
1014                4.29
1479                2.86
1235                2.14
2025                2.14
1005                2.14
936                 2.14
1160                2.14
1268                1.43
1265                1.43
1350                1.43
357                 1.43
937                 1.43
1238                1.43
979                 1.43
895                 1.43
1165                1.43
Among 2036 features, 1958 features are not used in the model

Train custom_revenue2_y_l_avg
[LightGBM] [Warning] Using self-defined objective function
[LightGBM] [Warning] Using self-defined objective function
Time usage: 23.64s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=2, max_depth=8, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=10,
       n_jobs=-1, num_leaves=15,
       objective=<function custom_revenue2_obj at 0x000001E7431E10D0>,
       random_state=0, reg_alpha=0.0, reg_lambda=0.0, silent=True,
       subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
                                      feature  importance_raw  \
1705                                   sh_vol              14
567                                       amt              10
1526          p80mv_(20k_low/p20mv_20k_low-1)               7
1466          p60mv_(20k_low/p20mv_20k_low-1)               7
1014            p1250mv_lower_shadow/250k_avg               6
1479          p60mv_(60k_low/p60mv_60k_low-1)               4
1235         p300mv_(60k_low/p60mv_60k_low-1)               3
2025                                   sz_vol               3
1005  p1250mv_(250k_high-250k_close)/250k_avg               3
936          p100mv_(20k_low/p20mv_20k_low-1)               3
1160      p240mv_(60k_high-60k_close)/60k_avg               3
1268             p360mv_lower_shadow/120k_avg               2
1265      p360mv_(120k_low/p120mv_120k_low-1)               2
1350             p480mv_lower_shadow/120k_avg               2
357                 (60k_low/p60mv_60k_low-1)               2
937        p100mv_(20k_open/p20mv_20k_open-1)               2
1238              p300mv_lower_shadow/60k_avg               2
979     p120mv_(120k_low-120k_close)/120k_avg               2
895                                 hs300_vol               2
1165        p240mv_(60k_low-60k_open)/60k_avg               2

      importance_percent
1705               10.00
567                 7.14
1526                5.00
1466                5.00
1014                4.29
1479                2.86
1235                2.14
2025                2.14
1005                2.14
936                 2.14
1160                2.14
1268                1.43
1265                1.43
1350                1.43
357                 1.43
937                 1.43
1238                1.43
979                 1.43
895                 1.43
1165                1.43
Among 2036 features, 1958 features are not used in the model

Train custom_revenue2_y_s_rise
[LightGBM] [Warning] Using self-defined objective function
[LightGBM] [Warning] Using self-defined objective function
Time usage: 23.75s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=2, max_depth=8, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=10,
       n_jobs=-1, num_leaves=15,
       objective=<function custom_revenue2_obj at 0x000001E7431E10D0>,
       random_state=0, reg_alpha=0.0, reg_lambda=0.0, silent=True,
       subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
                                      feature  importance_raw  \
1705                                   sh_vol              14
567                                       amt              10
1526          p80mv_(20k_low/p20mv_20k_low-1)               7
1466          p60mv_(20k_low/p20mv_20k_low-1)               7
1014            p1250mv_lower_shadow/250k_avg               6
1479          p60mv_(60k_low/p60mv_60k_low-1)               4
1235         p300mv_(60k_low/p60mv_60k_low-1)               3
2025                                   sz_vol               3
1005  p1250mv_(250k_high-250k_close)/250k_avg               3
936          p100mv_(20k_low/p20mv_20k_low-1)               3
1160      p240mv_(60k_high-60k_close)/60k_avg               3
1268             p360mv_lower_shadow/120k_avg               2
1265      p360mv_(120k_low/p120mv_120k_low-1)               2
1350             p480mv_lower_shadow/120k_avg               2
357                 (60k_low/p60mv_60k_low-1)               2
937        p100mv_(20k_open/p20mv_20k_open-1)               2
1238              p300mv_lower_shadow/60k_avg               2
979     p120mv_(120k_low-120k_close)/120k_avg               2
895                                 hs300_vol               2
1165        p240mv_(60k_low-60k_open)/60k_avg               2

      importance_percent
1705               10.00
567                 7.14
1526                5.00
1466                5.00
1014                4.29
1479                2.86
1235                2.14
2025                2.14
1005                2.14
936                 2.14
1160                2.14
1268                1.43
1265                1.43
1350                1.43
357                 1.43
937                 1.43
1238                1.43
979                 1.43
895                 1.43
1165                1.43
Among 2036 features, 1958 features are not used in the model

Train custom_revenue_y_l_rise
[LightGBM] [Warning] Using self-defined objective function
[LightGBM] [Warning] Using self-defined objective function
Time usage: 23.67s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=2, max_depth=8, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=10,
       n_jobs=-1, num_leaves=15,
       objective=<function custom_revenue_obj at 0x000001E7431D5EA0>,
       random_state=0, reg_alpha=0.0, reg_lambda=0.0, silent=True,
       subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
                                       feature  importance_raw  \
1705                                    sh_vol              17
1466           p60mv_(20k_low/p20mv_20k_low-1)              10
1524         p80mv_(20k_low-20k_close)/20k_avg              10
1181     p250mv_(250k_low-250k_close)/250k_avg              10
1235          p300mv_(60k_low/p60mv_60k_low-1)              10
1005   p1250mv_(250k_high-250k_close)/250k_avg              10
1526           p80mv_(20k_low/p20mv_20k_low-1)              10
1147    p240mv_(120k_high-120k_close)/120k_avg              10
2025                                    sz_vol              10
1004  p1250mv_(250k_close/p250mv_250k_close-1)               7
454                             (high-low)/avg               7
1170               p240mv_lower_shadow/60k_avg               6
979      p120mv_(120k_low-120k_close)/120k_avg               5
1165         p240mv_(60k_low-60k_open)/60k_avg               4
238                  (3k_high/p15mv_3k_high-1)               3
567                                        amt               3
916      p1000mv_(250k_high-250k_low)/250k_avg               3
343                (60k_high-60k_open)/60k_avg               2
24               (10k_close/p50mv_10k_close-1)               2
1157          p240mv_(60k_avg/p60mv_60k_avg-1)               1

      importance_percent
1705               12.14
1466                7.14
1524                7.14
1181                7.14
1235                7.14
1005                7.14
1526                7.14
1147                7.14
2025                7.14
1004                5.00
454                 5.00
1170                4.29
979                 3.57
1165                2.86
238                 2.14
567                 2.14
916                 2.14
343                 1.43
24                  1.43
1157                0.71
Among 2036 features, 2016 features are not used in the model

Train custom_revenue2_y_s_decline
[LightGBM] [Warning] Using self-defined objective function
[LightGBM] [Warning] Using self-defined objective function
Time usage: 23.85s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=2, max_depth=8, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=10,
       n_jobs=-1, num_leaves=15,
       objective=<function custom_revenue2_obj at 0x000001E7431E10D0>,
       random_state=0, reg_alpha=0.0, reg_lambda=0.0, silent=True,
       subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
                                      feature  importance_raw  \
1705                                   sh_vol              14
567                                       amt              10
1526          p80mv_(20k_low/p20mv_20k_low-1)               7
1466          p60mv_(20k_low/p20mv_20k_low-1)               7
1014            p1250mv_lower_shadow/250k_avg               6
1479          p60mv_(60k_low/p60mv_60k_low-1)               4
1235         p300mv_(60k_low/p60mv_60k_low-1)               3
2025                                   sz_vol               3
1005  p1250mv_(250k_high-250k_close)/250k_avg               3
936          p100mv_(20k_low/p20mv_20k_low-1)               3
1160      p240mv_(60k_high-60k_close)/60k_avg               3
1268             p360mv_lower_shadow/120k_avg               2
1265      p360mv_(120k_low/p120mv_120k_low-1)               2
1350             p480mv_lower_shadow/120k_avg               2
357                 (60k_low/p60mv_60k_low-1)               2
937        p100mv_(20k_open/p20mv_20k_open-1)               2
1238              p300mv_lower_shadow/60k_avg               2
979     p120mv_(120k_low-120k_close)/120k_avg               2
895                                 hs300_vol               2
1165        p240mv_(60k_low-60k_open)/60k_avg               2

      importance_percent
1705               10.00
567                 7.14
1526                5.00
1466                5.00
1014                4.29
1479                2.86
1235                2.14
2025                2.14
1005                2.14
936                 2.14
1160                2.14
1268                1.43
1265                1.43
1350                1.43
357                 1.43
937                 1.43
1238                1.43
979                 1.43
895                 1.43
1165                1.43
Among 2036 features, 1958 features are not used in the model

Train custom_revenue_y_s_avg
[LightGBM] [Warning] Using self-defined objective function
[LightGBM] [Warning] Using self-defined objective function
Time usage: 24.12s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=2, max_depth=8, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=10,
       n_jobs=-1, num_leaves=15,
       objective=<function custom_revenue_obj at 0x000001E7431D5EA0>,
       random_state=0, reg_alpha=0.0, reg_lambda=0.0, silent=True,
       subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
                                       feature  importance_raw  \
1705                                    sh_vol              17
1466           p60mv_(20k_low/p20mv_20k_low-1)              10
1524         p80mv_(20k_low-20k_close)/20k_avg              10
1181     p250mv_(250k_low-250k_close)/250k_avg              10
1235          p300mv_(60k_low/p60mv_60k_low-1)              10
1005   p1250mv_(250k_high-250k_close)/250k_avg              10
1526           p80mv_(20k_low/p20mv_20k_low-1)              10
1147    p240mv_(120k_high-120k_close)/120k_avg              10
2025                                    sz_vol              10
1004  p1250mv_(250k_close/p250mv_250k_close-1)               7
454                             (high-low)/avg               7
1170               p240mv_lower_shadow/60k_avg               6
979      p120mv_(120k_low-120k_close)/120k_avg               5
1165         p240mv_(60k_low-60k_open)/60k_avg               4
238                  (3k_high/p15mv_3k_high-1)               3
567                                        amt               3
916      p1000mv_(250k_high-250k_low)/250k_avg               3
343                (60k_high-60k_open)/60k_avg               2
24               (10k_close/p50mv_10k_close-1)               2
1157          p240mv_(60k_avg/p60mv_60k_avg-1)               1

      importance_percent
1705               12.14
1466                7.14
1524                7.14
1181                7.14
1235                7.14
1005                7.14
1526                7.14
1147                7.14
2025                7.14
1004                5.00
454                 5.00
1170                4.29
979                 3.57
1165                2.86
238                 2.14
567                 2.14
916                 2.14
343                 1.43
24                  1.43
1157                0.71
Among 2036 features, 2016 features are not used in the model

Train custom_revenue_y_s_decline
[LightGBM] [Warning] Using self-defined objective function
[LightGBM] [Warning] Using self-defined objective function
Time usage: 24.03s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=2, max_depth=8, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=10,
       n_jobs=-1, num_leaves=15,
       objective=<function custom_revenue_obj at 0x000001E7431D5EA0>,
       random_state=0, reg_alpha=0.0, reg_lambda=0.0, silent=True,
       subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
                                       feature  importance_raw  \
1705                                    sh_vol              17
1466           p60mv_(20k_low/p20mv_20k_low-1)              10
1524         p80mv_(20k_low-20k_close)/20k_avg              10
1181     p250mv_(250k_low-250k_close)/250k_avg              10
1235          p300mv_(60k_low/p60mv_60k_low-1)              10
1005   p1250mv_(250k_high-250k_close)/250k_avg              10
1526           p80mv_(20k_low/p20mv_20k_low-1)              10
1147    p240mv_(120k_high-120k_close)/120k_avg              10
2025                                    sz_vol              10
1004  p1250mv_(250k_close/p250mv_250k_close-1)               7
454                             (high-low)/avg               7
1170               p240mv_lower_shadow/60k_avg               6
979      p120mv_(120k_low-120k_close)/120k_avg               5
1165         p240mv_(60k_low-60k_open)/60k_avg               4
238                  (3k_high/p15mv_3k_high-1)               3
567                                        amt               3
916      p1000mv_(250k_high-250k_low)/250k_avg               3
343                (60k_high-60k_open)/60k_avg               2
24               (10k_close/p50mv_10k_close-1)               2
1157          p240mv_(60k_avg/p60mv_60k_avg-1)               1

      importance_percent
1705               12.14
1466                7.14
1524                7.14
1181                7.14
1235                7.14
1005                7.14
1526                7.14
1147                7.14
2025                7.14
1004                5.00
454                 5.00
1170                4.29
979                 3.57
1165                2.86
238                 2.14
567                 2.14
916                 2.14
343                 1.43
24                  1.43
1157                0.71
Among 2036 features, 2016 features are not used in the model

Train custom_revenue2_y_s_avg
[LightGBM] [Warning] Using self-defined objective function
[LightGBM] [Warning] Using self-defined objective function
Time usage: 24.06s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=2, max_depth=8, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=10,
       n_jobs=-1, num_leaves=15,
       objective=<function custom_revenue2_obj at 0x000001E7431E10D0>,
       random_state=0, reg_alpha=0.0, reg_lambda=0.0, silent=True,
       subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
                                      feature  importance_raw  \
1705                                   sh_vol              14
567                                       amt              10
1526          p80mv_(20k_low/p20mv_20k_low-1)               7
1466          p60mv_(20k_low/p20mv_20k_low-1)               7
1014            p1250mv_lower_shadow/250k_avg               6
1479          p60mv_(60k_low/p60mv_60k_low-1)               4
1235         p300mv_(60k_low/p60mv_60k_low-1)               3
2025                                   sz_vol               3
1005  p1250mv_(250k_high-250k_close)/250k_avg               3
936          p100mv_(20k_low/p20mv_20k_low-1)               3
1160      p240mv_(60k_high-60k_close)/60k_avg               3
1268             p360mv_lower_shadow/120k_avg               2
1265      p360mv_(120k_low/p120mv_120k_low-1)               2
1350             p480mv_lower_shadow/120k_avg               2
357                 (60k_low/p60mv_60k_low-1)               2
937        p100mv_(20k_open/p20mv_20k_open-1)               2
1238              p300mv_lower_shadow/60k_avg               2
979     p120mv_(120k_low-120k_close)/120k_avg               2
895                                 hs300_vol               2
1165        p240mv_(60k_low-60k_open)/60k_avg               2

      importance_percent
1705               10.00
567                 7.14
1526                5.00
1466                5.00
1014                4.29
1479                2.86
1235                2.14
2025                2.14
1005                2.14
936                 2.14
1160                2.14
1268                1.43
1265                1.43
1350                1.43
357                 1.43
937                 1.43
1238                1.43
979                 1.43
895                 1.43
1165                1.43
Among 2036 features, 1958 features are not used in the model

Train custom_revenue_y_l_avg
[LightGBM] [Warning] Using self-defined objective function
[LightGBM] [Warning] Using self-defined objective function
Time usage: 24.20s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=2, max_depth=8, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=10,
       n_jobs=-1, num_leaves=15,
       objective=<function custom_revenue_obj at 0x000001E7431D5EA0>,
       random_state=0, reg_alpha=0.0, reg_lambda=0.0, silent=True,
       subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
                                       feature  importance_raw  \
1705                                    sh_vol              17
1466           p60mv_(20k_low/p20mv_20k_low-1)              10
1524         p80mv_(20k_low-20k_close)/20k_avg              10
1181     p250mv_(250k_low-250k_close)/250k_avg              10
1235          p300mv_(60k_low/p60mv_60k_low-1)              10
1005   p1250mv_(250k_high-250k_close)/250k_avg              10
1526           p80mv_(20k_low/p20mv_20k_low-1)              10
1147    p240mv_(120k_high-120k_close)/120k_avg              10
2025                                    sz_vol              10
1004  p1250mv_(250k_close/p250mv_250k_close-1)               7
454                             (high-low)/avg               7
1170               p240mv_lower_shadow/60k_avg               6
979      p120mv_(120k_low-120k_close)/120k_avg               5
1165         p240mv_(60k_low-60k_open)/60k_avg               4
238                  (3k_high/p15mv_3k_high-1)               3
567                                        amt               3
916      p1000mv_(250k_high-250k_low)/250k_avg               3
343                (60k_high-60k_open)/60k_avg               2
24               (10k_close/p50mv_10k_close-1)               2
1157          p240mv_(60k_avg/p60mv_60k_avg-1)               1

      importance_percent
1705               12.14
1466                7.14
1524                7.14
1181                7.14
1235                7.14
1005                7.14
1526                7.14
1147                7.14
2025                7.14
1004                5.00
454                 5.00
1170                4.29
979                 3.57
1165                2.86
238                 2.14
567                 2.14
916                 2.14
343                 1.43
24                  1.43
1157                0.71
Among 2036 features, 2016 features are not used in the model

Train custom_revenue2_y_l_decline
[LightGBM] [Warning] Using self-defined objective function
[LightGBM] [Warning] Using self-defined objective function
Time usage: 24.08s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=2, max_depth=8, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=10,
       n_jobs=-1, num_leaves=15,
       objective=<function custom_revenue2_obj at 0x000001E7431E10D0>,
       random_state=0, reg_alpha=0.0, reg_lambda=0.0, silent=True,
       subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
                                      feature  importance_raw  \
1705                                   sh_vol              14
567                                       amt              10
1526          p80mv_(20k_low/p20mv_20k_low-1)               7
1466          p60mv_(20k_low/p20mv_20k_low-1)               7
1014            p1250mv_lower_shadow/250k_avg               6
1479          p60mv_(60k_low/p60mv_60k_low-1)               4
1235         p300mv_(60k_low/p60mv_60k_low-1)               3
2025                                   sz_vol               3
1005  p1250mv_(250k_high-250k_close)/250k_avg               3
936          p100mv_(20k_low/p20mv_20k_low-1)               3
1160      p240mv_(60k_high-60k_close)/60k_avg               3
1268             p360mv_lower_shadow/120k_avg               2
1265      p360mv_(120k_low/p120mv_120k_low-1)               2
1350             p480mv_lower_shadow/120k_avg               2
357                 (60k_low/p60mv_60k_low-1)               2
937        p100mv_(20k_open/p20mv_20k_open-1)               2
1238              p300mv_lower_shadow/60k_avg               2
979     p120mv_(120k_low-120k_close)/120k_avg               2
895                                 hs300_vol               2
1165        p240mv_(60k_low-60k_open)/60k_avg               2

      importance_percent
1705               10.00
567                 7.14
1526                5.00
1466                5.00
1014                4.29
1479                2.86
1235                2.14
2025                2.14
1005                2.14
936                 2.14
1160                2.14
1268                1.43
1265                1.43
1350                1.43
357                 1.43
937                 1.43
1238                1.43
979                 1.43
895                 1.43
1165                1.43
Among 2036 features, 1958 features are not used in the model

Train custom_revenue_y_l_decline
[LightGBM] [Warning] Using self-defined objective function
[LightGBM] [Warning] Using self-defined objective function
Time usage: 24.50s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=2, max_depth=8, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=10,
       n_jobs=-1, num_leaves=15,
       objective=<function custom_revenue_obj at 0x000001E7431D5EA0>,
       random_state=0, reg_alpha=0.0, reg_lambda=0.0, silent=True,
       subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
                                       feature  importance_raw  \
1705                                    sh_vol              17
1466           p60mv_(20k_low/p20mv_20k_low-1)              10
1524         p80mv_(20k_low-20k_close)/20k_avg              10
1181     p250mv_(250k_low-250k_close)/250k_avg              10
1235          p300mv_(60k_low/p60mv_60k_low-1)              10
1005   p1250mv_(250k_high-250k_close)/250k_avg              10
1526           p80mv_(20k_low/p20mv_20k_low-1)              10
1147    p240mv_(120k_high-120k_close)/120k_avg              10
2025                                    sz_vol              10
1004  p1250mv_(250k_close/p250mv_250k_close-1)               7
454                             (high-low)/avg               7
1170               p240mv_lower_shadow/60k_avg               6
979      p120mv_(120k_low-120k_close)/120k_avg               5
1165         p240mv_(60k_low-60k_open)/60k_avg               4
238                  (3k_high/p15mv_3k_high-1)               3
567                                        amt               3
916      p1000mv_(250k_high-250k_low)/250k_avg               3
343                (60k_high-60k_open)/60k_avg               2
24               (10k_close/p50mv_10k_close-1)               2
1157          p240mv_(60k_avg/p60mv_60k_avg-1)               1

      importance_percent
1705               12.14
1466                7.14
1524                7.14
1181                7.14
1235                7.14
1005                7.14
1526                7.14
1147                7.14
2025                7.14
1004                5.00
454                 5.00
1170                4.29
979                 3.57
1165                2.86
238                 2.14
567                 2.14
916                 2.14
343                 1.43
24                  1.43
1157                0.71
Among 2036 features, 2016 features are not used in the model

----------Layer 0 predicts----------

 (149126, 2180) (149126,) {'train_indexes': (49708, 99416), 'fit': {'categorical_feature': ['area', 'market', 'exchange', 'is_hs']}}

----------Train layer 1----------
slice(49708, 99416, None)

Train l2_y_l_rise
[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves
[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves
Time usage: 32.84s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=0.2, max_depth=12, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=25,
       n_jobs=-1, num_leaves=31, objective=None, random_state=0,
       reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,
       subsample_for_bin=200000, subsample_freq=0)
                                    feature  importance_raw  \
2025                                 sz_vol              52
1865                               sz50_vol              40
895                               hs300_vol              26
1705                                 sh_vol              21
567                                     amt              17
568                                    area              10
732                                 cyb_vol               9
2035                                   vol0               9
1241        p30mv_(10k_avg/p10mv_10k_avg-1)               8
1321        p40mv_(20k_avg/p20mv_20k_avg-1)               7
1525       p80mv_(20k_low-20k_open)/20k_avg               7
2048   layer0_custom_revenue2_y_l_rise_pred               7
1350           p480mv_lower_shadow/120k_avg               7
1268           p360mv_lower_shadow/120k_avg               6
453                        (high-close)/avg               6
454                          (high-low)/avg               6
1347    p480mv_(120k_low/p120mv_120k_low-1)               6
1449  p600mv_(120k_low-120k_close)/120k_avg               6
1121        p20mv_(20k_low/p20mv_20k_low-1)               5
1415           p5mv_(5k_high-5k_low)/5k_avg               5

      importance_percent
2025                6.93
1865                5.33
895                 3.47
1705                2.80
567                 2.27
568                 1.33
732                 1.20
2035                1.20
1241                1.07
1321                0.93
1525                0.93
2048                0.93
1350                0.93
1268                0.80
453                 0.80
454                 0.80
1347                0.80
1449                0.80
1121                0.67
1415                0.67
Among 2180 features, 1836 features are not used in the model

Train l2_y_s_avg
[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves
[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves
Time usage: 33.98s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=0.2, max_depth=12, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=25,
       n_jobs=-1, num_leaves=31, objective=None, random_state=0,
       reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,
       subsample_for_bin=200000, subsample_freq=0)
                                    feature  importance_raw  \
2025                                 sz_vol              52
1865                               sz50_vol              40
895                               hs300_vol              26
1705                                 sh_vol              21
567                                     amt              17
568                                    area              10
732                                 cyb_vol               9
2035                                   vol0               9
1241        p30mv_(10k_avg/p10mv_10k_avg-1)               8
1321        p40mv_(20k_avg/p20mv_20k_avg-1)               7
1525       p80mv_(20k_low-20k_open)/20k_avg               7
2048   layer0_custom_revenue2_y_l_rise_pred               7
1350           p480mv_lower_shadow/120k_avg               7
1268           p360mv_lower_shadow/120k_avg               6
453                        (high-close)/avg               6
454                          (high-low)/avg               6
1347    p480mv_(120k_low/p120mv_120k_low-1)               6
1449  p600mv_(120k_low-120k_close)/120k_avg               6
1121        p20mv_(20k_low/p20mv_20k_low-1)               5
1415           p5mv_(5k_high-5k_low)/5k_avg               5

      importance_percent
2025                6.93
1865                5.33
895                 3.47
1705                2.80
567                 2.27
568                 1.33
732                 1.20
2035                1.20
1241                1.07
1321                0.93
1525                0.93
2048                0.93
1350                0.93
1268                0.80
453                 0.80
454                 0.80
1347                0.80
1449                0.80
1121                0.67
1415                0.67
Among 2180 features, 1836 features are not used in the model

Train l2_y_s_rise
[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves
[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves
Time usage: 34.55s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=0.2, max_depth=12, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=25,
       n_jobs=-1, num_leaves=31, objective=None, random_state=0,
       reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,
       subsample_for_bin=200000, subsample_freq=0)
                                    feature  importance_raw  \
2025                                 sz_vol              52
1865                               sz50_vol              40
895                               hs300_vol              26
1705                                 sh_vol              21
567                                     amt              17
568                                    area              10
732                                 cyb_vol               9
2035                                   vol0               9
1241        p30mv_(10k_avg/p10mv_10k_avg-1)               8
1321        p40mv_(20k_avg/p20mv_20k_avg-1)               7
1525       p80mv_(20k_low-20k_open)/20k_avg               7
2048   layer0_custom_revenue2_y_l_rise_pred               7
1350           p480mv_lower_shadow/120k_avg               7
1268           p360mv_lower_shadow/120k_avg               6
453                        (high-close)/avg               6
454                          (high-low)/avg               6
1347    p480mv_(120k_low/p120mv_120k_low-1)               6
1449  p600mv_(120k_low-120k_close)/120k_avg               6
1121        p20mv_(20k_low/p20mv_20k_low-1)               5
1415           p5mv_(5k_high-5k_low)/5k_avg               5

      importance_percent
2025                6.93
1865                5.33
895                 3.47
1705                2.80
567                 2.27
568                 1.33
732                 1.20
2035                1.20
1241                1.07
1321                0.93
1525                0.93
2048                0.93
1350                0.93
1268                0.80
453                 0.80
454                 0.80
1347                0.80
1449                0.80
1121                0.67
1415                0.67
Among 2180 features, 1836 features are not used in the model

Train l2_y_l_decline
[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves
[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves
Time usage: 34.10s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=0.2, max_depth=12, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=25,
       n_jobs=-1, num_leaves=31, objective=None, random_state=0,
       reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,
       subsample_for_bin=200000, subsample_freq=0)
                                    feature  importance_raw  \
2025                                 sz_vol              52
1865                               sz50_vol              40
895                               hs300_vol              26
1705                                 sh_vol              21
567                                     amt              17
568                                    area              10
732                                 cyb_vol               9
2035                                   vol0               9
1241        p30mv_(10k_avg/p10mv_10k_avg-1)               8
1321        p40mv_(20k_avg/p20mv_20k_avg-1)               7
1525       p80mv_(20k_low-20k_open)/20k_avg               7
2048   layer0_custom_revenue2_y_l_rise_pred               7
1350           p480mv_lower_shadow/120k_avg               7
1268           p360mv_lower_shadow/120k_avg               6
453                        (high-close)/avg               6
454                          (high-low)/avg               6
1347    p480mv_(120k_low/p120mv_120k_low-1)               6
1449  p600mv_(120k_low-120k_close)/120k_avg               6
1121        p20mv_(20k_low/p20mv_20k_low-1)               5
1415           p5mv_(5k_high-5k_low)/5k_avg               5

      importance_percent
2025                6.93
1865                5.33
895                 3.47
1705                2.80
567                 2.27
568                 1.33
732                 1.20
2035                1.20
1241                1.07
1321                0.93
1525                0.93
2048                0.93
1350                0.93
1268                0.80
453                 0.80
454                 0.80
1347                0.80
1449                0.80
1121                0.67
1415                0.67
Among 2180 features, 1836 features are not used in the model

Train l2_y_l_avg
[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves
[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves
Time usage: 34.65s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=0.2, max_depth=12, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=25,
       n_jobs=-1, num_leaves=31, objective=None, random_state=0,
       reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,
       subsample_for_bin=200000, subsample_freq=0)
                                    feature  importance_raw  \
2025                                 sz_vol              52
1865                               sz50_vol              40
895                               hs300_vol              26
1705                                 sh_vol              21
567                                     amt              17
568                                    area              10
732                                 cyb_vol               9
2035                                   vol0               9
1241        p30mv_(10k_avg/p10mv_10k_avg-1)               8
1321        p40mv_(20k_avg/p20mv_20k_avg-1)               7
1525       p80mv_(20k_low-20k_open)/20k_avg               7
2048   layer0_custom_revenue2_y_l_rise_pred               7
1350           p480mv_lower_shadow/120k_avg               7
1268           p360mv_lower_shadow/120k_avg               6
453                        (high-close)/avg               6
454                          (high-low)/avg               6
1347    p480mv_(120k_low/p120mv_120k_low-1)               6
1449  p600mv_(120k_low-120k_close)/120k_avg               6
1121        p20mv_(20k_low/p20mv_20k_low-1)               5
1415           p5mv_(5k_high-5k_low)/5k_avg               5

      importance_percent
2025                6.93
1865                5.33
895                 3.47
1705                2.80
567                 2.27
568                 1.33
732                 1.20
2035                1.20
1241                1.07
1321                0.93
1525                0.93
2048                0.93
1350                0.93
1268                0.80
453                 0.80
454                 0.80
1347                0.80
1449                0.80
1121                0.67
1415                0.67
Among 2180 features, 1836 features are not used in the model

Train l2_y_s_decline
[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves
[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves
Time usage: 34.37s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=0.2, max_depth=12, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=25,
       n_jobs=-1, num_leaves=31, objective=None, random_state=0,
       reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,
       subsample_for_bin=200000, subsample_freq=0)
                                    feature  importance_raw  \
2025                                 sz_vol              52
1865                               sz50_vol              40
895                               hs300_vol              26
1705                                 sh_vol              21
567                                     amt              17
568                                    area              10
732                                 cyb_vol               9
2035                                   vol0               9
1241        p30mv_(10k_avg/p10mv_10k_avg-1)               8
1321        p40mv_(20k_avg/p20mv_20k_avg-1)               7
1525       p80mv_(20k_low-20k_open)/20k_avg               7
2048   layer0_custom_revenue2_y_l_rise_pred               7
1350           p480mv_lower_shadow/120k_avg               7
1268           p360mv_lower_shadow/120k_avg               6
453                        (high-close)/avg               6
454                          (high-low)/avg               6
1347    p480mv_(120k_low/p120mv_120k_low-1)               6
1449  p600mv_(120k_low-120k_close)/120k_avg               6
1121        p20mv_(20k_low/p20mv_20k_low-1)               5
1415           p5mv_(5k_high-5k_low)/5k_avg               5

      importance_percent
2025                6.93
1865                5.33
895                 3.47
1705                2.80
567                 2.27
568                 1.33
732                 1.20
2035                1.20
1241                1.07
1321                0.93
1525                0.93
2048                0.93
1350                0.93
1268                0.80
453                 0.80
454                 0.80
1347                0.80
1449                0.80
1121                0.67
1415                0.67
Among 2180 features, 1836 features are not used in the model

----------Layer 1 predicts----------

 (149126, 2336) (149126,) {'train_indexes': (99416, None), 'fit': {'categorical_feature': ['area', 'market', 'exchange', 'is_hs']}}

----------Train layer 2----------
slice(99416, None, None)

Train l2_y_l_r
[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves
[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves
Time usage: 47.83s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=0.1, max_depth=12, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=50,
       n_jobs=-1, num_leaves=31, objective=None, random_state=0,
       reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,
       subsample_for_bin=200000, subsample_freq=0)
                                    feature  importance_raw  \
568                                    area              87
895                               hs300_vol              48
1865                               sz50_vol              28
1705                                 sh_vol              25
567                                     amt              21
2025                                 sz_vol              16
994        p120mv_(60k_low/p60mv_60k_low-1)              15
1157       p240mv_(60k_avg/p60mv_60k_avg-1)              13
1509  p750mv_(250k_low-250k_close)/250k_avg              12
1074            p180mv_lower_shadow/60k_avg              12
1264   p360mv_(120k_low-120k_open)/120k_avg              11
1466        p60mv_(20k_low/p20mv_20k_low-1)              11
1121        p20mv_(20k_low/p20mv_20k_low-1)              11
1226       p300mv_(60k_avg/p60mv_60k_avg-1)              11
933      p100mv_(20k_high/p20mv_20k_high-1)              10
454                          (high-low)/avg               9
1351           p480mv_upper_shadow/120k_avg               9
1260   p360mv_(120k_high-120k_low)/120k_avg               9
937      p100mv_(20k_open/p20mv_20k_open-1)               9
936        p100mv_(20k_low/p20mv_20k_low-1)               8

      importance_percent
568                 5.80
895                 3.20
1865                1.87
1705                1.67
567                 1.40
2025                1.07
994                 1.00
1157                0.87
1509                0.80
1074                0.80
1264                0.73
1466                0.73
1121                0.73
1226                0.73
933                 0.67
454                 0.60
1351                0.60
1260                0.60
937                 0.60
936                 0.53
Among 2336 features, 1723 features are not used in the model

--------------------Predict--------------------

----------Layer 0 predicts----------

----------Layer 1 predicts----------

----------Layer 2 predicts----------

y_l_r
               count  eval_mean  eval_median  eval_std  eval_max  eval_min
pred_range
(-1.00,-0.95]      0        NaN          NaN       NaN       NaN       NaN
(-0.95,-0.90]      0        NaN          NaN       NaN       NaN       NaN
(-0.90,-0.85]      0        NaN          NaN       NaN       NaN       NaN
(-0.85,-0.80]      0        NaN          NaN       NaN       NaN       NaN
(-0.80,-0.75]      0        NaN          NaN       NaN       NaN       NaN
(-0.75,-0.70]      0        NaN          NaN       NaN       NaN       NaN
(-0.70,-0.65]      0        NaN          NaN       NaN       NaN       NaN
(-0.65,-0.60]      0        NaN          NaN       NaN       NaN       NaN
(-0.60,-0.55]      0        NaN          NaN       NaN       NaN       NaN
(-0.55,-0.50]      0        NaN          NaN       NaN       NaN       NaN
(-0.50,-0.45]      0        NaN          NaN       NaN       NaN       NaN
(-0.45,-0.40]      0        NaN          NaN       NaN       NaN       NaN
(-0.40,-0.35]      0        NaN          NaN       NaN       NaN       NaN
(-0.35,-0.30]      0        NaN          NaN       NaN       NaN       NaN
(-0.30,-0.25]      0        NaN          NaN       NaN       NaN       NaN
(-0.25,-0.20]      0        NaN          NaN       NaN       NaN       NaN
(-0.20,-0.15]      0        NaN          NaN       NaN       NaN       NaN
(-0.15,-0.10]      4     -0.250       -0.275     0.072    -0.146    -0.303
(-0.10,-0.05]     80     -0.061       -0.133     0.188     0.563    -0.328
(-0.05,0.00]    3768     -0.037       -0.065     0.135     1.151    -0.607
(0.00,0.05]    10948     -0.018       -0.053     0.133     0.748    -0.608
(0.05,0.10]     1985     -0.008       -0.055     0.151     0.770    -0.527
(0.10,0.15]      122     -0.008       -0.078     0.181     0.450    -0.323
(0.15,0.20]        9      0.004        0.000     0.175     0.250    -0.216
(0.20,0.25]        1      0.217        0.217       NaN     0.217     0.217
(0.25,0.30]        0        NaN          NaN       NaN       NaN       NaN
(0.30,0.35]        0        NaN          NaN       NaN       NaN       NaN
(0.35,0.40]        0        NaN          NaN       NaN       NaN       NaN
(0.40,0.45]        0        NaN          NaN       NaN       NaN       NaN
(0.45,0.50]        0        NaN          NaN       NaN       NaN       NaN
(0.50,0.55]        0        NaN          NaN       NaN       NaN       NaN
(0.55,0.60]        0        NaN          NaN       NaN       NaN       NaN
(0.60,0.65]        0        NaN          NaN       NaN       NaN       NaN
(0.65,0.70]        0        NaN          NaN       NaN       NaN       NaN
(0.70,0.75]        0        NaN          NaN       NaN       NaN       NaN
(0.75,0.80]        0        NaN          NaN       NaN       NaN       NaN
(0.80,0.85]        0        NaN          NaN       NaN       NaN       NaN
(0.85,0.90]        0        NaN          NaN       NaN       NaN       NaN
(0.90,0.95]        0        NaN          NaN       NaN       NaN       NaN
(0.95,1.00]        0        NaN          NaN       NaN       NaN       NaN

y_l
               count  eval_mean  eval_median  eval_std  eval_max  eval_min
pred_range
(-1.00,-0.95]      0        NaN          NaN       NaN       NaN       NaN
(-0.95,-0.90]      0        NaN          NaN       NaN       NaN       NaN
(-0.90,-0.85]      0        NaN          NaN       NaN       NaN       NaN
(-0.85,-0.80]      0        NaN          NaN       NaN       NaN       NaN
(-0.80,-0.75]      0        NaN          NaN       NaN       NaN       NaN
(-0.75,-0.70]      0        NaN          NaN       NaN       NaN       NaN
(-0.70,-0.65]      0        NaN          NaN       NaN       NaN       NaN
(-0.65,-0.60]      0        NaN          NaN       NaN       NaN       NaN
(-0.60,-0.55]      0        NaN          NaN       NaN       NaN       NaN
(-0.55,-0.50]      0        NaN          NaN       NaN       NaN       NaN
(-0.50,-0.45]      0        NaN          NaN       NaN       NaN       NaN
(-0.45,-0.40]      0        NaN          NaN       NaN       NaN       NaN
(-0.40,-0.35]      0        NaN          NaN       NaN       NaN       NaN
(-0.35,-0.30]      0        NaN          NaN       NaN       NaN       NaN
(-0.30,-0.25]      0        NaN          NaN       NaN       NaN       NaN
(-0.25,-0.20]      0        NaN          NaN       NaN       NaN       NaN
(-0.20,-0.15]      0        NaN          NaN       NaN       NaN       NaN
(-0.15,-0.10]      4     -0.300       -0.326     0.088    -0.173    -0.374
(-0.10,-0.05]     80     -0.067       -0.154     0.224     0.645    -0.386
(-0.05,0.00]    3768     -0.051       -0.091     0.157     1.326    -0.625
(0.00,0.05]    10948     -0.028       -0.077     0.155     0.839    -0.625
(0.05,0.10]     1985     -0.017       -0.080     0.176     0.845    -0.576
(0.10,0.15]      122     -0.021       -0.102     0.212     0.513    -0.364
(0.15,0.20]        9     -0.030       -0.144     0.211     0.293    -0.259
(0.20,0.25]        1      0.255        0.255       NaN     0.255     0.255
(0.25,0.30]        0        NaN          NaN       NaN       NaN       NaN
(0.30,0.35]        0        NaN          NaN       NaN       NaN       NaN
(0.35,0.40]        0        NaN          NaN       NaN       NaN       NaN
(0.40,0.45]        0        NaN          NaN       NaN       NaN       NaN
(0.45,0.50]        0        NaN          NaN       NaN       NaN       NaN
(0.50,0.55]        0        NaN          NaN       NaN       NaN       NaN
(0.55,0.60]        0        NaN          NaN       NaN       NaN       NaN
(0.60,0.65]        0        NaN          NaN       NaN       NaN       NaN
(0.65,0.70]        0        NaN          NaN       NaN       NaN       NaN
(0.70,0.75]        0        NaN          NaN       NaN       NaN       NaN
(0.75,0.80]        0        NaN          NaN       NaN       NaN       NaN
(0.80,0.85]        0        NaN          NaN       NaN       NaN       NaN
(0.85,0.90]        0        NaN          NaN       NaN       NaN       NaN
(0.90,0.95]        0        NaN          NaN       NaN       NaN       NaN
(0.95,1.00]        0        NaN          NaN       NaN       NaN       NaN

y_l_avg
               count  eval_mean  eval_median  eval_std  eval_max  eval_min
pred_range
(-1.00,-0.95]      0        NaN          NaN       NaN       NaN       NaN
(-0.95,-0.90]      0        NaN          NaN       NaN       NaN       NaN
(-0.90,-0.85]      0        NaN          NaN       NaN       NaN       NaN
(-0.85,-0.80]      0        NaN          NaN       NaN       NaN       NaN
(-0.80,-0.75]      0        NaN          NaN       NaN       NaN       NaN
(-0.75,-0.70]      0        NaN          NaN       NaN       NaN       NaN
(-0.70,-0.65]      0        NaN          NaN       NaN       NaN       NaN
(-0.65,-0.60]      0        NaN          NaN       NaN       NaN       NaN
(-0.60,-0.55]      0        NaN          NaN       NaN       NaN       NaN
(-0.55,-0.50]      0        NaN          NaN       NaN       NaN       NaN
(-0.50,-0.45]      0        NaN          NaN       NaN       NaN       NaN
(-0.45,-0.40]      0        NaN          NaN       NaN       NaN       NaN
(-0.40,-0.35]      0        NaN          NaN       NaN       NaN       NaN
(-0.35,-0.30]      0        NaN          NaN       NaN       NaN       NaN
(-0.30,-0.25]      0        NaN          NaN       NaN       NaN       NaN
(-0.25,-0.20]      0        NaN          NaN       NaN       NaN       NaN
(-0.20,-0.15]      0        NaN          NaN       NaN       NaN       NaN
(-0.15,-0.10]      4     -0.101       -0.084     0.048    -0.066    -0.171
(-0.10,-0.05]     80     -0.026       -0.030     0.100     0.315    -0.204
(-0.05,0.00]    3768     -0.016       -0.012     0.070     0.625    -0.552
(0.00,0.05]    10948     -0.006       -0.008     0.070     0.594    -0.562
(0.05,0.10]     1985     -0.003       -0.008     0.083     0.546    -0.378
(0.10,0.15]      122     -0.007       -0.014     0.094     0.261    -0.203
(0.15,0.20]        9     -0.006        0.000     0.075     0.123    -0.089
(0.20,0.25]        1      0.102        0.102       NaN     0.102     0.102
(0.25,0.30]        0        NaN          NaN       NaN       NaN       NaN
(0.30,0.35]        0        NaN          NaN       NaN       NaN       NaN
(0.35,0.40]        0        NaN          NaN       NaN       NaN       NaN
(0.40,0.45]        0        NaN          NaN       NaN       NaN       NaN
(0.45,0.50]        0        NaN          NaN       NaN       NaN       NaN
(0.50,0.55]        0        NaN          NaN       NaN       NaN       NaN
(0.55,0.60]        0        NaN          NaN       NaN       NaN       NaN
(0.60,0.65]        0        NaN          NaN       NaN       NaN       NaN
(0.65,0.70]        0        NaN          NaN       NaN       NaN       NaN
(0.70,0.75]        0        NaN          NaN       NaN       NaN       NaN
(0.75,0.80]        0        NaN          NaN       NaN       NaN       NaN
(0.80,0.85]        0        NaN          NaN       NaN       NaN       NaN
(0.85,0.90]        0        NaN          NaN       NaN       NaN       NaN
(0.90,0.95]        0        NaN          NaN       NaN       NaN       NaN
(0.95,1.00]        0        NaN          NaN       NaN       NaN       NaN

y_l_rise
               count  eval_mean  eval_median  eval_std  eval_max  eval_min
pred_range
(-1.00,-0.95]      0        NaN          NaN       NaN       NaN       NaN
(-0.95,-0.90]      0        NaN          NaN       NaN       NaN       NaN
(-0.90,-0.85]      0        NaN          NaN       NaN       NaN       NaN
(-0.85,-0.80]      0        NaN          NaN       NaN       NaN       NaN
(-0.80,-0.75]      0        NaN          NaN       NaN       NaN       NaN
(-0.75,-0.70]      0        NaN          NaN       NaN       NaN       NaN
(-0.70,-0.65]      0        NaN          NaN       NaN       NaN       NaN
(-0.65,-0.60]      0        NaN          NaN       NaN       NaN       NaN
(-0.60,-0.55]      0        NaN          NaN       NaN       NaN       NaN
(-0.55,-0.50]      0        NaN          NaN       NaN       NaN       NaN
(-0.50,-0.45]      0        NaN          NaN       NaN       NaN       NaN
(-0.45,-0.40]      0        NaN          NaN       NaN       NaN       NaN
(-0.40,-0.35]      0        NaN          NaN       NaN       NaN       NaN
(-0.35,-0.30]      0        NaN          NaN       NaN       NaN       NaN
(-0.30,-0.25]      0        NaN          NaN       NaN       NaN       NaN
(-0.25,-0.20]      0        NaN          NaN       NaN       NaN       NaN
(-0.20,-0.15]      0        NaN          NaN       NaN       NaN       NaN
(-0.15,-0.10]      4      0.079        0.073     0.065     0.159     0.012
(-0.10,-0.05]     80      0.106        0.065     0.112     0.645     0.000
(-0.05,0.00]    3768      0.065        0.039     0.080     1.326     0.000
(0.00,0.05]    10948      0.074        0.049     0.081     0.839     0.000
(0.05,0.10]     1985      0.090        0.061     0.094     0.845     0.000
(0.10,0.15]      122      0.108        0.066     0.120     0.513     0.000
(0.15,0.20]        9      0.110        0.095     0.111     0.293     0.000
(0.20,0.25]        1      0.255        0.255       NaN     0.255     0.255
(0.25,0.30]        0        NaN          NaN       NaN       NaN       NaN
(0.30,0.35]        0        NaN          NaN       NaN       NaN       NaN
(0.35,0.40]        0        NaN          NaN       NaN       NaN       NaN
(0.40,0.45]        0        NaN          NaN       NaN       NaN       NaN
(0.45,0.50]        0        NaN          NaN       NaN       NaN       NaN
(0.50,0.55]        0        NaN          NaN       NaN       NaN       NaN
(0.55,0.60]        0        NaN          NaN       NaN       NaN       NaN
(0.60,0.65]        0        NaN          NaN       NaN       NaN       NaN
(0.65,0.70]        0        NaN          NaN       NaN       NaN       NaN
(0.70,0.75]        0        NaN          NaN       NaN       NaN       NaN
(0.75,0.80]        0        NaN          NaN       NaN       NaN       NaN
(0.80,0.85]        0        NaN          NaN       NaN       NaN       NaN
(0.85,0.90]        0        NaN          NaN       NaN       NaN       NaN
(0.90,0.95]        0        NaN          NaN       NaN       NaN       NaN
(0.95,1.00]        0        NaN          NaN       NaN       NaN       NaN

test period:20180701-20190101
(166068, 2036) (17810, 2036)

--------------------Train network--------------------

 (166068, 2036) (166068,) {'train_indexes': (0, 55356), 'fit': {'categorical_feature': ['area', 'market', 'exchange', 'is_hs']}}

----------Train layer 0----------
slice(0, 55356, None)

Train custom_revenue_y_s_rise
C:\Users\dell-pc\Anaconda3.6\lib\site-packages\lightgbm\basic.py:1042: UserWarning: categorical_feature in Dataset is overridden. New categorical_feature is ['area', 'exchange', 'is_hs', 'market']
  warnings.warn('categorical_feature in Dataset is overridden. New categorical_feature is {}'.format(sorted(list(categorical_feature))))
[LightGBM] [Warning] Using self-defined objective function
[LightGBM] [Warning] Using self-defined objective function
Time usage: 26.77s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=2, max_depth=8, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=10,
       n_jobs=-1, num_leaves=15,
       objective=<function custom_revenue_obj at 0x000001E7431D5EA0>,
       random_state=0, reg_alpha=0.0, reg_lambda=0.0, silent=True,
       subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
                                     feature  importance_raw  \
1705                                  sh_vol              30
1526         p80mv_(20k_low/p20mv_20k_low-1)              10
1014           p1250mv_lower_shadow/250k_avg              10
1466         p60mv_(20k_low/p20mv_20k_low-1)              10
1238             p300mv_lower_shadow/60k_avg              10
1160     p240mv_(60k_high-60k_close)/60k_avg              10
2025                                  sz_vol              10
234                  (3k_high-3k_low)/3k_avg               8
1009  p1250mv_(250k_low-250k_close)/250k_avg               8
2035                                    vol0               6
173            (250k_avg/p1250mv_250k_avg-1)               4
1471      p60mv_(60k_close-60k_open)/60k_avg               4
1235        p300mv_(60k_low/p60mv_60k_low-1)               4
2034                                     vol               4
895                                hs300_vol               4
567                                      amt               2
372                      (amt/p10mean_amt-1)               2
1472     p60mv_(60k_close/p60mv_60k_close-1)               2
218                   (3k_amt/p6mv_3k_amt-1)               1
543                      (vol/p120max_vol-1)               1

      importance_percent
1705               21.43
1526                7.14
1014                7.14
1466                7.14
1238                7.14
1160                7.14
2025                7.14
234                 5.71
1009                5.71
2035                4.29
173                 2.86
1471                2.86
1235                2.86
2034                2.86
895                 2.86
567                 1.43
372                 1.43
1472                1.43
218                 0.71
543                 0.71
Among 2036 features, 2016 features are not used in the model

Train custom_revenue2_y_l_rise
[LightGBM] [Warning] Using self-defined objective function
[LightGBM] [Warning] Using self-defined objective function
Time usage: 26.49s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=2, max_depth=8, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=10,
       n_jobs=-1, num_leaves=15,
       objective=<function custom_revenue2_obj at 0x000001E7431E10D0>,
       random_state=0, reg_alpha=0.0, reg_lambda=0.0, silent=True,
       subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
                                      feature  importance_raw  \
1705                                   sh_vol              11
2025                                   sz_vol               8
567                                       amt               8
1466          p60mv_(20k_low/p20mv_20k_low-1)               8
1526          p80mv_(20k_low/p20mv_20k_low-1)               7
1235         p300mv_(60k_low/p60mv_60k_low-1)               4
1005  p1250mv_(250k_high-250k_close)/250k_avg               4
1014            p1250mv_lower_shadow/250k_avg               3
1227      p300mv_(60k_close-60k_open)/60k_avg               2
359              (60k_open/p120mv_60k_open-1)               2
1238              p300mv_lower_shadow/60k_avg               2
234                   (3k_high-3k_low)/3k_avg               2
1865                                 sz50_vol               2
1263    p360mv_(120k_low-120k_close)/120k_avg               2
919    p1000mv_(250k_low-250k_close)/250k_avg               2
1160      p240mv_(60k_high-60k_close)/60k_avg               2
357                 (60k_low/p60mv_60k_low-1)               2
1166         p240mv_(60k_low/p60mv_60k_low-1)               2
96                    (120k_open/250k_open-1)               2
936          p100mv_(20k_low/p20mv_20k_low-1)               2

      importance_percent
1705                7.86
2025                5.71
567                 5.71
1466                5.71
1526                5.00
1235                2.86
1005                2.86
1014                2.14
1227                1.43
359                 1.43
1238                1.43
234                 1.43
1865                1.43
1263                1.43
919                 1.43
1160                1.43
357                 1.43
1166                1.43
96                  1.43
936                 1.43
Among 2036 features, 1959 features are not used in the model

Train custom_revenue2_y_l_avg
[LightGBM] [Warning] Using self-defined objective function
[LightGBM] [Warning] Using self-defined objective function
Time usage: 26.99s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=2, max_depth=8, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=10,
       n_jobs=-1, num_leaves=15,
       objective=<function custom_revenue2_obj at 0x000001E7431E10D0>,
       random_state=0, reg_alpha=0.0, reg_lambda=0.0, silent=True,
       subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
                                      feature  importance_raw  \
1705                                   sh_vol              11
2025                                   sz_vol               8
567                                       amt               8
1466          p60mv_(20k_low/p20mv_20k_low-1)               8
1526          p80mv_(20k_low/p20mv_20k_low-1)               7
1235         p300mv_(60k_low/p60mv_60k_low-1)               4
1005  p1250mv_(250k_high-250k_close)/250k_avg               4
1014            p1250mv_lower_shadow/250k_avg               3
1227      p300mv_(60k_close-60k_open)/60k_avg               2
359              (60k_open/p120mv_60k_open-1)               2
1238              p300mv_lower_shadow/60k_avg               2
234                   (3k_high-3k_low)/3k_avg               2
1865                                 sz50_vol               2
1263    p360mv_(120k_low-120k_close)/120k_avg               2
919    p1000mv_(250k_low-250k_close)/250k_avg               2
1160      p240mv_(60k_high-60k_close)/60k_avg               2
357                 (60k_low/p60mv_60k_low-1)               2
1166         p240mv_(60k_low/p60mv_60k_low-1)               2
96                    (120k_open/250k_open-1)               2
936          p100mv_(20k_low/p20mv_20k_low-1)               2

      importance_percent
1705                7.86
2025                5.71
567                 5.71
1466                5.71
1526                5.00
1235                2.86
1005                2.86
1014                2.14
1227                1.43
359                 1.43
1238                1.43
234                 1.43
1865                1.43
1263                1.43
919                 1.43
1160                1.43
357                 1.43
1166                1.43
96                  1.43
936                 1.43
Among 2036 features, 1959 features are not used in the model

Train custom_revenue2_y_s_rise
[LightGBM] [Warning] Using self-defined objective function
[LightGBM] [Warning] Using self-defined objective function
Time usage: 26.99s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=2, max_depth=8, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=10,
       n_jobs=-1, num_leaves=15,
       objective=<function custom_revenue2_obj at 0x000001E7431E10D0>,
       random_state=0, reg_alpha=0.0, reg_lambda=0.0, silent=True,
       subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
                                      feature  importance_raw  \
1705                                   sh_vol              11
2025                                   sz_vol               8
567                                       amt               8
1466          p60mv_(20k_low/p20mv_20k_low-1)               8
1526          p80mv_(20k_low/p20mv_20k_low-1)               7
1235         p300mv_(60k_low/p60mv_60k_low-1)               4
1005  p1250mv_(250k_high-250k_close)/250k_avg               4
1014            p1250mv_lower_shadow/250k_avg               3
1227      p300mv_(60k_close-60k_open)/60k_avg               2
359              (60k_open/p120mv_60k_open-1)               2
1238              p300mv_lower_shadow/60k_avg               2
234                   (3k_high-3k_low)/3k_avg               2
1865                                 sz50_vol               2
1263    p360mv_(120k_low-120k_close)/120k_avg               2
919    p1000mv_(250k_low-250k_close)/250k_avg               2
1160      p240mv_(60k_high-60k_close)/60k_avg               2
357                 (60k_low/p60mv_60k_low-1)               2
1166         p240mv_(60k_low/p60mv_60k_low-1)               2
96                    (120k_open/250k_open-1)               2
936          p100mv_(20k_low/p20mv_20k_low-1)               2

      importance_percent
1705                7.86
2025                5.71
567                 5.71
1466                5.71
1526                5.00
1235                2.86
1005                2.86
1014                2.14
1227                1.43
359                 1.43
1238                1.43
234                 1.43
1865                1.43
1263                1.43
919                 1.43
1160                1.43
357                 1.43
1166                1.43
96                  1.43
936                 1.43
Among 2036 features, 1959 features are not used in the model

Train custom_revenue_y_l_rise
[LightGBM] [Warning] Using self-defined objective function
[LightGBM] [Warning] Using self-defined objective function
Time usage: 26.58s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=2, max_depth=8, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=10,
       n_jobs=-1, num_leaves=15,
       objective=<function custom_revenue_obj at 0x000001E7431D5EA0>,
       random_state=0, reg_alpha=0.0, reg_lambda=0.0, silent=True,
       subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
                                     feature  importance_raw  \
1705                                  sh_vol              30
1526         p80mv_(20k_low/p20mv_20k_low-1)              10
1014           p1250mv_lower_shadow/250k_avg              10
1466         p60mv_(20k_low/p20mv_20k_low-1)              10
1238             p300mv_lower_shadow/60k_avg              10
1160     p240mv_(60k_high-60k_close)/60k_avg              10
2025                                  sz_vol              10
234                  (3k_high-3k_low)/3k_avg               8
1009  p1250mv_(250k_low-250k_close)/250k_avg               8
2035                                    vol0               6
173            (250k_avg/p1250mv_250k_avg-1)               4
1471      p60mv_(60k_close-60k_open)/60k_avg               4
1235        p300mv_(60k_low/p60mv_60k_low-1)               4
2034                                     vol               4
895                                hs300_vol               4
567                                      amt               2
372                      (amt/p10mean_amt-1)               2
1472     p60mv_(60k_close/p60mv_60k_close-1)               2
218                   (3k_amt/p6mv_3k_amt-1)               1
543                      (vol/p120max_vol-1)               1

      importance_percent
1705               21.43
1526                7.14
1014                7.14
1466                7.14
1238                7.14
1160                7.14
2025                7.14
234                 5.71
1009                5.71
2035                4.29
173                 2.86
1471                2.86
1235                2.86
2034                2.86
895                 2.86
567                 1.43
372                 1.43
1472                1.43
218                 0.71
543                 0.71
Among 2036 features, 2016 features are not used in the model

Train custom_revenue2_y_s_decline
[LightGBM] [Warning] Using self-defined objective function
[LightGBM] [Warning] Using self-defined objective function
Time usage: 26.80s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=2, max_depth=8, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=10,
       n_jobs=-1, num_leaves=15,
       objective=<function custom_revenue2_obj at 0x000001E7431E10D0>,
       random_state=0, reg_alpha=0.0, reg_lambda=0.0, silent=True,
       subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
                                      feature  importance_raw  \
1705                                   sh_vol              11
2025                                   sz_vol               8
567                                       amt               8
1466          p60mv_(20k_low/p20mv_20k_low-1)               8
1526          p80mv_(20k_low/p20mv_20k_low-1)               7
1235         p300mv_(60k_low/p60mv_60k_low-1)               4
1005  p1250mv_(250k_high-250k_close)/250k_avg               4
1014            p1250mv_lower_shadow/250k_avg               3
1227      p300mv_(60k_close-60k_open)/60k_avg               2
359              (60k_open/p120mv_60k_open-1)               2
1238              p300mv_lower_shadow/60k_avg               2
234                   (3k_high-3k_low)/3k_avg               2
1865                                 sz50_vol               2
1263    p360mv_(120k_low-120k_close)/120k_avg               2
919    p1000mv_(250k_low-250k_close)/250k_avg               2
1160      p240mv_(60k_high-60k_close)/60k_avg               2
357                 (60k_low/p60mv_60k_low-1)               2
1166         p240mv_(60k_low/p60mv_60k_low-1)               2
96                    (120k_open/250k_open-1)               2
936          p100mv_(20k_low/p20mv_20k_low-1)               2

      importance_percent
1705                7.86
2025                5.71
567                 5.71
1466                5.71
1526                5.00
1235                2.86
1005                2.86
1014                2.14
1227                1.43
359                 1.43
1238                1.43
234                 1.43
1865                1.43
1263                1.43
919                 1.43
1160                1.43
357                 1.43
1166                1.43
96                  1.43
936                 1.43
Among 2036 features, 1959 features are not used in the model

Train custom_revenue_y_s_avg
[LightGBM] [Warning] Using self-defined objective function
[LightGBM] [Warning] Using self-defined objective function
Time usage: 26.68s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=2, max_depth=8, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=10,
       n_jobs=-1, num_leaves=15,
       objective=<function custom_revenue_obj at 0x000001E7431D5EA0>,
       random_state=0, reg_alpha=0.0, reg_lambda=0.0, silent=True,
       subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
                                     feature  importance_raw  \
1705                                  sh_vol              30
1526         p80mv_(20k_low/p20mv_20k_low-1)              10
1014           p1250mv_lower_shadow/250k_avg              10
1466         p60mv_(20k_low/p20mv_20k_low-1)              10
1238             p300mv_lower_shadow/60k_avg              10
1160     p240mv_(60k_high-60k_close)/60k_avg              10
2025                                  sz_vol              10
234                  (3k_high-3k_low)/3k_avg               8
1009  p1250mv_(250k_low-250k_close)/250k_avg               8
2035                                    vol0               6
173            (250k_avg/p1250mv_250k_avg-1)               4
1471      p60mv_(60k_close-60k_open)/60k_avg               4
1235        p300mv_(60k_low/p60mv_60k_low-1)               4
2034                                     vol               4
895                                hs300_vol               4
567                                      amt               2
372                      (amt/p10mean_amt-1)               2
1472     p60mv_(60k_close/p60mv_60k_close-1)               2
218                   (3k_amt/p6mv_3k_amt-1)               1
543                      (vol/p120max_vol-1)               1

      importance_percent
1705               21.43
1526                7.14
1014                7.14
1466                7.14
1238                7.14
1160                7.14
2025                7.14
234                 5.71
1009                5.71
2035                4.29
173                 2.86
1471                2.86
1235                2.86
2034                2.86
895                 2.86
567                 1.43
372                 1.43
1472                1.43
218                 0.71
543                 0.71
Among 2036 features, 2016 features are not used in the model

Train custom_revenue_y_s_decline
[LightGBM] [Warning] Using self-defined objective function
[LightGBM] [Warning] Using self-defined objective function
Time usage: 27.11s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=2, max_depth=8, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=10,
       n_jobs=-1, num_leaves=15,
       objective=<function custom_revenue_obj at 0x000001E7431D5EA0>,
       random_state=0, reg_alpha=0.0, reg_lambda=0.0, silent=True,
       subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
                                     feature  importance_raw  \
1705                                  sh_vol              30
1526         p80mv_(20k_low/p20mv_20k_low-1)              10
1014           p1250mv_lower_shadow/250k_avg              10
1466         p60mv_(20k_low/p20mv_20k_low-1)              10
1238             p300mv_lower_shadow/60k_avg              10
1160     p240mv_(60k_high-60k_close)/60k_avg              10
2025                                  sz_vol              10
234                  (3k_high-3k_low)/3k_avg               8
1009  p1250mv_(250k_low-250k_close)/250k_avg               8
2035                                    vol0               6
173            (250k_avg/p1250mv_250k_avg-1)               4
1471      p60mv_(60k_close-60k_open)/60k_avg               4
1235        p300mv_(60k_low/p60mv_60k_low-1)               4
2034                                     vol               4
895                                hs300_vol               4
567                                      amt               2
372                      (amt/p10mean_amt-1)               2
1472     p60mv_(60k_close/p60mv_60k_close-1)               2
218                   (3k_amt/p6mv_3k_amt-1)               1
543                      (vol/p120max_vol-1)               1

      importance_percent
1705               21.43
1526                7.14
1014                7.14
1466                7.14
1238                7.14
1160                7.14
2025                7.14
234                 5.71
1009                5.71
2035                4.29
173                 2.86
1471                2.86
1235                2.86
2034                2.86
895                 2.86
567                 1.43
372                 1.43
1472                1.43
218                 0.71
543                 0.71
Among 2036 features, 2016 features are not used in the model

Train custom_revenue2_y_s_avg
[LightGBM] [Warning] Using self-defined objective function
[LightGBM] [Warning] Using self-defined objective function
Time usage: 26.85s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=2, max_depth=8, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=10,
       n_jobs=-1, num_leaves=15,
       objective=<function custom_revenue2_obj at 0x000001E7431E10D0>,
       random_state=0, reg_alpha=0.0, reg_lambda=0.0, silent=True,
       subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
                                      feature  importance_raw  \
1705                                   sh_vol              11
2025                                   sz_vol               8
567                                       amt               8
1466          p60mv_(20k_low/p20mv_20k_low-1)               8
1526          p80mv_(20k_low/p20mv_20k_low-1)               7
1235         p300mv_(60k_low/p60mv_60k_low-1)               4
1005  p1250mv_(250k_high-250k_close)/250k_avg               4
1014            p1250mv_lower_shadow/250k_avg               3
1227      p300mv_(60k_close-60k_open)/60k_avg               2
359              (60k_open/p120mv_60k_open-1)               2
1238              p300mv_lower_shadow/60k_avg               2
234                   (3k_high-3k_low)/3k_avg               2
1865                                 sz50_vol               2
1263    p360mv_(120k_low-120k_close)/120k_avg               2
919    p1000mv_(250k_low-250k_close)/250k_avg               2
1160      p240mv_(60k_high-60k_close)/60k_avg               2
357                 (60k_low/p60mv_60k_low-1)               2
1166         p240mv_(60k_low/p60mv_60k_low-1)               2
96                    (120k_open/250k_open-1)               2
936          p100mv_(20k_low/p20mv_20k_low-1)               2

      importance_percent
1705                7.86
2025                5.71
567                 5.71
1466                5.71
1526                5.00
1235                2.86
1005                2.86
1014                2.14
1227                1.43
359                 1.43
1238                1.43
234                 1.43
1865                1.43
1263                1.43
919                 1.43
1160                1.43
357                 1.43
1166                1.43
96                  1.43
936                 1.43
Among 2036 features, 1959 features are not used in the model

Train custom_revenue_y_l_avg
[LightGBM] [Warning] Using self-defined objective function
[LightGBM] [Warning] Using self-defined objective function
Time usage: 25.83s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=2, max_depth=8, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=10,
       n_jobs=-1, num_leaves=15,
       objective=<function custom_revenue_obj at 0x000001E7431D5EA0>,
       random_state=0, reg_alpha=0.0, reg_lambda=0.0, silent=True,
       subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
                                     feature  importance_raw  \
1705                                  sh_vol              30
1526         p80mv_(20k_low/p20mv_20k_low-1)              10
1014           p1250mv_lower_shadow/250k_avg              10
1466         p60mv_(20k_low/p20mv_20k_low-1)              10
1238             p300mv_lower_shadow/60k_avg              10
1160     p240mv_(60k_high-60k_close)/60k_avg              10
2025                                  sz_vol              10
234                  (3k_high-3k_low)/3k_avg               8
1009  p1250mv_(250k_low-250k_close)/250k_avg               8
2035                                    vol0               6
173            (250k_avg/p1250mv_250k_avg-1)               4
1471      p60mv_(60k_close-60k_open)/60k_avg               4
1235        p300mv_(60k_low/p60mv_60k_low-1)               4
2034                                     vol               4
895                                hs300_vol               4
567                                      amt               2
372                      (amt/p10mean_amt-1)               2
1472     p60mv_(60k_close/p60mv_60k_close-1)               2
218                   (3k_amt/p6mv_3k_amt-1)               1
543                      (vol/p120max_vol-1)               1

      importance_percent
1705               21.43
1526                7.14
1014                7.14
1466                7.14
1238                7.14
1160                7.14
2025                7.14
234                 5.71
1009                5.71
2035                4.29
173                 2.86
1471                2.86
1235                2.86
2034                2.86
895                 2.86
567                 1.43
372                 1.43
1472                1.43
218                 0.71
543                 0.71
Among 2036 features, 2016 features are not used in the model

Train custom_revenue2_y_l_decline
[LightGBM] [Warning] Using self-defined objective function
[LightGBM] [Warning] Using self-defined objective function
Time usage: 26.01s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=2, max_depth=8, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=10,
       n_jobs=-1, num_leaves=15,
       objective=<function custom_revenue2_obj at 0x000001E7431E10D0>,
       random_state=0, reg_alpha=0.0, reg_lambda=0.0, silent=True,
       subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
                                      feature  importance_raw  \
1705                                   sh_vol              11
2025                                   sz_vol               8
567                                       amt               8
1466          p60mv_(20k_low/p20mv_20k_low-1)               8
1526          p80mv_(20k_low/p20mv_20k_low-1)               7
1235         p300mv_(60k_low/p60mv_60k_low-1)               4
1005  p1250mv_(250k_high-250k_close)/250k_avg               4
1014            p1250mv_lower_shadow/250k_avg               3
1227      p300mv_(60k_close-60k_open)/60k_avg               2
359              (60k_open/p120mv_60k_open-1)               2
1238              p300mv_lower_shadow/60k_avg               2
234                   (3k_high-3k_low)/3k_avg               2
1865                                 sz50_vol               2
1263    p360mv_(120k_low-120k_close)/120k_avg               2
919    p1000mv_(250k_low-250k_close)/250k_avg               2
1160      p240mv_(60k_high-60k_close)/60k_avg               2
357                 (60k_low/p60mv_60k_low-1)               2
1166         p240mv_(60k_low/p60mv_60k_low-1)               2
96                    (120k_open/250k_open-1)               2
936          p100mv_(20k_low/p20mv_20k_low-1)               2

      importance_percent
1705                7.86
2025                5.71
567                 5.71
1466                5.71
1526                5.00
1235                2.86
1005                2.86
1014                2.14
1227                1.43
359                 1.43
1238                1.43
234                 1.43
1865                1.43
1263                1.43
919                 1.43
1160                1.43
357                 1.43
1166                1.43
96                  1.43
936                 1.43
Among 2036 features, 1959 features are not used in the model

Train custom_revenue_y_l_decline
[LightGBM] [Warning] Using self-defined objective function
[LightGBM] [Warning] Using self-defined objective function
Time usage: 25.43s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=2, max_depth=8, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=10,
       n_jobs=-1, num_leaves=15,
       objective=<function custom_revenue_obj at 0x000001E7431D5EA0>,
       random_state=0, reg_alpha=0.0, reg_lambda=0.0, silent=True,
       subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
                                     feature  importance_raw  \
1705                                  sh_vol              30
1526         p80mv_(20k_low/p20mv_20k_low-1)              10
1014           p1250mv_lower_shadow/250k_avg              10
1466         p60mv_(20k_low/p20mv_20k_low-1)              10
1238             p300mv_lower_shadow/60k_avg              10
1160     p240mv_(60k_high-60k_close)/60k_avg              10
2025                                  sz_vol              10
234                  (3k_high-3k_low)/3k_avg               8
1009  p1250mv_(250k_low-250k_close)/250k_avg               8
2035                                    vol0               6
173            (250k_avg/p1250mv_250k_avg-1)               4
1471      p60mv_(60k_close-60k_open)/60k_avg               4
1235        p300mv_(60k_low/p60mv_60k_low-1)               4
2034                                     vol               4
895                                hs300_vol               4
567                                      amt               2
372                      (amt/p10mean_amt-1)               2
1472     p60mv_(60k_close/p60mv_60k_close-1)               2
218                   (3k_amt/p6mv_3k_amt-1)               1
543                      (vol/p120max_vol-1)               1

      importance_percent
1705               21.43
1526                7.14
1014                7.14
1466                7.14
1238                7.14
1160                7.14
2025                7.14
234                 5.71
1009                5.71
2035                4.29
173                 2.86
1471                2.86
1235                2.86
2034                2.86
895                 2.86
567                 1.43
372                 1.43
1472                1.43
218                 0.71
543                 0.71
Among 2036 features, 2016 features are not used in the model

----------Layer 0 predicts----------

 (166068, 2180) (166068,) {'train_indexes': (55356, 110712), 'fit': {'categorical_feature': ['area', 'market', 'exchange', 'is_hs']}}

----------Train layer 1----------
slice(55356, 110712, None)

Train l2_y_l_rise
[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves
[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves
Time usage: 36.78s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=0.2, max_depth=12, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=25,
       n_jobs=-1, num_leaves=31, objective=None, random_state=0,
       reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,
       subsample_for_bin=200000, subsample_freq=0)
                                         feature  importance_raw  \
1865                                    sz50_vol              47
2025                                      sz_vol              47
567                                          amt              18
1705                                      sh_vol              17
895                                    hs300_vol              17
568                                         area              12
1449       p600mv_(120k_low-120k_close)/120k_avg               9
732                                      cyb_vol               8
1350                p480mv_lower_shadow/120k_avg               8
1347         p480mv_(120k_low/p120mv_120k_low-1)               8
1268                p360mv_lower_shadow/120k_avg               7
1241             p30mv_(10k_avg/p10mv_10k_avg-1)               6
453                             (high-close)/avg               6
1341      p480mv_(120k_high-120k_close)/120k_avg               6
1062            p180mv_(60k_avg/p60mv_60k_avg-1)               5
1247           p30mv_(10k_high/p10mv_10k_high-1)               5
2050  layer0_custom_revenue2_y_l_rise_tree0_leaf               5
986          p120mv_(60k_close-60k_open)/60k_avg               5
1112             p20mv_(20k_avg/p20mv_20k_avg-1)               5
985             p120mv_(60k_avg/p60mv_60k_avg-1)               5

      importance_percent
1865                6.27
2025                6.27
567                 2.40
1705                2.27
895                 2.27
568                 1.60
1449                1.20
732                 1.07
1350                1.07
1347                1.07
1268                0.93
1241                0.80
453                 0.80
1341                0.80
1062                0.67
1247                0.67
2050                0.67
986                 0.67
1112                0.67
985                 0.67
Among 2180 features, 1843 features are not used in the model

Train l2_y_s_avg
[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves
[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves
Time usage: 37.58s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=0.2, max_depth=12, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=25,
       n_jobs=-1, num_leaves=31, objective=None, random_state=0,
       reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,
       subsample_for_bin=200000, subsample_freq=0)
                                         feature  importance_raw  \
1865                                    sz50_vol              47
2025                                      sz_vol              47
567                                          amt              18
1705                                      sh_vol              17
895                                    hs300_vol              17
568                                         area              12
1449       p600mv_(120k_low-120k_close)/120k_avg               9
732                                      cyb_vol               8
1350                p480mv_lower_shadow/120k_avg               8
1347         p480mv_(120k_low/p120mv_120k_low-1)               8
1268                p360mv_lower_shadow/120k_avg               7
1241             p30mv_(10k_avg/p10mv_10k_avg-1)               6
453                             (high-close)/avg               6
1341      p480mv_(120k_high-120k_close)/120k_avg               6
1062            p180mv_(60k_avg/p60mv_60k_avg-1)               5
1247           p30mv_(10k_high/p10mv_10k_high-1)               5
2050  layer0_custom_revenue2_y_l_rise_tree0_leaf               5
986          p120mv_(60k_close-60k_open)/60k_avg               5
1112             p20mv_(20k_avg/p20mv_20k_avg-1)               5
985             p120mv_(60k_avg/p60mv_60k_avg-1)               5

      importance_percent
1865                6.27
2025                6.27
567                 2.40
1705                2.27
895                 2.27
568                 1.60
1449                1.20
732                 1.07
1350                1.07
1347                1.07
1268                0.93
1241                0.80
453                 0.80
1341                0.80
1062                0.67
1247                0.67
2050                0.67
986                 0.67
1112                0.67
985                 0.67
Among 2180 features, 1843 features are not used in the model

Train l2_y_s_rise
[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves
[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves
Time usage: 38.09s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=0.2, max_depth=12, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=25,
       n_jobs=-1, num_leaves=31, objective=None, random_state=0,
       reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,
       subsample_for_bin=200000, subsample_freq=0)
                                         feature  importance_raw  \
1865                                    sz50_vol              47
2025                                      sz_vol              47
567                                          amt              18
1705                                      sh_vol              17
895                                    hs300_vol              17
568                                         area              12
1449       p600mv_(120k_low-120k_close)/120k_avg               9
732                                      cyb_vol               8
1350                p480mv_lower_shadow/120k_avg               8
1347         p480mv_(120k_low/p120mv_120k_low-1)               8
1268                p360mv_lower_shadow/120k_avg               7
1241             p30mv_(10k_avg/p10mv_10k_avg-1)               6
453                             (high-close)/avg               6
1341      p480mv_(120k_high-120k_close)/120k_avg               6
1062            p180mv_(60k_avg/p60mv_60k_avg-1)               5
1247           p30mv_(10k_high/p10mv_10k_high-1)               5
2050  layer0_custom_revenue2_y_l_rise_tree0_leaf               5
986          p120mv_(60k_close-60k_open)/60k_avg               5
1112             p20mv_(20k_avg/p20mv_20k_avg-1)               5
985             p120mv_(60k_avg/p60mv_60k_avg-1)               5

      importance_percent
1865                6.27
2025                6.27
567                 2.40
1705                2.27
895                 2.27
568                 1.60
1449                1.20
732                 1.07
1350                1.07
1347                1.07
1268                0.93
1241                0.80
453                 0.80
1341                0.80
1062                0.67
1247                0.67
2050                0.67
986                 0.67
1112                0.67
985                 0.67
Among 2180 features, 1843 features are not used in the model

Train l2_y_l_decline
[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves
[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves
Time usage: 38.26s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=0.2, max_depth=12, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=25,
       n_jobs=-1, num_leaves=31, objective=None, random_state=0,
       reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,
       subsample_for_bin=200000, subsample_freq=0)
                                         feature  importance_raw  \
1865                                    sz50_vol              47
2025                                      sz_vol              47
567                                          amt              18
1705                                      sh_vol              17
895                                    hs300_vol              17
568                                         area              12
1449       p600mv_(120k_low-120k_close)/120k_avg               9
732                                      cyb_vol               8
1350                p480mv_lower_shadow/120k_avg               8
1347         p480mv_(120k_low/p120mv_120k_low-1)               8
1268                p360mv_lower_shadow/120k_avg               7
1241             p30mv_(10k_avg/p10mv_10k_avg-1)               6
453                             (high-close)/avg               6
1341      p480mv_(120k_high-120k_close)/120k_avg               6
1062            p180mv_(60k_avg/p60mv_60k_avg-1)               5
1247           p30mv_(10k_high/p10mv_10k_high-1)               5
2050  layer0_custom_revenue2_y_l_rise_tree0_leaf               5
986          p120mv_(60k_close-60k_open)/60k_avg               5
1112             p20mv_(20k_avg/p20mv_20k_avg-1)               5
985             p120mv_(60k_avg/p60mv_60k_avg-1)               5

      importance_percent
1865                6.27
2025                6.27
567                 2.40
1705                2.27
895                 2.27
568                 1.60
1449                1.20
732                 1.07
1350                1.07
1347                1.07
1268                0.93
1241                0.80
453                 0.80
1341                0.80
1062                0.67
1247                0.67
2050                0.67
986                 0.67
1112                0.67
985                 0.67
Among 2180 features, 1843 features are not used in the model

Train l2_y_l_avg
[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves
[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves
Time usage: 38.17s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=0.2, max_depth=12, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=25,
       n_jobs=-1, num_leaves=31, objective=None, random_state=0,
       reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,
       subsample_for_bin=200000, subsample_freq=0)
                                         feature  importance_raw  \
1865                                    sz50_vol              47
2025                                      sz_vol              47
567                                          amt              18
1705                                      sh_vol              17
895                                    hs300_vol              17
568                                         area              12
1449       p600mv_(120k_low-120k_close)/120k_avg               9
732                                      cyb_vol               8
1350                p480mv_lower_shadow/120k_avg               8
1347         p480mv_(120k_low/p120mv_120k_low-1)               8
1268                p360mv_lower_shadow/120k_avg               7
1241             p30mv_(10k_avg/p10mv_10k_avg-1)               6
453                             (high-close)/avg               6
1341      p480mv_(120k_high-120k_close)/120k_avg               6
1062            p180mv_(60k_avg/p60mv_60k_avg-1)               5
1247           p30mv_(10k_high/p10mv_10k_high-1)               5
2050  layer0_custom_revenue2_y_l_rise_tree0_leaf               5
986          p120mv_(60k_close-60k_open)/60k_avg               5
1112             p20mv_(20k_avg/p20mv_20k_avg-1)               5
985             p120mv_(60k_avg/p60mv_60k_avg-1)               5

      importance_percent
1865                6.27
2025                6.27
567                 2.40
1705                2.27
895                 2.27
568                 1.60
1449                1.20
732                 1.07
1350                1.07
1347                1.07
1268                0.93
1241                0.80
453                 0.80
1341                0.80
1062                0.67
1247                0.67
2050                0.67
986                 0.67
1112                0.67
985                 0.67
Among 2180 features, 1843 features are not used in the model

Train l2_y_s_decline
[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves
[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves
Time usage: 38.01s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=0.2, max_depth=12, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=25,
       n_jobs=-1, num_leaves=31, objective=None, random_state=0,
       reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,
       subsample_for_bin=200000, subsample_freq=0)
                                         feature  importance_raw  \
1865                                    sz50_vol              47
2025                                      sz_vol              47
567                                          amt              18
1705                                      sh_vol              17
895                                    hs300_vol              17
568                                         area              12
1449       p600mv_(120k_low-120k_close)/120k_avg               9
732                                      cyb_vol               8
1350                p480mv_lower_shadow/120k_avg               8
1347         p480mv_(120k_low/p120mv_120k_low-1)               8
1268                p360mv_lower_shadow/120k_avg               7
1241             p30mv_(10k_avg/p10mv_10k_avg-1)               6
453                             (high-close)/avg               6
1341      p480mv_(120k_high-120k_close)/120k_avg               6
1062            p180mv_(60k_avg/p60mv_60k_avg-1)               5
1247           p30mv_(10k_high/p10mv_10k_high-1)               5
2050  layer0_custom_revenue2_y_l_rise_tree0_leaf               5
986          p120mv_(60k_close-60k_open)/60k_avg               5
1112             p20mv_(20k_avg/p20mv_20k_avg-1)               5
985             p120mv_(60k_avg/p60mv_60k_avg-1)               5

      importance_percent
1865                6.27
2025                6.27
567                 2.40
1705                2.27
895                 2.27
568                 1.60
1449                1.20
732                 1.07
1350                1.07
1347                1.07
1268                0.93
1241                0.80
453                 0.80
1341                0.80
1062                0.67
1247                0.67
2050                0.67
986                 0.67
1112                0.67
985                 0.67
Among 2180 features, 1843 features are not used in the model

----------Layer 1 predicts----------

 (166068, 2336) (166068,) {'train_indexes': (110712, None), 'fit': {'categorical_feature': ['area', 'market', 'exchange', 'is_hs']}}

----------Train layer 2----------
slice(110712, None, None)

Train l2_y_l_r
[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves
[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves
Time usage: 52.32s
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=0.1, max_depth=12, min_child_samples=30,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=50,
       n_jobs=-1, num_leaves=31, objective=None, random_state=0,
       reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,
       subsample_for_bin=200000, subsample_freq=0)
                                    feature  importance_raw  \
568                                    area              81
895                               hs300_vol              53
1705                                 sh_vol              48
1865                               sz50_vol              44
2025                                 sz_vol              39
1466        p60mv_(20k_low/p20mv_20k_low-1)              19
732                                 cyb_vol              17
994        p120mv_(60k_low/p60mv_60k_low-1)              15
1351           p480mv_upper_shadow/120k_avg              15
1236     p300mv_(60k_open/p60mv_60k_open-1)              13
1450   p600mv_(120k_low-120k_open)/120k_avg              12
1074            p180mv_lower_shadow/60k_avg              11
1509  p750mv_(250k_low-250k_close)/250k_avg              10
1157       p240mv_(60k_avg/p60mv_60k_avg-1)              10
1256    p360mv_(120k_avg/p120mv_120k_avg-1)               9
1399        p50mv_(10k_low/p10mv_10k_low-1)               9
1226       p300mv_(60k_avg/p60mv_60k_avg-1)               9
492                        (low/p1mv_low-1)               9
1166       p240mv_(60k_low/p60mv_60k_low-1)               9
567                                     amt               9

      importance_percent
568                 5.40
895                 3.53
1705                3.20
1865                2.93
2025                2.60
1466                1.27
732                 1.13
994                 1.00
1351                1.00
1236                0.87
1450                0.80
1074                0.73
1509                0.67
1157                0.67
1256                0.60
1399                0.60
1226                0.60
492                 0.60
1166                0.60
567                 0.60
Among 2336 features, 1767 features are not used in the model

--------------------Predict--------------------

----------Layer 0 predicts----------

----------Layer 1 predicts----------

----------Layer 2 predicts----------

y_l_r
               count  eval_mean  eval_median  eval_std  eval_max  eval_min
pred_range
(-1.00,-0.95]      0        NaN          NaN       NaN       NaN       NaN
(-0.95,-0.90]      0        NaN          NaN       NaN       NaN       NaN
(-0.90,-0.85]      0        NaN          NaN       NaN       NaN       NaN
(-0.85,-0.80]      0        NaN          NaN       NaN       NaN       NaN
(-0.80,-0.75]      0        NaN          NaN       NaN       NaN       NaN
(-0.75,-0.70]      0        NaN          NaN       NaN       NaN       NaN
(-0.70,-0.65]      0        NaN          NaN       NaN       NaN       NaN
(-0.65,-0.60]      0        NaN          NaN       NaN       NaN       NaN
(-0.60,-0.55]      0        NaN          NaN       NaN       NaN       NaN
(-0.55,-0.50]      0        NaN          NaN       NaN       NaN       NaN
(-0.50,-0.45]      0        NaN          NaN       NaN       NaN       NaN
(-0.45,-0.40]      0        NaN          NaN       NaN       NaN       NaN
(-0.40,-0.35]      0        NaN          NaN       NaN       NaN       NaN
(-0.35,-0.30]      0        NaN          NaN       NaN       NaN       NaN
(-0.30,-0.25]      0        NaN          NaN       NaN       NaN       NaN
(-0.25,-0.20]      0        NaN          NaN       NaN       NaN       NaN
(-0.20,-0.15]      3      0.100        0.074     0.272     0.384    -0.157
(-0.15,-0.10]     15     -0.053       -0.134     0.162     0.303    -0.205
(-0.10,-0.05]    466     -0.040       -0.075     0.136     0.650    -0.419
(-0.05,0.00]    6990     -0.026       -0.057     0.125     0.924    -0.635
(0.00,0.05]     8481     -0.010       -0.042     0.129     0.869    -0.584
(0.05,0.10]     1577      0.032        0.066     0.155     0.651    -0.417
(0.10,0.15]      247      0.090        0.129     0.181     0.531    -0.288
(0.15,0.20]       26      0.077        0.041     0.223     0.585    -0.231
(0.20,0.25]        4      0.087        0.122     0.151     0.229    -0.126
(0.25,0.30]        1      0.498        0.498       NaN     0.498     0.498
(0.30,0.35]        0        NaN          NaN       NaN       NaN       NaN
(0.35,0.40]        0        NaN          NaN       NaN       NaN       NaN
(0.40,0.45]        0        NaN          NaN       NaN       NaN       NaN
(0.45,0.50]        0        NaN          NaN       NaN       NaN       NaN
(0.50,0.55]        0        NaN          NaN       NaN       NaN       NaN
(0.55,0.60]        0        NaN          NaN       NaN       NaN       NaN
(0.60,0.65]        0        NaN          NaN       NaN       NaN       NaN
(0.65,0.70]        0        NaN          NaN       NaN       NaN       NaN
(0.70,0.75]        0        NaN          NaN       NaN       NaN       NaN
(0.75,0.80]        0        NaN          NaN       NaN       NaN       NaN
(0.80,0.85]        0        NaN          NaN       NaN       NaN       NaN
(0.85,0.90]        0        NaN          NaN       NaN       NaN       NaN
(0.90,0.95]        0        NaN          NaN       NaN       NaN       NaN
(0.95,1.00]        0        NaN          NaN       NaN       NaN       NaN

y_l
               count  eval_mean  eval_median  eval_std  eval_max  eval_min
pred_range
(-1.00,-0.95]      0        NaN          NaN       NaN       NaN       NaN
(-0.95,-0.90]      0        NaN          NaN       NaN       NaN       NaN
(-0.90,-0.85]      0        NaN          NaN       NaN       NaN       NaN
(-0.85,-0.80]      0        NaN          NaN       NaN       NaN       NaN
(-0.80,-0.75]      0        NaN          NaN       NaN       NaN       NaN
(-0.75,-0.70]      0        NaN          NaN       NaN       NaN       NaN
(-0.70,-0.65]      0        NaN          NaN       NaN       NaN       NaN
(-0.65,-0.60]      0        NaN          NaN       NaN       NaN       NaN
(-0.60,-0.55]      0        NaN          NaN       NaN       NaN       NaN
(-0.55,-0.50]      0        NaN          NaN       NaN       NaN       NaN
(-0.50,-0.45]      0        NaN          NaN       NaN       NaN       NaN
(-0.45,-0.40]      0        NaN          NaN       NaN       NaN       NaN
(-0.40,-0.35]      0        NaN          NaN       NaN       NaN       NaN
(-0.35,-0.30]      0        NaN          NaN       NaN       NaN       NaN
(-0.30,-0.25]      0        NaN          NaN       NaN       NaN       NaN
(-0.25,-0.20]      0        NaN          NaN       NaN       NaN       NaN
(-0.20,-0.15]      3      0.111        0.087     0.316     0.438    -0.194
(-0.15,-0.10]     15     -0.067       -0.160     0.190     0.342    -0.240
(-0.10,-0.05]    466     -0.055       -0.096     0.156     0.765    -0.466
(-0.05,0.00]    6990     -0.036       -0.076     0.145     1.012    -0.659
(0.00,0.05]     8481     -0.018       -0.062     0.151     0.953    -0.639
(0.05,0.10]     1577      0.030        0.071     0.183     0.733    -0.467
(0.10,0.15]      247      0.103        0.152     0.213     0.614    -0.320
(0.15,0.20]       26      0.096        0.100     0.264     0.695    -0.259
(0.20,0.25]        4      0.103        0.149     0.181     0.267    -0.153
(0.25,0.30]        1      0.602        0.602       NaN     0.602     0.602
(0.30,0.35]        0        NaN          NaN       NaN       NaN       NaN
(0.35,0.40]        0        NaN          NaN       NaN       NaN       NaN
(0.40,0.45]        0        NaN          NaN       NaN       NaN       NaN
(0.45,0.50]        0        NaN          NaN       NaN       NaN       NaN
(0.50,0.55]        0        NaN          NaN       NaN       NaN       NaN
(0.55,0.60]        0        NaN          NaN       NaN       NaN       NaN
(0.60,0.65]        0        NaN          NaN       NaN       NaN       NaN
(0.65,0.70]        0        NaN          NaN       NaN       NaN       NaN
(0.70,0.75]        0        NaN          NaN       NaN       NaN       NaN
(0.75,0.80]        0        NaN          NaN       NaN       NaN       NaN
(0.80,0.85]        0        NaN          NaN       NaN       NaN       NaN
(0.85,0.90]        0        NaN          NaN       NaN       NaN       NaN
(0.90,0.95]        0        NaN          NaN       NaN       NaN       NaN
(0.95,1.00]        0        NaN          NaN       NaN       NaN       NaN

y_l_avg
               count  eval_mean  eval_median  eval_std  eval_max  eval_min
pred_range
(-1.00,-0.95]      0        NaN          NaN       NaN       NaN       NaN
(-0.95,-0.90]      0        NaN          NaN       NaN       NaN       NaN
(-0.90,-0.85]      0        NaN          NaN       NaN       NaN       NaN
(-0.85,-0.80]      0        NaN          NaN       NaN       NaN       NaN
(-0.80,-0.75]      0        NaN          NaN       NaN       NaN       NaN
(-0.75,-0.70]      0        NaN          NaN       NaN       NaN       NaN
(-0.70,-0.65]      0        NaN          NaN       NaN       NaN       NaN
(-0.65,-0.60]      0        NaN          NaN       NaN       NaN       NaN
(-0.60,-0.55]      0        NaN          NaN       NaN       NaN       NaN
(-0.55,-0.50]      0        NaN          NaN       NaN       NaN       NaN
(-0.50,-0.45]      0        NaN          NaN       NaN       NaN       NaN
(-0.45,-0.40]      0        NaN          NaN       NaN       NaN       NaN
(-0.40,-0.35]      0        NaN          NaN       NaN       NaN       NaN
(-0.35,-0.30]      0        NaN          NaN       NaN       NaN       NaN
(-0.30,-0.25]      0        NaN          NaN       NaN       NaN       NaN
(-0.25,-0.20]      0        NaN          NaN       NaN       NaN       NaN
(-0.20,-0.15]      3      0.069        0.033     0.139     0.223    -0.047
(-0.15,-0.10]     15     -0.012       -0.042     0.078     0.187    -0.099
(-0.10,-0.05]    466     -0.020       -0.021     0.072     0.305    -0.278
(-0.05,0.00]    6990     -0.012       -0.011     0.066     0.660    -0.564
(0.00,0.05]     8481     -0.003       -0.005     0.067     0.617    -0.418
(0.05,0.10]     1577      0.019        0.012     0.079     0.405    -0.266
(0.10,0.15]      247      0.049        0.053     0.093     0.365    -0.211
(0.15,0.20]       26      0.040        0.007     0.098     0.260    -0.149
(0.20,0.25]        4      0.038        0.039     0.066     0.117    -0.044
(0.25,0.30]        1      0.186        0.186       NaN     0.186     0.186
(0.30,0.35]        0        NaN          NaN       NaN       NaN       NaN
(0.35,0.40]        0        NaN          NaN       NaN       NaN       NaN
(0.40,0.45]        0        NaN          NaN       NaN       NaN       NaN
(0.45,0.50]        0        NaN          NaN       NaN       NaN       NaN
(0.50,0.55]        0        NaN          NaN       NaN       NaN       NaN
(0.55,0.60]        0        NaN          NaN       NaN       NaN       NaN
(0.60,0.65]        0        NaN          NaN       NaN       NaN       NaN
(0.65,0.70]        0        NaN          NaN       NaN       NaN       NaN
(0.70,0.75]        0        NaN          NaN       NaN       NaN       NaN
(0.75,0.80]        0        NaN          NaN       NaN       NaN       NaN
(0.80,0.85]        0        NaN          NaN       NaN       NaN       NaN
(0.85,0.90]        0        NaN          NaN       NaN       NaN       NaN
(0.90,0.95]        0        NaN          NaN       NaN       NaN       NaN
(0.95,1.00]        0        NaN          NaN       NaN       NaN       NaN

y_l_rise
               count  eval_mean  eval_median  eval_std  eval_max  eval_min
pred_range
(-1.00,-0.95]      0        NaN          NaN       NaN       NaN       NaN
(-0.95,-0.90]      0        NaN          NaN       NaN       NaN       NaN
(-0.90,-0.85]      0        NaN          NaN       NaN       NaN       NaN
(-0.85,-0.80]      0        NaN          NaN       NaN       NaN       NaN
(-0.80,-0.75]      0        NaN          NaN       NaN       NaN       NaN
(-0.75,-0.70]      0        NaN          NaN       NaN       NaN       NaN
(-0.70,-0.65]      0        NaN          NaN       NaN       NaN       NaN
(-0.65,-0.60]      0        NaN          NaN       NaN       NaN       NaN
(-0.60,-0.55]      0        NaN          NaN       NaN       NaN       NaN
(-0.55,-0.50]      0        NaN          NaN       NaN       NaN       NaN
(-0.50,-0.45]      0        NaN          NaN       NaN       NaN       NaN
(-0.45,-0.40]      0        NaN          NaN       NaN       NaN       NaN
(-0.40,-0.35]      0        NaN          NaN       NaN       NaN       NaN
(-0.35,-0.30]      0        NaN          NaN       NaN       NaN       NaN
(-0.30,-0.25]      0        NaN          NaN       NaN       NaN       NaN
(-0.25,-0.20]      0        NaN          NaN       NaN       NaN       NaN
(-0.20,-0.15]      3      0.196        0.087     0.210     0.438     0.063
(-0.15,-0.10]     15      0.093        0.060     0.093     0.342     0.015
(-0.10,-0.05]    466      0.071        0.049     0.077     0.765     0.000
(-0.05,0.00]    6990      0.067        0.048     0.071     1.012     0.000
(0.00,0.05]     8481      0.077        0.055     0.078     0.953     0.000
(0.05,0.10]     1577      0.119        0.095     0.101     0.733     0.000
(0.10,0.15]      247      0.172        0.152     0.129     0.614     0.000
(0.15,0.20]       26      0.180        0.102     0.190     0.695     0.000
(0.20,0.25]        4      0.151        0.149     0.096     0.267     0.037
(0.25,0.30]        1      0.602        0.602       NaN     0.602     0.602
(0.30,0.35]        0        NaN          NaN       NaN       NaN       NaN
(0.35,0.40]        0        NaN          NaN       NaN       NaN       NaN
(0.40,0.45]        0        NaN          NaN       NaN       NaN       NaN
(0.45,0.50]        0        NaN          NaN       NaN       NaN       NaN
(0.50,0.55]        0        NaN          NaN       NaN       NaN       NaN
(0.55,0.60]        0        NaN          NaN       NaN       NaN       NaN
(0.60,0.65]        0        NaN          NaN       NaN       NaN       NaN
(0.65,0.70]        0        NaN          NaN       NaN       NaN       NaN
(0.70,0.75]        0        NaN          NaN       NaN       NaN       NaN
(0.75,0.80]        0        NaN          NaN       NaN       NaN       NaN
(0.80,0.85]        0        NaN          NaN       NaN       NaN       NaN
(0.85,0.90]        0        NaN          NaN       NaN       NaN       NaN
(0.90,0.95]        0        NaN          NaN       NaN       NaN       NaN
(0.95,1.00]        0        NaN          NaN       NaN       NaN       NaN
