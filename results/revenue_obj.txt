Rule revenue: 5385.712396324944
499 183 9501 (10000,)
y3==0: 499
(7000, 10) (3000, 10)

LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=0.1, max_depth=6, min_child_samples=5,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=30,
       n_jobs=-1, num_leaves=16,
       objective=<function custom_obj at 0x0000000000592EA0>,
       random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,
       subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
-140.28192065051115
-2552.674758692763

LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=0.1, max_depth=8, min_child_samples=10,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=30,
       n_jobs=-1, num_leaves=30,
       objective=<function custom_obj at 0x0000000001E62EA0>,
       random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,
       subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
-143.1212182525778
-2552.674758692763

LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=0.1, max_depth=6, min_child_samples=5,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=50,
       n_jobs=-1, num_leaves=16,
       objective=<function custom_obj at 0x0000000001D52EA0>,
       random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,
       subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
311.334550710021
-2552.674758692763


LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=0.1, max_depth=6, min_child_samples=5,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=75,
       n_jobs=-1, num_leaves=16,
       objective=<function custom_obj at 0x0000000001D72EA0>,
       random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,
       subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
580.9501451747273
-2552.674758692763

LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
learning_rate=0.1, max_depth=6, min_child_samples=5,
min_child_weight=0.001, min_split_gain=0.0, n_estimators=100,
n_jobs=-1, num_leaves=16,
objective=<function custom_obj at 0x0000000001E92EA0>,
random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,
subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
702.0856568018665
-2552.674758692763






LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=0.1, max_depth=6, min_child_samples=5,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=200,
       n_jobs=-1, num_leaves=16,
       objective=<function custom_obj at 0x0000000000422EA0>,
       random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,
       subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
902.1305501472744
-2552.674758692763




LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=0.1, max_depth=6, min_child_samples=5,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=300,
       n_jobs=-1, num_leaves=16,
       objective=<function custom_obj at 0x0000000001F12EA0>,
       random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,
       subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
967.8555145783843
-2552.674758692763

LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=0.1, max_depth=6, min_child_samples=5,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=450,
       n_jobs=-1, num_leaves=16,
       objective=<function custom_obj at 0x0000000001E52EA0>,
       random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,
       subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
1011.3295835822589
-2552.674758692763


LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=0.1, max_depth=6, min_child_samples=5,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=500,
       n_jobs=-1, num_leaves=16,
       objective=<function custom_obj at 0x0000000001E42EA0>,
       random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,
       subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
1016.5356850249676 1209.8496655915262 0.9
1016.5356850249676 1265.8186316290273 0.8
1016.5356850249676 1272.7203407793818 0.7
1016.5356850249676 1230.866987623925 0.6
-2552.674758692763


LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=0.1, max_depth=6, min_child_samples=5,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=600,
       n_jobs=-1, num_leaves=16,
       objective=<function custom_obj at 0x0000000001F92EA0>,
       random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,
       subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
1014.8969344745196
-2552.674758692763




---------------------
C:\Users\dell-pc\Anaconda3.6\python.exe C:/Users/dell-pc/Quant/Quant/revenue_obj.py
(10000, 10)
[[ 1.76405235  0.40015721  0.97873798  2.2408932   1.86755799 -0.97727788
   0.95008842 -0.15135721 -0.10321885  0.4105985 ]
 [ 0.14404357  1.45427351  0.76103773  0.12167502  0.44386323  0.33367433
   1.49407907 -0.20515826  0.3130677  -0.85409574]
 [-2.55298982  0.6536186   0.8644362  -0.74216502  2.26975462 -1.45436567
   0.04575852 -0.18718385  1.53277921  1.46935877]
 [ 0.15494743  0.37816252 -0.88778575 -1.98079647 -0.34791215  0.15634897
   1.23029068  1.20237985 -0.38732682 -0.30230275]
 [-1.04855297 -1.42001794 -1.70627019  1.9507754  -0.50965218 -0.4380743
  -1.25279536  0.77749036 -1.61389785 -0.21274028]]
Rule revenue: -8392.924793001948
1432 360 8568 (10000,)
y3==0: 1432
(7000, 10) (3000, 10)
feature count: 1432 456
[LightGBM] [Warning] Using self-defined objective function
[LightGBM] [Warning] Using self-defined objective function
       buy_pct   increase  return_rate    revenue
4     0.937967  14.782008    10.347406   9.705522
31    0.923589  -5.990789    -4.193552  -3.873118
41    0.811378   7.074863     4.952404   4.018273
73    0.994787   1.992074     1.394452   1.387182
131   0.966873  22.093349    15.465344  14.953020
135   0.855269 -14.681655   -10.000000  -8.552686
179   0.913368  42.980688    30.086482  27.480020
192   0.830116 -26.049365   -10.000000  -8.301158
196   0.991858  47.076710    32.953697  32.685377
199   0.800232 -17.562898   -10.000000  -8.002322
200   0.981007  49.711627    34.798139  34.137228
208   0.808637  -8.698646    -6.089052  -4.923835
212   0.852444 -52.641510   -10.000000  -8.524437
256   0.991260  38.228827    26.760179  26.526308
298   0.808105  51.267572    35.887301  29.000713
300   0.879045 -14.037900   -10.000000  -8.790448
370   0.996879  21.084548    14.759184  14.713116
387   0.999396   5.801688     4.061181   4.058728
427   0.962344  35.084123    24.558886  23.634108
476   0.906628   0.696915     0.487840   0.442290
478   0.894806  11.020810     7.714567   6.903043
484   0.825187 -14.981137   -10.000000  -8.251868
527   0.933112 -38.648264   -10.000000  -9.331118
542   0.931981  48.445089    33.911562  31.604935
554   0.996919  -8.643894    -6.050726  -6.032086
559   0.841913  49.789140    34.852398  29.342702
636   0.926234  17.591731    12.314212  11.405840
654   0.979161  -9.777652    -6.844356  -6.701725
685   0.952190  -7.366646    -5.156652  -4.910112
701   0.939655   9.808911     6.866238   6.451892
...        ...        ...          ...        ...
2197  0.922729 -21.115423   -10.000000  -9.227290
2218  0.925385  49.830555    34.881388  32.278706
2374  0.971237  35.380514    24.766360  24.054012
2381  0.982277   3.491938     2.444356   2.401035
2417  0.927823  34.797564    24.358295  22.600176
2421  0.939972 -19.591120   -10.000000  -9.399716
2438  0.999287  19.489360    13.642552  13.632827
2450  0.944734  28.523049    19.966134  18.862693
2461  0.968164   4.134602     2.894221   2.802082
2508  0.937342  -8.658351    -6.060846  -5.681086
2533  0.995104 -20.954278   -10.000000  -9.951042
2537  0.997719   6.182822     4.327976   4.318105
2541  0.895428 -39.806144   -10.000000  -8.954283
2552  0.834051 -12.224113   -10.000000  -8.340510
2597  0.933592 -19.334523   -10.000000  -9.335919
2627  0.973952  13.355894     9.349126   9.105596
2718  0.996987  12.161572     8.513101   8.487453
2759  0.874999   6.892580     4.824806   4.221701
2774  0.889081  42.076670    29.453669  26.186686
2796  0.962324  44.072935    30.851055  29.688715
2822  0.842227 -24.767338   -10.000000  -8.422271
2827  0.924990  10.435504     7.304853   6.756918
2852  0.986116  57.531824    40.272277  39.713117
2858  0.993498  43.431151    30.401806  30.204139
2861  0.831907 -14.378469   -10.000000  -8.319069
2863  0.825735  17.302056    12.111440  10.000835
2875  0.876912   2.881269     2.016889   1.768635
2936  0.843206  44.885836    31.420085  26.493604
2938  0.902837 -19.793058   -10.000000  -9.028371
2960  0.981793  31.812601    22.268821  21.863368

[118 rows x 4 columns]
LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
       learning_rate=0.1, max_depth=6, min_child_samples=5,
       min_child_weight=0.001, min_split_gain=0.0, n_estimators=700,
       n_jobs=-1, num_leaves=16,
       objective=<function custom_obj at 0x000001AAFFD49048>,
       random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,
       subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
1048.8280831313152 -2808.5203625271174
>0.1: 1111.5847675438504 435
>0.2: 1111.5414711281414 359
>0.30000000000000004: 1159.25489508374 302
>0.4: 1142.4644368853756 264
>0.5: 1090.7203380669291 230
>0.6000000000000001: 1030.2599809181627 197
>0.7000000000000001: 956.8711363461175 152
>0.8: 906.9795434368016 118
>0.9: 771.7289309651412 77
>0:
       increase       pred  return_rate
5      5.530221   0.178154     3.871155
12   -28.932751   7.062110   -10.000000
16    16.449748   4.721567    11.514824
31    -5.990789  11.095120    -4.193552
34   -38.764751   2.432311   -10.000000
41     7.074863  12.877637     4.952404
44    -6.216746   2.410070    -4.351722
52    31.929922   8.145415    22.350945
73     1.992074  31.507381     1.394452
93     9.745800   6.521210     6.822060
98   -12.035105   0.090606   -10.000000
111  -23.070447   3.467274   -10.000000
113  -10.611368   0.085103   -10.000000
133  -27.326725   0.464153   -10.000000
138   -4.969251   0.952358    -3.478476
160    1.951120   2.211587     1.365784
168  -12.593262  15.426041   -10.000000
173  -34.929315   4.987709   -10.000000
177  -28.169573   0.611433   -10.000000
179   42.980688  17.313796    30.086482
192  -26.049365  11.522532   -10.000000
196   47.076710  14.301103    32.953697
199  -17.562898   5.514897   -10.000000
200   49.711627  32.335452    34.798139
208   -8.698646   7.153306    -6.089052
212  -52.641510   1.415168   -10.000000
252   -6.719806   1.583536    -4.703864
253   11.460152   0.284318     8.022106
256   38.228827  17.600026    26.760179
261   -8.669413   1.502228    -6.068589
...         ...        ...          ...
2630 -20.891903   6.391151   -10.000000
2632   3.015467   4.636390     2.110827
2633  31.688661   4.721608    22.182063
2666  -8.971297   1.419262    -6.279908
2668  12.701423   1.635012     8.890996
2693  -8.183745   0.950283    -5.728622
2697 -27.471879   4.724741   -10.000000
2718  12.161572  22.008932     8.513101
2736   9.816621   0.926637     6.871635
2759   6.892580   7.864794     4.824806
2768   2.422058   1.946801     1.695440
2774  42.076670   3.614705    29.453669
2776 -21.352749   5.731828   -10.000000
2783  13.298907   0.313471     9.309235
2796  44.072935  23.590988    30.851055
2798 -43.008417  11.084641   -10.000000
2822 -24.767338   1.080337   -10.000000
2852  57.531824  22.742201    40.272277
2856  -1.149119   0.209055    -0.804383
2858  43.431151  24.357442    30.401806
2866   2.331464   3.197074     1.632025
2889  -9.403431   1.951762    -6.582402
2927   4.636287  10.319932     3.245401
2933 -15.636971   4.966637   -10.000000
2936  44.885836   8.418599    31.420085
2938 -19.793058   7.622127   -10.000000
2959 -16.893532   2.007107   -10.000000
2960  31.812601   8.716542    22.268821
2966 -12.492629   1.006926   -10.000000
2967  -4.031431   1.276512    -2.822002

[294 rows x 3 columns]
696.3208223903137

>5:
       increase       pred  return_rate
12   -28.932751   7.062110   -10.000000
31    -5.990789  11.095120    -4.193552
41     7.074863  12.877637     4.952404
52    31.929922   8.145415    22.350945
73     1.992074  31.507381     1.394452
93     9.745800   6.521210     6.822060
168  -12.593262  15.426041   -10.000000
179   42.980688  17.313796    30.086482
192  -26.049365  11.522532   -10.000000
196   47.076710  14.301103    32.953697
199  -17.562898   5.514897   -10.000000
200   49.711627  32.335452    34.798139
208   -8.698646   7.153306    -6.089052
256   38.228827  17.600026    26.760179
294   -3.183297   5.365423    -2.228308
298   51.267572   6.273553    35.887301
305   -5.727261  14.376343    -4.009082
327    7.030691  10.331937     4.921484
330    7.696680   5.584155     5.387676
370   21.084548  16.891754    14.759184
387    5.801688   5.440840     4.061181
397  -40.207571   6.916251   -10.000000
402  -20.873834   5.899362   -10.000000
411   18.318790  17.224486    12.823153
427   35.084123  14.107746    24.558886
441   11.276050   7.202296     7.893235
476    0.696915   6.258436     0.487840
478   11.020810  16.614978     7.714567
479  -18.934956   6.434601   -10.000000
497    2.271609   5.969301     1.590127
...         ...        ...          ...
1938   3.221380   5.526321     2.254966
1939  18.701878  20.745939    13.091314
2036  40.305475   5.091927    28.213833
2046  10.329514  11.106235     7.230660
2092  18.459843   7.288314    12.921890
2211  19.972048   7.609428    13.980434
2218  49.830555  10.333023    34.881388
2243   1.544570  11.949490     1.081199
2374  35.380514  15.432804    24.766360
2381   3.491938   9.597455     2.444356
2417  34.797564  19.161930    24.358295
2438  19.489360  24.261394    13.642552
2450  28.523049  19.382831    19.966134
2507  -2.621341   5.480916    -1.834939
2508  -8.658351   9.012614    -6.060846
2537   6.182822  13.544859     4.327976
2552 -12.224113   5.678776   -10.000000
2627  13.355894  10.182277     9.349126
2630 -20.891903   6.391151   -10.000000
2718  12.161572  22.008932     8.513101
2759   6.892580   7.864794     4.824806
2776 -21.352749   5.731828   -10.000000
2796  44.072935  23.590988    30.851055
2798 -43.008417  11.084641   -10.000000
2852  57.531824  22.742201    40.272277
2858  43.431151  24.357442    30.401806
2927   4.636287  10.319932     3.245401
2936  44.885836   8.418599    31.420085
2938 -19.793058   7.622127   -10.000000
2960  31.812601   8.716542    22.268821

[125 rows x 3 columns]
835.5231470782512

>10:
       increase       pred  return_rate
31    -5.990789  11.095120    -4.193552
41     7.074863  12.877637     4.952404
73     1.992074  31.507381     1.394452
168  -12.593262  15.426041   -10.000000
179   42.980688  17.313796    30.086482
192  -26.049365  11.522532   -10.000000
196   47.076710  14.301103    32.953697
200   49.711627  32.335452    34.798139
256   38.228827  17.600026    26.760179
305   -5.727261  14.376343    -4.009082
327    7.030691  10.331937     4.921484
370   21.084548  16.891754    14.759184
411   18.318790  17.224486    12.823153
427   35.084123  14.107746    24.558886
478   11.020810  16.614978     7.714567
554   -8.643894  26.187108    -6.050726
701    9.808911  11.235780     6.866238
708    7.138195  14.720975     4.996737
763   24.061269  16.854369    16.842888
912    5.639366  11.723031     3.947556
952  -17.790270  19.551221   -10.000000
1026  10.732683  30.609371     7.512878
1060   7.586018  32.487496     5.310212
1062  25.438535  32.424881    17.806975
1065  -0.350829  11.623917    -0.245581
1102   1.963822  11.744621     1.374675
1123 -22.682917  15.759143   -10.000000
1137  30.308793  24.192204    21.216155
1184 -30.364864  11.627755   -10.000000
1239  22.330600  11.985703    15.631420
1268   3.057888  16.123083     2.140521
1400  -9.623696  21.247488    -6.736587
1435  20.732805  10.460841    14.512964
1560  29.710933  19.478916    20.797653
1565 -15.624753  10.237643   -10.000000
1588  30.501788  12.171883    21.351252
1674  32.447158  10.206789    22.713011
1683  35.522042  13.616910    24.865430
1722  19.380091  12.141715    13.566064
1751  -0.350534  21.686713    -0.245374
1831  23.836598  21.328239    16.685618
1901 -16.319127  13.695489   -10.000000
1905  -1.413999  12.566403    -0.989799
1921 -20.142229  10.660931   -10.000000
1939  18.701878  20.745939    13.091314
2046  10.329514  11.106235     7.230660
2218  49.830555  10.333023    34.881388
2243   1.544570  11.949490     1.081199
2374  35.380514  15.432804    24.766360
2417  34.797564  19.161930    24.358295
2438  19.489360  24.261394    13.642552
2450  28.523049  19.382831    19.966134
2537   6.182822  13.544859     4.327976
2627  13.355894  10.182277     9.349126
2718  12.161572  22.008932     8.513101
2796  44.072935  23.590988    30.851055
2798 -43.008417  11.084641   -10.000000
2852  57.531824  22.742201    40.272277
2858  43.431151  24.357442    30.401806
2927   4.636287  10.319932     3.245401
587.3688138284615

>15:
       increase       pred  return_rate
73     1.992074  31.507381     1.394452
168  -12.593262  15.426041   -10.000000
179   42.980688  17.313796    30.086482
200   49.711627  32.335452    34.798139
256   38.228827  17.600026    26.760179
370   21.084548  16.891754    14.759184
411   18.318790  17.224486    12.823153
478   11.020810  16.614978     7.714567
554   -8.643894  26.187108    -6.050726
763   24.061269  16.854369    16.842888
952  -17.790270  19.551221   -10.000000
1026  10.732683  30.609371     7.512878
1060   7.586018  32.487496     5.310212
1062  25.438535  32.424881    17.806975
1123 -22.682917  15.759143   -10.000000
1137  30.308793  24.192204    21.216155
1268   3.057888  16.123083     2.140521
1400  -9.623696  21.247488    -6.736587
1560  29.710933  19.478916    20.797653
1751  -0.350534  21.686713    -0.245374
1831  23.836598  21.328239    16.685618
1939  18.701878  20.745939    13.091314
2374  35.380514  15.432804    24.766360
2417  34.797564  19.161930    24.358295
2438  19.489360  24.261394    13.642552
2450  28.523049  19.382831    19.966134
2718  12.161572  22.008932     8.513101
2796  44.072935  23.590988    30.851055
2852  57.531824  22.742201    40.272277
2858  43.431151  24.357442    30.401806
399.47926334962835

>20:
       increase       pred  return_rate
73     1.992074  31.507381     1.394452
200   49.711627  32.335452    34.798139
554   -8.643894  26.187108    -6.050726
1026  10.732683  30.609371     7.512878
1060   7.586018  32.487496     5.310212
1062  25.438535  32.424881    17.806975
1137  30.308793  24.192204    21.216155
1400  -9.623696  21.247488    -6.736587
1751  -0.350534  21.686713    -0.245374
1831  23.836598  21.328239    16.685618
1939  18.701878  20.745939    13.091314
2438  19.489360  24.261394    13.642552
2718  12.161572  22.008932     8.513101
2796  44.072935  23.590988    30.851055
2852  57.531824  22.742201    40.272277
2858  43.431151  24.357442    30.401806
228.46384762851486

>25:
       increase       pred  return_rate
73     1.992074  31.507381     1.394452
200   49.711627  32.335452    34.798139
554   -8.643894  26.187108    -6.050726
1026  10.732683  30.609371     7.512878
1060   7.586018  32.487496     5.310212
1062  25.438535  32.424881    17.806975
60.77193062690404

>30:
       increase       pred  return_rate
73     1.992074  31.507381     1.394452
200   49.711627  32.335452    34.798139
1026  10.732683  30.609371     7.512878
1060   7.586018  32.487496     5.310212
1062  25.438535  32.424881    17.806975
66.82265635530307

>35:
Empty DataFrame
Columns: [increase, pred, return_rate]
Index: []
0.0

>40:
Empty DataFrame
Columns: [increase, pred, return_rate]
Index: []
0.0

>45:
Empty DataFrame
Columns: [increase, pred, return_rate]
Index: []
0.0

>50:
Empty DataFrame
Columns: [increase, pred, return_rate]
Index: []
0.0

2189.66471732412 2718.790617557897 180

Process finished with exit code 0

def custom_obj(y_true,y_pred):
    y_true = pd.Series(y_true)
    r = y_true.copy(deep=True)
    idx = y_true.index[y_true <= -10]
    r.iloc[idx] = -10
    idx = y_true.index[y_true > -10]
    r.iloc[idx] = y_true.iloc[idx] * 0.7

    sigmoid = 1/(1+np.exp(-y_pred))
    grad = -r *sigmoid*(1-sigmoid)
    hess = np.ones(shape=y_true.shape)
    return grad,hess


def get_revenue(y_true,y_pred):
    y_true = pd.Series(y_true)
    r = y_true.copy(deep=True)
    idx = y_true.index[y_true<=-10]
    r.iloc[idx] = -10
    idx = y_true.index[y_true>-10]
    r.iloc[idx] = y_true.iloc[idx] * 0.7

    plt.figure()
    plt.hist(r)

    revenue = r /(1+np.exp(-y_pred))
    return r,revenue,sum(revenue)


def derive_feature(X):
    return X[:, 0] * np.exp(X[:, 1]) / (1 + X[:, 2] * X[:, 2]) + X[:, 3]


def filter(y0):
    return np.where((y0>1) & (y0<2),1,0)


if __name__ == '__main__':
    n_samples = 10000
    n_features = 10
    np.random.seed(0)
    X = np.random.normal(0,1,size=(n_samples,n_features))

    print(X.shape)
    print(X[:5])

    y0 = derive_feature(X)

    y1 = filter(y0)
    y2 = y1 * (y0+np.random.normal(0,0.1,size=n_samples)-1.5)*100
    print("Rule revenue:",sum(y2)*0.7)
    print(sum(y1!=0),sum(y2>15),sum(y1==0),y2.shape)
    y3 = (1-y1) * np.random.normal(-10,10,size=n_samples)/4 + (1-y1) * np.random.normal(-5,20,size=n_samples)*0.75
    print("y3==0:",sum(y3==0))

    t = y3 + y2



